# write_ncdf

Export a data cube as netCDF file(s)



```{r include=FALSE}
library(gdalcubes)
```

## Description

This function will read chunks of a data cube and write them to a single (the default) or multitple (if `chunked = TRUE`) netCDF file(s). The resulting
file(s) uses the enhanced netCDF-4 format, supporting chunking and compression.


## Usage


```r
write_ncdf(
  x,
  fname = tempfile(pattern = "gdalcubes", fileext = ".nc"),
  overwrite = FALSE,
  write_json_descr = FALSE,
  with_VRT = FALSE,
  pack = NULL,
  chunked = FALSE
)

```


## Arguments

| Argument    | Description                       |
|:------------|:----------------------------------|
| x | a data cube proxy object (class cube) |
| fname | output file name |
| overwrite | logical; overwrite output file if it already exists |
| write_json_descr | logical; write a JSON description of x as additional file |
| with_VRT | logical; write additional VRT datasets (one per time slice) |
| pack | reduce output file size by packing values (see Details), defaults to no packing |
| chunked | logical; if TRUE, write one netCDF file per chunk; defaults to FALSE |


## Details

The resulting netCDF file(s) contain three dimensions (t, y, x) and bands as variables.

If `write_json_descr` is TRUE, the function will write an addition file with the same name as the NetCDF file but 
".json" suffix. This file includes a serialized description of the input data cube, including all chained data cube operations.

To reduce the size of created files, values can be packed by applying a scale factor and an offset value and using a smaller
integer data type for storage (only supported if `chunked = TRUE`). The `pack` argument can be either NULL (the default), or a list with elements `type`, `scale`, `offset`, 
and `nodata`. `type` can be any of "uint8", "uint16" , "uint32", "int16", or "int32". `scale`, `offset`, and 
`nodata` must be numeric vectors with length one or length equal to the number of data cube bands (to use different values for different bands). 
The helper function  [`pack_minmax`](pack_minmax.Rmd) can be used to derive offset and scale values with maximum precision from minimum and maximum data values on
original scale.

If `chunked = TRUE`, names of the produced files will start with `name` (with removed extension), followed by an underscore and the internal integer chunk number.


## Value

returns (invisibly) the path of the created netCDF file(s)


## Note

Packing is currently ignored if `chunked = TRUE`


## Examples


```{r}
# create image collection from example Landsat data only 
# if not already done in other examples
if (!file.exists(file.path(tempdir(), "L8.db"))) {
  L8_files <- list.files(system.file("L8NY18", package = "gdalcubes"),
                         ".TIF", recursive = TRUE, full.names = TRUE)
  create_image_collection(L8_files, "L8_L1TP", file.path(tempdir(), "L8.db"), quiet = TRUE) 
}

L8.col = image_collection(file.path(tempdir(), "L8.db"))
v = cube_view(extent=list(left=388941.2, right=766552.4, 
              bottom=4345299, top=4744931, t0="2018-04", t1="2018-04"),
              srs="EPSG:32618", nx = 497, ny=526, dt="P1M")
write_ncdf(select_bands(raster_cube(L8.col, v), c("B04", "B05")), fname=tempfile(fileext = ".nc"))
```


## See Also

[`gdalcubes_options`](gdalcubes_options.Rmd)

[`pack_minmax`](pack_minmax.Rmd)


