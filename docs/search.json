[
  {
    "objectID": "source/concepts/execution.html",
    "href": "source/concepts/execution.html",
    "title": "gdalcubes",
    "section": "",
    "text": "Creating data cubes from image collections or deriving data cubes from existing data cubes using the built-in operations is computationally cheap because no pixel values will be read and no complex computations will be started. Instead, gdalcubes uses proxy objects that simply know the shape of a data cube, what operations they refer to, and where the data comes from. Actual computations are started when users explicitly read pixels from a data cube, e.g., by calling plot, write_ncdf, write_tif, as_array, or similar operations.\nThis concept is sometimes referred to as lazy evaluation and allows for a few optimizations when operations on data cubes are chained. For example, when plotting RGB bands only, it is possible to avoid reading any files that relate to other bands.\nChaining data cube operations will create a so called process graph that can be converted to a JSON format. The format is not particularly important for users but it allows to save virtual data cube objects (no pixel data) to disk (see here).\nBelow you can find an example process graph for computing the median NDVI of pixel time series over some area in the Brazilian Amazon forest.\n{\n  \"cube_type\": \"reduce_time\",\n  \"in_cube\": {\n      \"band_names\": [\n      \"NDVI\"\n      ],\n      \"cube_type\": \"apply_pixel\",\n      \"expr\": [\n      \"(b05-b04)/(b05+b04)\"\n      ],\n      \"in_cube\": {\n      \"bands\": [\n          \"B04\",\n          \"B05\"\n      ],\n      \"cube_type\": \"select_bands\",\n      \"in_cube\": {\n          \"chunk_size\": [\n          1,\n          256,\n          256\n          ],\n          \"cube_type\": \"image_collection\",\n          \"file\": \"/tmp/RtmpacmRAy/file11af57b771e8.sqlite\",\n          \"view\": {\n          \"aggregation\": \"median\",\n          \"resampling\": \"bilinear\",\n          \"space\": {\n              \"bottom\": -550000.0,\n              \"left\": -6180000.0,\n              \"nx\": 2000,\n              \"ny\": 2000,\n              \"right\": -6080000.0,\n              \"srs\": \"EPSG:3857\",\n              \"top\": -450000.0\n          },\n          \"time\": {\n              \"dt\": \"P1Y\",\n              \"t0\": \"2014\",\n              \"t1\": \"2018\"\n          }\n          },\n          \"warp_args\": []\n      }\n      },\n      \"keep_bands\": false\n  },\n  \"reducer_bands\": [\n      [\n      \"median\",\n      \"NDVI\"\n      ]\n  ]\n}\n\n\n\nTo avoid running out of memory and to allow for parallel processing, gdalcubes divides data cubes into smaller chunks. A chunk is defined by its size in the temporal and spatial dimensions and contains all bands / variables. Internally, a chunk is simply stored as a four dimensional numeric (double-precision floating-point number) array.\nEmpty chunks that do not contain any data in most cases do not consume any memory. Data cubes in many case contain quite a large number of empty chunks for example when there is simply no satellite image available in a collection that intersects with the spatiotemporal extent of the chunk. Most data cube operations propagate empty chunks, i.e., they check if a chunk of the input cube is empty and simply forward the chunk without doing expensive computations. As a result, the data model can be seen as a semi-sparse array. One important consequence is that in many cases, using a higher temporal resolution (e.g. daily in case of Sentinel-2 data with 5 days revisit time) does not cause computations to take significantly longer.\nWhile a data cube is being processed, gdalcubes simply iterates over its chunks. If the cube is the result from chained operations, the process graph is automatically traversed backwards and each chunk knows which chunks from the input cubes must be read or which images must be read.\n\n\nA custom chunk size of data cubes can be set either as an additional argument chunking to the raster_cube() function, or as a global package default variable using gdalcubes_options(). Sizes are defined as an integer vector with 3 elements, representing the size in t, y, and x dimensions (in this order). For gdalcubes_options(), it is also possible to define a function that calculates the chunk size based on the size of the input cube.\nThe following examples show how to define a custom chunk size either for a specific cube, or as a global package variable.\nL8.col = image_collection(file.path(tempdir(), \"L8.db\"))\nv = cube_view(extent=L8.col, srs=\"EPSG:32618\", nx = 497, ny=526, dt=\"P1M\")\nraster_cube(L8.col, v, chunking = c(1,512,512))\ngdalcubes_options(default_chunksize = c(1, 512, 512))\n\n\n\n\ngdalcubes has built-in support for processing data cubes in parallel using multiple CPU cores. Users can define the maximum number of worker processes as a global package variable (see below). Chunks of the data cube will then be distributed among the worker processes.\ngdalcubes_options(parallel = 8)\n\n\n\nThe size of data cube chunks has a strong effect on computation times and memory consumption. There is no golden rule to find an optimal chunk size, because it depends on\n\navailable hardware,\ninput imagery (data format, tiling), and\nparticular analysis (how the data is accessed).\n\nBy default, gdalcubes tries to find an appropriate size considering the size of the cube and the number of worker processes. However, below are some practical considerations that might be helpful to find a better chunk size:\n\nThe larger the chunks and the more parallel processes are being used, the more memory is consumed. If you run into out-of-memory issues / swapping, try decreasing one or both.\nIf you find that the number of true processes used is lower than set, the data cube might have less chunks than worker processes. You can try to decrease the chunk size to improve parallelization.\nIf the computations are I/O-bound (most time is required for disk reads / writes or downloads), try to find out the block size of the image data (e.g., with the gdalinfo utility) and use this as a chunk size. You also might want to try out different GDAL configuration options to define how downloads and/or memory blocks are being cached.\nThere are only very few cases where chunks with temporal size greater than one improve computation times, so there is likely no need to change this."
  },
  {
    "objectID": "source/concepts/udfs.html",
    "href": "source/concepts/udfs.html",
    "title": "gdalcubes",
    "section": "",
    "text": "Data cube operations such as apply_pixel, or reduce_time expect functions or expressions as arguments. For example, to compute summary statistics over time, reduce_time supports computing minimum, maximum, mean, median, and a few other built-in statistics. These built-in functions are purely written in C++ and hence relatively efficient. However, in many cases, we would like to apply more complex functions from external R packages on data cubes.\nTable 1 lists data cube operations that additionally support calling user-defined R functions (e.g., on time series). For example, reduce_time can not only be used for simple statistics but also for applying complex time series analysis like classification or change detection.\n\n\nTable 1: Data cube operations supporting UDFs and shape of the input and output of the UDF. \\(n_b\\),\\(n_t\\),\\(n_y\\),\\(n_x\\) refer to the dimension sizes of the whole cube, \\(m_b\\) means that the number of bands the function returns is flexible and independent from the number of input bands.\n\n\nOperation\nUDF input\\((n_b, n_t, n_y, n_x)\\)\nUDF output\\((n_b, n_t, n_y, n_x)\\)\n\n\n\n\napply_pixel\n\\((n_b, 1, 1, 1)\\)\n\\((m_b, 1, 1, 1)\\)\n\n\napply_time\n\\((n_b, n_t, 1, 1)\\)\n\\((m_b, n_t, 1, 1)\\)\n\n\nreduce_space\n\\((n_b, 1, n_y, n_x)\\)\n\\((m_b, 1, 1, 1)\\)\n\n\nreduce_time\n\\((n_b, n_t, 1, 1)\\)\n\\((m_b, 1, 1, 1)\\)\n\n\n\n\n\n\n\nreduce_timeapply_pixelapply_timereduce_space\n\n\nFit a linear model to all time series and returns the coefficients:\n# z is a data cube with band NDVI\nreduce_time(z, names = c(\"intercept\",\"slope\"), \n  FUN = function(x) {\n    df = data.frame(t=1:ncol(x), ndvi=x[\"NDVI\",])\n    result = c(NA, NA)\n    if (sum(!is.na(df$ndvi)) > 3) {\n      result = coef(lm(ndvi ~ t, df, \n                    na.action = na.exclude))\n    }\n    return(result) \n})\n\n\nDerive wind speed from north/south and east/west wind components:\n# z is a data cube with bands u/v wind components\napply_pixel(z, names=\"wind_speed\", \n  FUN=function(x) {\n    sqrt(x[\"u\"]^2 + x[\"v\"]^2)\n  })\n\n\nCalculate cumulative sums of NDVI times series after removing the (per time series) mean NDVI:\n# z is a data cube with band NDVI\napply_time(z, names = c(\"cusum\"), \n  FUN = function(x) {\n    res = x[\"NDVI\",] - mean(x[\"NDVI\",], na.rm = TRUE)\n    res[is.na(res)] = 0\n    return(cumsum(res)) \n})\n\n\nCalculate min, max, quartiles, and median for all image slices:\n# z is a data cube with a single band\nreduce_space(z, names = paste0(\"q\",1:5), FUN = function(x) {\n  quantile(x, c(0, 0.25, 0.5, 0.75, 1), na.rm = TRUE)\n})\n\n\n\n\n\n\nWriting UDFs can sometimes become complicated and more difficult to debug (see Debugging). However, you can reduce frustration if you consider the following rules:\n\nThe function must always return an array of the corresponding dimensions (see Table 1). Dimensions with size 1 can be dropped in the result array.\nThe number of bands that a UDF returns can be independent from the number of input bands but must be identical for all function calls. For example, if a UDF outputs model parameters for time series model, it should always return the same number of parameters.\nMake sure that the function does not crash due to NAs. It is quite common that there are for example time series without any valid observations at the corners of a data cube. Ideally, use tryCatch to handle errors and return an NA array of appropriate shape by default. If errors are not handled, computations will stop even if only a single call fails.\nDo not try to use variables, packages, or any other objects from the environment outside the function. Since the UDF runs in a new R process, make sure to load needed packages, data, etc. within the function.\n\n\n\n\nBecause UDFs run in separate processes, debugging can be challenging. When developing UDFs, it is recommended to start with a minimal example, e.g. by working on lower resolution and/or spatiotemporal extent. Error messages are generally forwarded to the main R process. To get more detailed error messages, try setting gdalcubes_options(debug = TRUE).\n\n\n\n\n\nThe following steps are performed when executing a UDF on a data cube.\n\nIf needed, chunks of data cubes are rearranged. For example, to apply a function on time series, this step makes sure that a single chunk contains complete time series of a small spatial block of pixels.\nA chunk of the data cube is written to a temporary file on disk using a custom binary format (see binary serialization format).\nA new R process is started, reads the chunk from disk memory, applies the UDF, and finally writes the result to another temporary binary file.\ngdalcubes now loads the result file into memory and continues.\n\nNotice that it is possible to change the directory where intermediate files are written, e.g. to use a shared memory device with gdalcubes_options(streaming_dir = \"/dev/shm\").\n\n\n\nTo stream data to and from the external process, a custom binary serialization format is used.\nThe format includes data cube values of one chunk and includes dimension values, band names, and the spatial reference system.\n\n\n\n\n\n\nWarning\n\n\n\nThe binary serialization format will be replaced with CF compliant netCDF-4 / ZARR files in future versions.\n\n\nThe format contains\n\nthe size of the chunk as 4 * 4 bytes in total (nbands:int32, nt:int32, ny:int32, nx:int32),\nband names, where each band starts with the number of characters as int32 followed by actual characters,\ndimension values in the order time, y, x as doubles, summing to (nt + ny + nx) * 8 bytes in total,\nthe spatial reference system as a string (number of characters as int32, followed by actual characters), and\nactual values of the chunk as doubles (summing to nbands * nt * ny * nx * 8 bytes)."
  },
  {
    "objectID": "source/concepts/image_collections.html",
    "href": "source/concepts/image_collections.html",
    "title": "gdalcubes",
    "section": "",
    "text": "References\n\nSimoes, Rolf, Felipe Souza, Matheus Zaglia, Gilberto Ribeiro Queiroz, Rafael Santos, and Karine Ferreira. 2021. “Rstac: An r Package to Access Spatiotemporal Asset Catalog Satellite Imagery.” In 2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS, 7674–77. https://doi.org/10.1109/IGARSS47720.2021.9553518."
  },
  {
    "objectID": "source/concepts/config.html",
    "href": "source/concepts/config.html",
    "title": "gdalcubes",
    "section": "",
    "text": "gdalcubes heavily relies on GDAL to read image data. GDAL itself comes with a lot of configuration options that can be set to improve computation times and I/O or network transfer performance. Below, you find the most important options for gdalcubes with a brief description. Please refer to the original documentation for details.\n\n\n\n\n\n\n\nConfiguration option\nDescription\n\n\n\n\nGDAL_CACHEMAX\nSize of the default block cache, can be set in byte, MB, or as a percentage of available main, memory. Defaults to 256 MB\n\n\nGDAL_DISABLE_READDIR_ON_OPEN\nSet to TRUE or EMPTY_DIR to avoid listing all files in the directory once a single file is opened (this is highly recommended). Defaults to TRUE\n\n\nGDAL_NUM_THREADS\nNumber of threads GDAL can use for block reads and (de)compression, set to ALL_CPUS to use all available cores. Defaults to 1.\n\n\nVSI_CACHE\nEnable / disable per-file caching by setting to TRUE or FALSE. Default is FALSE.\n\n\nVSI_CACHE_SIZE\nPer-file cache size in bytes, defaults to 25 MB.\n\n\nCPL_VSIL_CURL_CACHE_SIZE\nGlobal cache size for downloads in bytes, defaults to 16 MB.\n\n\n\n\n\nPlease consider that settings apply for each gdalcubes worker process and you should calculate memory limits such as cache sizes accordingly. To set a configuration option, you can use gdalcubes_set_gdal_config() as in the following examples.\ngdalcubes_set_gdal_config(\"GDAL_NUM_THREADS\", \"ALL_CPUS\")\ngdalcubes_set_gdal_config(\"VSI_CACHE\", \"TRUE\")\ngdalcubes_set_gdal_config(\"VSI_CACHE_SIZE\", as.character(5*1000*1000)) # 5 MB per file\ngdalcubes_set_gdal_config(\"GDAL_CACHEMAX\", \"2%\") \n\n\nSimilar to the recommended settings for TiTiler (see here), the following options are recommended as a starting points to improve the performance of cloud data access.\ngdalcubes_set_gdal_config(\"VSI_CACHE\", \"TRUE\")\ngdalcubes_set_gdal_config(\"GDAL_CACHEMAX\",\"30%\")\ngdalcubes_set_gdal_config(\"VSI_CACHE_SIZE\",\"10000000\")\ngdalcubes_set_gdal_config(\"GDAL_HTTP_MULTIPLEX\",\"YES\")\ngdalcubes_set_gdal_config(\"GDAL_INGESTED_BYTES_AT_OPEN\",\"32000\")\ngdalcubes_set_gdal_config(\"GDAL_DISABLE_READDIR_ON_OPEN\",\"EMPTY_DIR\")\ngdalcubes_set_gdal_config(\"GDAL_HTTP_VERSION\",\"2\")\ngdalcubes_set_gdal_config(\"GDAL_HTTP_MERGE_CONSECUTIVE_RANGES\",\"YES\")\ngdalcubes_set_gdal_config(\"GDAL_NUM_THREADS\", \"ALL_CPUS\")\nTo access imagery from requester pays buckets, you additionally may want to set:\ngdalcubes_set_gdal_config(\"AWS_ACCESS_KEY_ID\", \"xxxxxxxxxxxxxx\")\ngdalcubes_set_gdal_config(\"AWS_SECRET_ACCESS_KEY\", \"xxxxxxxxxxxxxx\")\ngdalcubes_set_gdal_config(\"AWS_REQUEST_PAYER\", \"requester\")\nFor more details, please refer to the GDAL documentation of virtual file systems for cloud providers."
  },
  {
    "objectID": "source/concepts/streaming.html",
    "href": "source/concepts/streaming.html",
    "title": "gdalcubes",
    "section": "",
    "text": "Chunks of a data cube can be streamed to external processes. For example this allows to run user-defined R or Python scripts on chunks of data cubes in parallel.\nThere are currently three operations supporting chunk streaming:\n\nstream_apply_pixel streams chunks of a source data cube to an external processs and expects the same number of pixels as a result, but any number of bands.\n\nstream_reduce_time combines chunks of the same spatial part but different spans of time first, such that one resulting chunk contains complete time series of the cube and afterwards calls an external process on chunks. The external process is expected to produce a single time slice (i.e., nt = 1), the same number of pixels as the source data cube in space, and any number of bands.\nstream_chunk is a less user-friendly but more general operation that tries to derive the dimensionality of the result cube automatically, by calling the process on dummy data once.\n\nNotice that the number of result bands must be identical for all input chunks. The R package includes an easy to use implementation that allows passing R functions to apply_pixel and reduce_time.\n\n\nTo stream data to and from the external process, a custom binary serialization format is used.\nThe format includes data cube values of one chunk and includes dimension values, band names, and the spatial reference system.\n\n\n\n\n\n\nWarning\n\n\n\nThe binary serialization format will be replaced with CF compliant netCDF-4 / ZARR files in future versions.\n\n\nThe format contains\n\nthe size of the chunk as 4 * 4 bytes in total (nbands:int32, nt:int32, ny:int32, nx:int32),\nband names, where each band starts with the number of characters as int32 followed by actual characters,\ndimension values in the order time, y, x as doubles, summing to (nt + ny + nx) * 8 bytes in total,\nthe spatial reference system as a string (number of characters as int32, followed by actual characters), and\nactual values of the chunk as doubles (summing to nbands * nt * ny * nx * 8 bytes)."
  },
  {
    "objectID": "source/tutorials/videos.html",
    "href": "source/tutorials/videos.html",
    "title": "gdalcubes",
    "section": "",
    "text": "Analyzing massive amounts of EO data in the cloud with R, gdalcubes, and STAC (tutorial presented at OpenGeoHub Summer School, online, Sept 1-3, 2021)\n\n\n\n\n\n\nAnalyzing Multi-Variable Earth Observation Data Cubes (tutorial presented at Geospatial Sensing | Virtual 2020, Aug 31- Sep 2, 2020)"
  },
  {
    "objectID": "source/tutorials/bfast/bfast.html",
    "href": "source/tutorials/bfast/bfast.html",
    "title": "gdalcubes",
    "section": "",
    "text": "This tutorial shows how user-defined functions from external R packages can be applied to data cubes over time. As an example, we will use the bfast R package containing unsupervised change detection methods identifying structural breakpoints in vegetation index time series. Specifically, we will use the bfastmonitor() function to monitor changes on a time series of Sentinel-2 imagery.\n\n\n\nWe will use Sentinel-2 surface reflectance data from 2016 to 2020 covering a small forested area located southeast of Berlin. The area of interest is available as a polygon in a GeoPackage file gruenheide_forest.gpkg, which is shown in a simple map below.\n\nlibrary(sf)\n\n## Linking to GEOS 3.10.1, GDAL 3.4.0, PROJ 8.2.0; sf_use_s2() is TRUE\n\ngeom = read_sf(\"gruenheide_forest.gpkg\")\ngeom |>\n  st_bbox() -> bbox\n\nlibrary(tmap)\ntmap_mode(\"view\")\n\n## tmap mode set to interactive viewing\n\ntm_shape(st_geometry(geom)) +  tm_polygons()\n\n\n\n\n\n\n\n\n\nInstead of downloading > 100 Sentinel-2 images, we use a cheap machine on Amazon Web Services (AWS) in the Oregon region, where the Sentinel-2 level 2A data are available as cloud-optimized GeoTIFFs (COGs) and explorable via the SpatioTemporal Asset Catalog (STAC) API (see here for more details about the public Sentinel-2 level 2A COG data catalog).\nUsing the rstac package, we first request all available images from 2016 to 2020 that intersect with our region of interest.\n\nlibrary(rstac)\ns = stac(\"https://earth-search.aws.element84.com/v0\")\n\nitems <- s |>\n    stac_search(collections = \"sentinel-s2-l2a-cogs\",\n                bbox = c(bbox[\"xmin\"],bbox[\"ymin\"],bbox[\"xmax\"],bbox[\"ymax\"]), \n                datetime = \"2016-01-01/2020-12-31\",\n                limit = 500) |>\n    post_request() \nitems\n\n## ###STACItemCollection\n## - matched feature(s): 457\n## - features (457 item(s) / 0 not fetched):\n##   - S2B_33UVU_20201229_0_L2A\n##   - S2A_33UVU_20201227_0_L2A\n##   - S2A_33UVU_20201224_0_L2A\n##   - S2B_33UVU_20201222_0_L2A\n##   - S2B_33UVU_20201219_0_L2A\n##   - S2A_33UVU_20201217_0_L2A\n##   - S2B_33UVU_20201212_0_L2A\n##   - S2B_33UVU_20201209_1_L2A\n##   - S2A_33UVU_20201207_0_L2A\n##   - S2A_33UVU_20201204_0_L2A\n##   - ... with 447 more feature(s).\n## - assets: \n## thumbnail, overview, info, metadata, visual, B01, B02, B03, B04, B05, B06, B07, B08, B8A, B09, B11, B12, AOT, WVP, SCL\n## - other field(s): \n## type, stac_version, stac_extensions, context, numberMatched, numberReturned, features, links\n\n# Date and time of first and last images\nrange(sapply(items$features, function(x) {x$properties$datetime}))\n\n## [1] \"2016-11-05T10:12:57Z\" \"2020-12-29T10:16:06Z\"\n\n\nIt turns out that 457 images intersect with our region of interest while the first available images have been recorded in November, 2016.\nTo build a regular monthly data cube, we now need to create a gdalcubes image collection from the STAC query result. Notice that to include the SCL band containing per-pixel quality flags (classification as clouds, cloud-shadows, and others), we need to explicitly list the names of the assets. We furthermore ignore images with 50% or more cloud coverage.\n\nlibrary(gdalcubes)\nassets = c(\"B01\",\"B02\",\"B03\",\"B04\",\"B05\",\"B06\", \"B07\",\"B08\",\"B8A\",\"B09\",\"B11\",\"SCL\")\nstac_image_collection(items$features, asset_names = assets, property_filter = function(x) {x[[\"eo:cloud_cover\"]] < 50}) -> s2_collection\n\n## Warning in stac_image_collection(items$features, asset_names = assets,\n## property_filter = function(x) {: STAC asset with name 'SCL' does not include\n## eo:bands metadata and will be considered as a single band source\n\ns2_collection\n\n## Image collection object, referencing 200 images with 12 bands\n## Images:\n##                       name     left      top   bottom    right\n## 1 S2A_33UVU_20201107_0_L2A 13.50096 53.24957 52.25346 14.89124\n## 2 S2A_33UVU_20201104_0_L2A 13.50096 53.24953 52.25346 15.14626\n## 3 S2B_33UVU_20201023_0_L2A 13.50096 53.24958 52.25346 14.90383\n## 4 S2B_33UVU_20201003_0_L2A 13.50096 53.24958 52.25346 14.90847\n## 5 S2A_33UVU_20200928_0_L2A 13.50096 53.24958 52.25346 14.90143\n## 6 S2B_33UVU_20200923_0_L2A 13.50096 53.24958 52.25346 14.91057\n##              datetime        srs\n## 1 2020-11-07T10:26:09 EPSG:32633\n## 2 2020-11-04T10:16:13 EPSG:32633\n## 3 2020-10-23T10:26:08 EPSG:32633\n## 4 2020-10-03T10:26:08 EPSG:32633\n## 5 2020-09-28T10:26:10 EPSG:32633\n## 6 2020-09-23T10:26:07 EPSG:32633\n## [ omitted 194 images ] \n## \n## Bands:\n##    name offset scale unit nodata image_count\n## 1   B01      0     1                     200\n## 2   B02      0     1                     200\n## 3   B03      0     1                     200\n## 4   B04      0     1                     200\n## 5   B05      0     1                     200\n## 6   B06      0     1                     200\n## 7   B07      0     1                     200\n## 8   B08      0     1                     200\n## 9   B09      0     1                     200\n## 10  B11      0     1                     200\n## 11  B8A      0     1                     200\n## 12  SCL      0     1                     200\n\n\nThe result contains 200 images, from which we can now create a data cube. We use the projected bounding box of our polygon as spatial extent, 10 meters spatial resolution, bilinear spatial resampling and derive monthly median values for all pixel values from multiple images within a month, if available. Notice that to make sure that the polygon is completely within our extent, we add 10m to each side of the cube.\n\nst_as_sfc(bbox) |>\n  st_transform(\"EPSG:32633\") |>\n  st_bbox() -> bbox_utm\nv = cube_view(srs = \"EPSG:32633\", extent = list(t0 = \"2016-01\", t1 = \"2020-12\", left = bbox_utm[\"xmin\"] - 10, right = bbox_utm[\"xmax\"] + 10, bottom = bbox_utm[\"ymin\"] - 10, top = bbox_utm[\"ymax\"] + 10),\n              dx = 10, dy = 10, dt = \"P1M\", aggregation = \"median\", resampling = \"bilinear\")\nv\n\n## A data cube view object\n## \n## Dimensions:\n##                low             high count pixel_size\n## t       2016-01-01       2020-12-31    60        P1M\n## y 5802003.49436843 5807403.49436843   540         10\n## x 415522.739260076 424662.739260076   914         10\n## \n## SRS: \"EPSG:32633\"\n## Temporal aggregation method: \"median\"\n## Spatial resampling method: \"bilinear\"\n\n\nNext, we create a data cube, subset the red and near infrared bands and crop by our polygon, which simply sets pixel values outside of the polygon to NA. Afterwards we simply save the data cube as a single netCDF file. Notice that this is not needed but makes debugging to some degree easier.\n\ns2.mask = image_mask(\"SCL\", values = c(3,8,9))\ngdalcubes_options(threads = 8, ncdf_compression_level = 5)\nraster_cube(s2_collection, v, mask = s2.mask) |>\n  select_bands(c(\"B04\",\"B08\")) |>\n  filter_geom(geom$geometry) |>\n  write_ncdf(\"gruenheide_cube_monthly.nc\")\n\n\n\n\nTo get an overview of the data, we first calculate the number of available observations per time series using the built-in count reducer.\n\ngdalcubes_options(parallel = 8)\nncdf_cube(\"gruenheide_cube_monthly.nc\") |>\n  reduce_time(\"count(B04)\") |>\n  plot(key.pos = 1, zlim=c(0,60), col = viridis::viridis, nbreaks = 7)\n\n\n\n\nAlthough our collection contains 200 images with less than 50% cloud coverage, most time series only contain between 40 and 50 valid (non-masked) observations.\nWe can now use the generic function reduce_time() to apply bfastmonitor() to all kNDVI time series. Notice that there are some fully missing time series and we must carefully catch potential errors, because we do not want a single failing time series to stop all computations. The script below returns computed change dates and magnitudes for all pixel time series and writes the results to a netCDF file.\n\nncdf_cube(\"gruenheide_cube_monthly.nc\") |>\n  reduce_time(names = c(\"change_date\", \"change_magnitude\"), FUN = function(x) {\n    knr <- exp(-((x[\"B08\",]/10000)-(x[\"B04\",]/10000))^2/(2))\n    kndvi <- (1-knr) / (1+knr)   \n    if (all(is.na(kndvi))) {\n      return(c(NA,NA))\n    }\n    kndvi_ts = ts(kndvi, start = c(2016, 1), frequency = 12)\n    library(bfast)\n    tryCatch({\n        result = bfastmonitor(kndvi_ts, start = c(2020,1), level = 0.01)\n        return(c(result$breakpoint, result$magnitude))\n      }, error = function(x) {\n        return(c(NA,NA))\n      })\n  }) |>\n  write_ncdf(\"result.nc\", overwrite = TRUE)\n\nRunning bfastmonitor() is computationally expensive. However, since the data is located in the cloud anyway, it would be obvious to launch one of the more powerful machine instance types with many processors. Parallelization within one instance can be controlled entirely by gdalcubes using gdalcubes_options().\n\n\n\nTo visualize the change detection results, we load the resulting netCDF file, convert it to a stars object, and finally use the tmap package to create an interactive map to visualize the change date.\n\nlibrary(stars)\n\n## Loading required package: abind\n\nncdf_cube(\"result.nc\") |>\n  st_as_stars() -> x\ntm_shape(x[\"NETCDF:\\\"result.nc\\\":change_date\"]) + tm_raster()\n\n\n\n\n\nThe result certainly needs some postprocessing to understand types of changes and to identify false positives. The larger region in the west of the study area however clearly shows some deforestation due to the construction of Tesla’s Gigafactory Berlin-Brandenburg.\n\n\n\nThis tutorial has shown how change detection with BFAST can be applied on pixel time series of a data cube as a user-defined function. To avoid downloading a large number of images, the data cube has been created in the cloud, where Sentinel-2 level 2A imagery is already available.\nThe BFAST family of change detection methods is computationally quite expensive. For processing larger areas and/or longer time series, a more powerful machine would be helpful. However, there are quite a few ongoing developments improving the performance that may find their way to the bfast package on CRAN in the near future."
  },
  {
    "objectID": "source/tutorials/vignettes/gc02_AWS_Sentinel2.html",
    "href": "source/tutorials/vignettes/gc02_AWS_Sentinel2.html",
    "title": "2. Data cubes from Sentinel-2 data in the cloud",
    "section": "",
    "text": "This vignette will not explain any details the specifications but demonstrate how they can be used in combination with gdalcubes and the rstac package. We will use the freely available Sentinel-2 COG catalog on Amazon Web Services (AWS) and the corresponding STAC-API endpoint at https://earth-search.aws.element84.com/v0/collections/sentinel-s2-l2a.\nNotice that this vignette in principle runs anywhere but computations take much longer when not working on an AWS machine in the region of the data catalog (in this case us-west-2).\n\nFinding images with rstac\nAs an example, we are interested in cloud-free images of New York City in June, 2021. We can use the NYC administrative polygons that are shipped as example data with the package and use the (sf)[https://cran.r-project.org/package=sf] package for reading and calculating the bounding box.\n\nlibrary(sf)\n## Linking to GEOS 3.10.1, GDAL 3.4.0, PROJ 8.2.0; sf_use_s2() is TRUE\nnyc_shape = read_sf(system.file(\"nycd.gpkg\",package = \"gdalcubes\"))\n\nbbox = st_bbox(nyc_shape) \nbbox\n##      xmin      ymin      xmax      ymax \n##  563069.9 4483098.0  609761.1 4529895.0\n\nTo ask the STACK endpoints for available images intersecting with our area of interest, we need to provide the bounding box in WGS84 (latitude / longitude) coordinates, which we can calculate with:\n\nnyc_shape |>\n  st_transform(\"EPSG:4326\") |>\n  st_bbox() -> bbox_wgs84\nbbox_wgs84\n##      xmin      ymin      xmax      ymax \n## -74.25559  40.49614 -73.70002  40.91500\n\nNext, we load the rstac package, specify the STAC-API endpoint URL and query all available images for our area and time of interest.\n\nlibrary(rstac)\ns = stac(\"https://earth-search.aws.element84.com/v0\")\n  items = s |>\n    stac_search(collections = \"sentinel-s2-l2a-cogs\",\n                bbox = c(bbox_wgs84[\"xmin\"],bbox_wgs84[\"ymin\"],\n                         bbox_wgs84[\"xmax\"],bbox_wgs84[\"ymax\"]), \n                datetime = \"2021-06-01/2021-06-30\") |>\n    post_request() |> items_fetch(progress = FALSE)\n  length(items$features)\n## [1] 48\n\nAs a result, we get a list with metadata and URLs pointing to 48 images. This list is an index-like object pointing to original images on a AWS S3 bucket and hence somewhat similar to gdalcubes image collections.\n\n\nConverting STAC items to image collections\nWe can convert the STAC response to a gdalcubes image collections using stac_image_collection(). This function expects a STAC feature list as input and optionally can apply some filters on metadata and bands. Notice that this operation is much faster than the creation of image collections from local files, because all metadata are already available and no image file must be opened. Below, we create a collection for images with less than 10% cloud cover.\n\nlibrary(gdalcubes)\ns2_collection = stac_image_collection(items$features,  property_filter = function(x) {x[[\"eo:cloud_cover\"]] < 10})\ns2_collection\n## Image collection object, referencing 16 images with 18 bands\n## Images:\n##                       name      left      top   bottom     right\n## 1 S2B_18TWK_20210629_0_L2A -75.00023 40.65085 39.65842 -73.78649\n## 2 S2B_18TXK_20210629_0_L2A -73.81752 40.64478 40.55838 -73.78649\n## 3 S2B_18TWL_20210629_0_L2A -75.00023 41.55184 40.55671 -73.68381\n## 4 S2B_18TXL_20210629_0_L2A -73.81884 41.54559 40.55671 -73.45793\n## 5 S2A_18TWK_20210624_0_L2A -75.00023 40.65085 39.65836 -73.77774\n## 6 S2A_18TXK_20210624_0_L2A -73.81796 40.64478 40.53306 -73.77774\n##              datetime        srs\n## 1 2021-06-29T16:02:02 EPSG:32618\n## 2 2021-06-29T16:01:52 EPSG:32618\n## 3 2021-06-29T16:01:48 EPSG:32618\n## 4 2021-06-29T16:01:42 EPSG:32618\n## 5 2021-06-24T16:02:02 EPSG:32618\n## 6 2021-06-24T16:01:52 EPSG:32618\n## [ omitted 10 images ] \n## \n## Bands:\n##            name offset scale unit nodata image_count\n## 1           B01      0     1                      16\n## 2           B02      0     1                      16\n## 3           B03      0     1                      16\n## 4           B04      0     1                      16\n## 5           B05      0     1                      16\n## 6           B06      0     1                      16\n## 7           B07      0     1                      16\n## 8           B08      0     1                      16\n## 9           B09      0     1                      16\n## 10          B11      0     1                      16\n## 11          B12      0     1                      16\n## 12          B8A      0     1                      16\n## 13 overview:B02      0     1                      16\n## 14 overview:B03      0     1                      16\n## 15 overview:B04      0     1                      16\n## 16   visual:B02      0     1                      16\n## 17   visual:B03      0     1                      16\n## 18   visual:B04      0     1                      16\n\nThe collection contains 16 images and all spectral bands plus some RGB preview images. However, the scene classification layer (SCL) containing pixel-wise information whether a pixel shows a cloud, cloud-shadow, water, or something else, is missing. Although the SCL images are available in the returned STAC list, the response does not include all of the metadata to let gdalcubes recognize it as an image. However, it is possible to explicitly list the names of all bands to be included in the collection by adding the asset_names argument:\n\nassets = c(\"B01\",\"B02\",\"B03\",\"B04\",\"B05\",\"B06\", \"B07\",\"B08\",\"B8A\",\"B09\",\"B11\",\"SCL\")\ns2_collection = stac_image_collection(items$features, asset_names = assets, property_filter =\n                                      function(x) {x[[\"eo:cloud_cover\"]] < 10})\ns2_collection\n## Image collection object, referencing 16 images with 12 bands\n## Images:\n##                       name      left      top   bottom     right\n## 1 S2B_18TWK_20210629_0_L2A -75.00023 40.65085 39.65842 -73.78649\n## 2 S2B_18TXK_20210629_0_L2A -73.81752 40.64478 40.55838 -73.78649\n## 3 S2B_18TWL_20210629_0_L2A -75.00023 41.55184 40.55671 -73.68381\n## 4 S2B_18TXL_20210629_0_L2A -73.81884 41.54559 40.55671 -73.45793\n## 5 S2A_18TWK_20210624_0_L2A -75.00023 40.65085 39.65836 -73.77774\n## 6 S2A_18TXK_20210624_0_L2A -73.81796 40.64478 40.53306 -73.77774\n##              datetime        srs\n## 1 2021-06-29T16:02:02 EPSG:32618\n## 2 2021-06-29T16:01:52 EPSG:32618\n## 3 2021-06-29T16:01:48 EPSG:32618\n## 4 2021-06-29T16:01:42 EPSG:32618\n## 5 2021-06-24T16:02:02 EPSG:32618\n## 6 2021-06-24T16:01:52 EPSG:32618\n## [ omitted 10 images ] \n## \n## Bands:\n##    name offset scale unit nodata image_count\n## 1   B01      0     1                      16\n## 2   B02      0     1                      16\n## 3   B03      0     1                      16\n## 4   B04      0     1                      16\n## 5   B05      0     1                      16\n## 6   B06      0     1                      16\n## 7   B07      0     1                      16\n## 8   B08      0     1                      16\n## 9   B09      0     1                      16\n## 10  B11      0     1                      16\n## 11  B8A      0     1                      16\n## 12  SCL      0     1                      16\n\n\n\nCreating and processing data cubes\nHaving an image collection object, we can now use gdalcubes in the same way as we do with local files. Particularly, we define a data cube view and maybe some additional data cube operations. In the following example, we create a coarse resolution (100m) simple median-composite RGB image from a daily data cube.\n\ngdalcubes_options(parallel = 8)\nv = cube_view(srs=\"EPSG:32618\", dx=100, dy=100, dt=\"P1D\", \n                           aggregation=\"median\", resampling = \"average\",\n                           extent=list(t0 = \"2021-06-01\", t1 = \"2021-06-30\",\n                                       left=bbox[\"xmin\"], right=bbox[\"xmax\"],\n                                       top=bbox[\"ymax\"], bottom=bbox[\"ymin\"]))\nv\n## A data cube view object\n## \n## Dimensions:\n##                low             high count pixel_size\n## t       2021-06-01       2021-06-30    30        P1D\n## y 4483096.51932691 4529896.51932691   468        100\n## x 563065.499607774 609765.499607774   467        100\n## \n## SRS: \"EPSG:32618\"\n## Temporal aggregation method: \"median\"\n## Spatial resampling method: \"average\"\n\nraster_cube(s2_collection, v) |>\n  select_bands(c(\"B02\",\"B03\",\"B04\")) |>\n  reduce_time(c(\"median(B02)\", \"median(B03)\", \"median(B04)\")) |>\n  plot(rgb = 3:1, zlim = c(0,2500))\n\n\n\n\n\n\n\n\nOf course, we can “zoom in” to Lower Manhattan simply by changing the data cube view.\n\nv = cube_view(srs=\"EPSG:32618\", dx=10, dy=10, dt=\"P1D\", \n                           aggregation=\"median\", resampling = \"average\",\n                           extent=list(t0 = \"2021-06-01\", t1 = \"2021-06-30\",\n                                       left=582182, right=587019,\n                                       top=4508997, bottom=4505883))\nv\n## A data cube view object\n## \n## Dimensions:\n##          low       high count pixel_size\n## t 2021-06-01 2021-06-30    30        P1D\n## y    4505880    4509000   312         10\n## x   582180.5   587020.5   484         10\n## \n## SRS: \"EPSG:32618\"\n## Temporal aggregation method: \"median\"\n## Spatial resampling method: \"average\"\nraster_cube(s2_collection, v) |>\n  select_bands(c(\"B02\",\"B03\",\"B04\")) |>\n  reduce_time(c(\"median(B02)\", \"median(B03)\", \"median(B04)\")) |>\n  plot(rgb = 3:1, zlim = c(0,2500))\n\n\n\n\n\n\n\n\nFor more complex examples, you can find a tutorial on YouTube and corresponding materials on GitHub how to use gdalcubes in the cloud, presented at the virtual OpenGeoHub Summer School 2021.\n\n\nSummary\nThanks to STAC, cloud-optimized GeoTIFFs, and GDAL being capable of reading imagery from cloud storage directly, moving to cloud-based analysis workflows without downloading any imagery from portals become a lot easier and more efficient. Whether or not this is the right approach depends a lot on particular applications. In some cases (e.g. when having access to institutional HPC resources while applying very complex models on small areas of interest), it might still be appropriate to download the data once. The gdalcubes package still can help as an interface to downloading analysis-ready data cubes instead of image files from portals."
  },
  {
    "objectID": "source/tutorials/vignettes/gc01_MODIS.html",
    "href": "source/tutorials/vignettes/gc01_MODIS.html",
    "title": "1. Creating data cubes from local MODIS imagery",
    "section": "",
    "text": "The gdalcubes package aims at making the work with large collections of Earth observation (EO) imagery (e.g. from Sentinel 2) easier and faster. Typical challenges with these data such as overlapping images, different spatial resolutions of spectral bands, irregular temporal sampling, and different coordinate reference systems are abstracted away from users by reading the data as a raster data cube and letting users define the shape of the cube (spatiotemporal extent, resolution, and spatial reference system). Working with EO imagery then becomes more interactive: going from “try method X on low resolution and get the result asap” to “apply the final method to the full resolution dataset over night” becomes straightforward.\nThis brief vignette illustrates basic ideas of the package. We will use satellite imagery from the Moderate Resolution Imaging Spectroradiometer (MODIS) that is small enough to process even on older machines. The imagery comes as a set of HDF4 files. We assume that you have successfully installed the gdalcubes package. Please also make sure that your GDAL installation supports the HDF4 driver (e.g. with gdalcubes_gdalformats()).\nIn the following, we will follow a simple workflow by"
  },
  {
    "objectID": "source/tutorials/vignettes/gc01_MODIS.html#aggregation-and-resampling",
    "href": "source/tutorials/vignettes/gc01_MODIS.html#aggregation-and-resampling",
    "title": "1. Creating data cubes from local MODIS imagery",
    "section": "Aggregation and resampling",
    "text": "Aggregation and resampling\nBesides the spatiotemporal extent, the resolution and the spatial reference system, the data cube view contains the two important parameters aggregation and resampling. Resampling here refers to how images are resampled in space during the reprojection, scaling, and cropping operations. The temporal aggregation method defines how values for the same cell from different images are combined in the target cube. For example, a data cube with monthly temporal resolution will contain values from multiple images. Currently, possible values are first, last, min, max, mean, and median. These functions are evaluated per data cube pixel."
  },
  {
    "objectID": "source/tutorials/vignettes/gc01_MODIS.html#export-data-cubes-to-files",
    "href": "source/tutorials/vignettes/gc01_MODIS.html#export-data-cubes-to-files",
    "title": "1. Creating data cubes from local MODIS imagery",
    "section": "Export data cubes to files",
    "text": "Export data cubes to files\nReplacing the call to plot() with write_ncdf(), or write_tif() would write the result as NetCDF or GeoTIFF files to disk. While write_ncdf() always produces a single file, write_tif() produces one file per time slice and the time is automatically added to the provided output filename. Both functions support compression and modifying the data type to save disk space."
  },
  {
    "objectID": "source/tutorials/vignettes/gc01_MODIS.html#parallel-processing",
    "href": "source/tutorials/vignettes/gc01_MODIS.html#parallel-processing",
    "title": "1. Creating data cubes from local MODIS imagery",
    "section": "Parallel processing",
    "text": "Parallel processing\ngdalcubes supports parallel processing of data cube operations. Calling gdalcubes_options(parallel = n) will tell all following data cube operations to use up to n parallel processes. Notice that worker processes are assigned to chunks of the data cube and the true number of processes can be lower if there are less than n chunks."
  },
  {
    "objectID": "source/tutorials/vignettes/gc03_ML_training_data.html",
    "href": "source/tutorials/vignettes/gc03_ML_training_data.html",
    "title": "3. Extracting training data for machine learning models",
    "section": "",
    "text": "Machine learning models for land cover classification, change detection, spatiotemporal prediction, and similar tasks in most cases need a large number of observations for training.\nThis vignette will demonstrate how training data from satellite image collections can be extracted for typical tasks including:\nOne function that can do all of this is extract_geom(), which is similar to the st_extract() function from the stars package and the extract() function from the raster and terra packages."
  },
  {
    "objectID": "source/tutorials/vignettes/gc03_ML_training_data.html#the-extract_geom-function",
    "href": "source/tutorials/vignettes/gc03_ML_training_data.html#the-extract_geom-function",
    "title": "3. Extracting training data for machine learning models",
    "section": "The extract_geom() function",
    "text": "The extract_geom() function\nGiven a data cube and any simple feature geometries as an sf object, the extract_geom() function can be used as a general method to extract data cube pixel values at irregular locations. extract_geom() returns a data.frame with columns for feature identifiers (FIDs, often row numbers of the sf object), time, and bands / variables of the data cube. Each row represents the data cube values of one pixel relating to the feature given by the FID column. For anything other than simple point geometries (e.g. POLYGON, LINESTRING, MULTIPOINT, and similar), the result may contain multiple rows per feature. In these cases, it is possible to apply an aggregation function to compute mean, median or similar summary statistics over features.\nextract_geom() drops any pixels with missing values only. Hence, if a feature is outside the extent of the data cube, or all pixels of a feature are NA due to clouds or unavailability of images, these pixels will not be included in the result. In contrast, if the input features contain overlapping geometries, pixels may be included several times (with different values in the FID column).\nFor multitemporal cubes, the full time series of pixels relating to the features is returned by default, leading to multiple rows with different time values. It is possible to specify the date/time of features using either an available time column from the sf object by name (argument time_column), or as an additional Date, POSIXt, or character vector with length corresponding to the number of features (argument datetime). In this case, only data cube pixels related to the time value of features is returned in the result instead of the full time series.\nCompared to the extract() function from the raster and terra packages, extract_geom() is a little less flexible. For example, it is not possible to derive fractions of pixels covered by the features to compute weighted aggregations or similar."
  },
  {
    "objectID": "source/tutorials/vignettes/gc03_ML_training_data.html#extracting-pixel-values-and-summary-statistics-from-spatial-polygons",
    "href": "source/tutorials/vignettes/gc03_ML_training_data.html#extracting-pixel-values-and-summary-statistics-from-spatial-polygons",
    "title": "3. Extracting training data for machine learning models",
    "section": "1. Extracting pixel values and summary statistics from spatial polygons",
    "text": "1. Extracting pixel values and summary statistics from spatial polygons\nAs a small example how to prepare training data for simple classification tasks, we use a labeled land cover polygon dataset covering the city of Muenster, Germany, which can be downloaded from https://uni-muenster.sciebo.de/s/fgyaomOJxSd93H8/download. This GeoPackage dataset contains spatial polygons with a column class representing land cover. We can directly download and plot the features using the sf package:\n\nlibrary(sf)\n## Linking to GEOS 3.10.1, GDAL 3.4.0, PROJ 8.2.0; sf_use_s2() is TRUE\ntraining_sites = read_sf(\"https://uni-muenster.sciebo.de/s/fgyaomOJxSd93H8/download\")\nplot(training_sites, axes = TRUE, key.pos = 1)\n\n\n\n\n\n\n\n\nThis is a rather small toy dataset but since the features are polygons, they already cover quite a few 10m pixels from Sentinel-2 imagery. As a first step to extract Sentinel-2 values within the polygons, we create a (virtual) data cube from Sentinel-2 data on Amazon Web Services (see previous vignette). Since the data is openly available, we can still work locally and do not need to run a machine on AWS (though this would be much faster for larger polygon datasets).\nAs our area of interest, we use the extent of the polygon dataset and look for (cloud-free) observations in July, 2021. To find corresponding images, we use the rstac package and query from the Sentinel-2 cloud-optimized GeoTIFF collection on AWS.\n\nbbox = st_bbox(training_sites) \nbbox\n##      xmin      ymin      xmax      ymax \n##  7.576647 51.874603  7.673467 51.977592\nlibrary(rstac)\ns = stac(\"https://earth-search.aws.element84.com/v0\")\n  items = s |>\n    stac_search(collections = \"sentinel-s2-l2a-cogs\",\n                bbox = c(bbox[\"xmin\"],bbox[\"ymin\"],\n                         bbox[\"xmax\"],bbox[\"ymax\"]), \n                datetime = \"2021-07-01/2021-07-31\") |>\n    post_request() |> items_fetch(progress = FALSE)\n  length(items$features)\n## [1] 26\n\nTo filter by cloud coverage and create a gdalcubes image collection object, we apply stac_image_collection() on the resulting list of 26 images.\n\nlibrary(gdalcubes)\ns2_collection = stac_image_collection(items$features, property_filter = function(x) {x[[\"eo:cloud_cover\"]] < 20})\ns2_collection\n## Image collection object, referencing 5 images with 18 bands\n## Images:\n##                       name     left      top   bottom    right\n## 1 S2B_32ULC_20210723_0_L2A 6.946499 52.34304 51.34525 7.704564\n## 2 S2B_32UMC_20210723_0_L2A 7.531544 52.35038 51.35444 9.143276\n## 3 S2A_32ULC_20210718_0_L2A 6.952812 52.34304 51.34536 7.704564\n## 4 S2A_32UMC_20210718_0_L2A 7.531544 52.35038 51.35444 9.143276\n## 5 S2B_32ULC_20210703_0_L2A 6.948221 52.34304 51.34528 7.704564\n##              datetime        srs\n## 1 2021-07-23T10:36:40 EPSG:32632\n## 2 2021-07-23T10:36:36 EPSG:32632\n## 3 2021-07-18T10:36:41 EPSG:32632\n## 4 2021-07-18T10:36:37 EPSG:32632\n## 5 2021-07-03T10:36:39 EPSG:32632\n## \n## Bands:\n##            name offset scale unit nodata image_count\n## 1           B01      0     1                       5\n## 2           B02      0     1                       5\n## 3           B03      0     1                       5\n## 4           B04      0     1                       5\n## 5           B05      0     1                       5\n## 6           B06      0     1                       5\n## 7           B07      0     1                       5\n## 8           B08      0     1                       5\n## 9           B09      0     1                       5\n## 10          B11      0     1                       5\n## 11          B12      0     1                       5\n## 12          B8A      0     1                       5\n## 13 overview:B02      0     1                       5\n## 14 overview:B03      0     1                       5\n## 15 overview:B04      0     1                       5\n## 16   visual:B02      0     1                       5\n## 17   visual:B03      0     1                       5\n## 18   visual:B04      0     1                       5\n\nThe collection contains five images only. However, we now create a rather large data cube with spatial extent from the image collection and 10m spatial resolution. Notice that this data cube is not downloaded but only created virtually, as a proxy object that knows where the corresponding images are located and what to do with the data when needed. In the example below, we use the visible RGB and the near infrared bands and add the NDVI vegetation index as a data cube band. Notice that we do not use a per-pixel cloud mask here.\n\nv = cube_view(extent=s2_collection, dt=\"P1M\", dx=10, dy=10, srs=\"EPSG:3857\", \n                      aggregation = \"median\", resampling = \"bilinear\")\n\nraster_cube(s2_collection, v) |> # no mask\n  select_bands(c(\"B02\",\"B03\",\"B04\",\"B08\")) |>\n  apply_pixel(\"(B08-B04)/(B08+B04)\", \"NDVI\", keep_bands = TRUE) -> ms_cube\nms_cube\n## A GDAL data cube proxy object\n## \n## Dimensions:\n##                low             high count pixel_size chunk_size\n## t       2021-07-01       2021-07-31     1        P1M          1\n## y 6682590.54960759 6863730.54960759 18114         10       1024\n## x 773277.779989172 1017827.77998917 24455         10       1024\n## \n## Bands:\n##   name offset scale nodata unit\n## 1  B02      0     1    NaN     \n## 2  B03      0     1    NaN     \n## 3  B04      0     1    NaN     \n## 4  B08      0     1    NaN     \n## 5 NDVI      0     1    NaN\n\nThe cube has 24455 x 18114 spatial pixels, which would sum to a GeoTIFF file of several gigabytes (depending on data type and compression), although the area of interest is quite small and we are only interested in a few pixels in the polygons. Fortunately, extract_geom() reduces unnecessary data reads to a large extent, meaning that even if we would use a data cube for whole Germany at 10m resolution, it would only read blocks of the data covering our area of interest, and simply ignore other parts.\n\nx = extract_geom(ms_cube, training_sites)\nnrow(x)\n## [1] 12744\nhead(x)\n##   FID       time      B02      B03      B04      B08      NDVI\n## 1   7 2021-07-01 312.3927 454.4502 300.3140 4142.701 0.8648152\n## 2   7 2021-07-01 314.5155 445.5853 303.2982 4160.428 0.8641054\n## 3   7 2021-07-01 320.6820 445.7498 307.1665 4165.566 0.8626493\n## 4   7 2021-07-01 313.4379 459.7528 307.8308 4106.122 0.8605192\n## 5   7 2021-07-01 318.1167 446.6952 311.6203 4140.536 0.8600138\n## 6   7 2021-07-01 324.3806 444.3545 312.0102 4149.988 0.8601478\n\nAs expected, the result contains multiple rows per polygon (because polygons cover multiple pixels). To compute summary statistics per polygon, we can provide a function as the FUN argument:\n\nx = extract_geom(ms_cube, training_sites, FUN = median)\n#x = extract_geom(ms_cube, training_sites)#), FUN = median)\nx\n##    FID       time       B02       B03       B04       B08        NDVI\n## 1    1 2021-07-01  266.2039  389.5117  218.2514  237.6531  0.04524603\n## 2    2 2021-07-01  266.8352  368.6943  223.0690  257.1879  0.07006745\n## 3    3 2021-07-01  642.4923  884.2024  987.9066 2134.6692  0.36731547\n## 4    4 2021-07-01  339.1859  519.5446  314.6939 4237.5824  0.86212147\n## 5    5 2021-07-01  742.0260 1048.1800 1432.2655 2591.4463  0.28675374\n## 6    6 2021-07-01  554.2089  829.8890  866.6759 2255.3755  0.44919218\n## 7    7 2021-07-01  427.3777  596.9655  485.9907 3970.5424  0.78361568\n## 8    8 2021-07-01 1181.4101 1277.0147 1335.0851 1752.2424  0.10188053\n## 9    9 2021-07-01  858.2257  990.5626 1143.5540 1573.5704  0.14296265\n## 10  10 2021-07-01 1361.9271 1536.8561 1653.4901 2186.0671  0.09075880\n## 11  11 2021-07-01  721.8104  867.5908 1001.1942 1868.7402  0.25241746\n## 12  12 2021-07-01  269.9440  405.1574  237.6765 3493.1907  0.87339904\n## 13  13 2021-07-01  288.0669  424.8431  261.3002 3458.0253  0.86101114\n## 14  14 2021-07-01  277.8512  412.7048  245.6007 4087.6796  0.88691074\n## 15  15 2021-07-01  599.5534  821.2706  498.7003  260.6612 -0.30120940\n## 16  16 2021-07-01  538.8088  758.5329  407.5442  311.8426 -0.15754052\n\nTo combine the extracted data cube values with the original sf objects including the geometries, the merge() function can be used. merge() performs table join operations on common columns (e.g. IDs). We therefore first need to add an FID column to the features and then join both tables by their FID columns. Notice that by default, this is performing an inner join, i.e. rows with FIDs that only exist in one table will be dropped. Alternatively, we can set all.x=TRUE to make sure that our result contains all features from the original dataset (left outer join). Below, we combine the tables, drop the geometries and order by NDVI, showing a clear relation between class and NDVI.\n\nx = x[order(x$NDVI,decreasing = T),]\ntraining_sites$FID = rownames(training_sites)\ntrn_df = sf::st_drop_geometry(merge(training_sites, x, by = \"FID\"))\ntrn_df[order(trn_df$NDVI, decreasing = TRUE),]\n##    FID       class       time       B02       B03       B04       B08\n## 6   14      forest 2021-07-01  277.8512  412.7048  245.6007 4087.6796\n## 4   12      forest 2021-07-01  269.9440  405.1574  237.6765 3493.1907\n## 11   4 agriculture 2021-07-01  339.1859  519.5446  314.6939 4237.5824\n## 5   13      forest 2021-07-01  288.0669  424.8431  261.3002 3458.0253\n## 14   7 agriculture 2021-07-01  427.3777  596.9655  485.9907 3970.5424\n## 13   6 agriculture 2021-07-01  554.2089  829.8890  866.6759 2255.3755\n## 10   3 agriculture 2021-07-01  642.4923  884.2024  987.9066 2134.6692\n## 12   5 agriculture 2021-07-01  742.0260 1048.1800 1432.2655 2591.4463\n## 3   11       urban 2021-07-01  721.8104  867.5908 1001.1942 1868.7402\n## 16   9       urban 2021-07-01  858.2257  990.5626 1143.5540 1573.5704\n## 15   8       urban 2021-07-01 1181.4101 1277.0147 1335.0851 1752.2424\n## 2   10       urban 2021-07-01 1361.9271 1536.8561 1653.4901 2186.0671\n## 9    2       water 2021-07-01  266.8352  368.6943  223.0690  257.1879\n## 1    1       water 2021-07-01  266.2039  389.5117  218.2514  237.6531\n## 8   16       water 2021-07-01  538.8088  758.5329  407.5442  311.8426\n## 7   15       water 2021-07-01  599.5534  821.2706  498.7003  260.6612\n##           NDVI\n## 6   0.88691074\n## 4   0.87339904\n## 11  0.86212147\n## 5   0.86101114\n## 14  0.78361568\n## 13  0.44919218\n## 10  0.36731547\n## 12  0.28675374\n## 3   0.25241746\n## 16  0.14296265\n## 15  0.10188053\n## 2   0.09075880\n## 9   0.07006745\n## 1   0.04524603\n## 8  -0.15754052\n## 7  -0.30120940"
  },
  {
    "objectID": "source/tutorials/vignettes/gc03_ML_training_data.html#time-series-extraction-from-spatial-points",
    "href": "source/tutorials/vignettes/gc03_ML_training_data.html#time-series-extraction-from-spatial-points",
    "title": "3. Extracting training data for machine learning models",
    "section": "2. Time series extraction from spatial points",
    "text": "2. Time series extraction from spatial points\nIn the next example, we use MODIS land surface temperature measurements over Europe (see first vignette) and extract time series in London, Paris, and Barcelona. For each city, we define some points in the urban center as well as in the rural surrounding areas.\nWe start with downloading the MODIS data, if needed:\n\ndest_dir = tempdir()\nif (!dir.exists(file.path(dest_dir,\"MOD11A2\"))) {\n  options(timeout = max(1800, getOption(\"timeout\")))\n  download.file(\"https://uni-muenster.sciebo.de/s/eP9E6OIkQbXrmsY/download\", destfile=file.path(dest_dir, \"MOD11A2.zip\"),mode = \"wb\")\n  unzip(file.path(dest_dir, \"MOD11A2.zip\"), exdir = file.path(dest_dir,\"MOD11A2\"))\n  unlink(file.path(dest_dir, \"MOD11A2.zip\"))\n}\n\nNext, we build a gdalcubes image collection object:\n\nlibrary(gdalcubes)\nfiles = list.files(file.path(dest_dir,\"MOD11A2\"), pattern=\".hdf$\", full.names = TRUE)\nMODIS.collection = create_image_collection(files, \"MxD11A2\")\nMODIS.collection\n## Image collection object, referencing 140 images with 8 bands\n## Images:\n##                                                                name      left\n## 1 /tmp/Rtmps3iUD7/MOD11A2/MOD11A2.A2018001.h17v03.006.2018011145329 -20.00000\n## 2 /tmp/Rtmps3iUD7/MOD11A2/MOD11A2.A2018001.h17v04.006.2018011145438 -15.55724\n## 3 /tmp/Rtmps3iUD7/MOD11A2/MOD11A2.A2018001.h18v03.006.2018011145428   0.00000\n## 4 /tmp/Rtmps3iUD7/MOD11A2/MOD11A2.A2018001.h18v04.006.2018011145326   0.00000\n## 5 /tmp/Rtmps3iUD7/MOD11A2/MOD11A2.A2018009.h17v03.006.2018018034330 -20.00000\n## 6 /tmp/Rtmps3iUD7/MOD11A2/MOD11A2.A2018009.h17v04.006.2018018034246 -15.55724\n##   top bottom    right            datetime\n## 1  60     50  0.00000 2018-01-01T00:00:00\n## 2  50     40  0.00000 2018-01-01T00:00:00\n## 3  60     50 20.00000 2018-01-01T00:00:00\n## 4  50     40 15.55724 2018-01-01T00:00:00\n## 5  60     50  0.00000 2018-01-09T00:00:00\n## 6  50     40  0.00000 2018-01-09T00:00:00\n##                                                                                                                                                                                                                                                                                                                                                                                                                                        srs\n## 1 PROJCS[\"unnamed\",GEOGCS[\"Unknown datum based upon the custom spheroid\",DATUM[\"Not specified (based on custom spheroid)\",SPHEROID[\"Custom spheroid\",6371007.181,0]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]]],PROJECTION[\"Sinusoidal\"],PARAMETER[\"longitude_of_center\",0],PARAMETER[\"false_easting\",0],PARAMETER[\"false_northing\",0],UNIT[\"Meter\",1],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH]]\n## 2 PROJCS[\"unnamed\",GEOGCS[\"Unknown datum based upon the custom spheroid\",DATUM[\"Not specified (based on custom spheroid)\",SPHEROID[\"Custom spheroid\",6371007.181,0]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]]],PROJECTION[\"Sinusoidal\"],PARAMETER[\"longitude_of_center\",0],PARAMETER[\"false_easting\",0],PARAMETER[\"false_northing\",0],UNIT[\"Meter\",1],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH]]\n## 3 PROJCS[\"unnamed\",GEOGCS[\"Unknown datum based upon the custom spheroid\",DATUM[\"Not specified (based on custom spheroid)\",SPHEROID[\"Custom spheroid\",6371007.181,0]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]]],PROJECTION[\"Sinusoidal\"],PARAMETER[\"longitude_of_center\",0],PARAMETER[\"false_easting\",0],PARAMETER[\"false_northing\",0],UNIT[\"Meter\",1],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH]]\n## 4 PROJCS[\"unnamed\",GEOGCS[\"Unknown datum based upon the custom spheroid\",DATUM[\"Not specified (based on custom spheroid)\",SPHEROID[\"Custom spheroid\",6371007.181,0]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]]],PROJECTION[\"Sinusoidal\"],PARAMETER[\"longitude_of_center\",0],PARAMETER[\"false_easting\",0],PARAMETER[\"false_northing\",0],UNIT[\"Meter\",1],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH]]\n## 5 PROJCS[\"unnamed\",GEOGCS[\"Unknown datum based upon the custom spheroid\",DATUM[\"Not specified (based on custom spheroid)\",SPHEROID[\"Custom spheroid\",6371007.181,0]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]]],PROJECTION[\"Sinusoidal\"],PARAMETER[\"longitude_of_center\",0],PARAMETER[\"false_easting\",0],PARAMETER[\"false_northing\",0],UNIT[\"Meter\",1],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH]]\n## 6 PROJCS[\"unnamed\",GEOGCS[\"Unknown datum based upon the custom spheroid\",DATUM[\"Not specified (based on custom spheroid)\",SPHEROID[\"Custom spheroid\",6371007.181,0]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]]],PROJECTION[\"Sinusoidal\"],PARAMETER[\"longitude_of_center\",0],PARAMETER[\"false_easting\",0],PARAMETER[\"false_northing\",0],UNIT[\"Meter\",1],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH]]\n## [ omitted 134 images ] \n## \n## Bands:\n##              name offset scale unit     nodata image_count\n## 1   DAY_VIEW_TIME   0.00 0.100  hrs 255.000000         140\n## 2         EMIS_31   0.49 0.002        0.000000         140\n## 3         EMIS_32   0.49 0.002        0.000000         140\n## 4         LST_DAY   0.00 0.020    K   0.000000         140\n## 5       LST_NIGHT   0.00 0.020    K   0.000000         140\n## 6 NIGHT_VIEW_TIME   0.00 0.100  hrs 255.000000         140\n## 7          QC_DAY   0.00 1.000                         140\n## 8        QC_NIGHT   0.00 1.000                         140\n\nNow, we create some sample points from hand, where we want to extract the time series of land surface temperature measurements. We convert the created data.frame to an sf object using st_as_sf().\n\n# create points from hand...\nx = c(2.347821, 2.3062300, 2.3802715, 2.3562110, 2.473618884, 2.2717150, 1.9978976)\ny = c(48.853590, 48.8422630, 48.8680197, 48.8901057, 48.670428823, 49.0335277, 48.6987311)\nname = c(\"PARIS_URBAN_1\", \"PARIS_URBAN_2\", \"PARIS_URBAN_3\", \"PARIS_URBAN_4\", \"PARIS_RURAL_1\", \"PARIS_RURAL_2\", \"PARIS_RURAL_3\")\n\nx = c(x, -0.1004895, -0.1018785, -0.1250968, -0.0810867, 0.0490169, -0.461243207, -0.2806675, -0.3103141)\ny = c(y, 51.4941646, 51.4653369, 51.5268144, 51.5109185, 51.6569130, 51.589319769, 51.2611309, 51.6595132)\nname = c(name, \"LONDON_URBAN_1\", \"LONDON_URBAN_2\", \"LONDON_URBAN_3\",\"LONDON_URBAN_4\", \"LONDON_RURAL_1\", \"LONDON_RURAL_2\", \"LONDON_RURAL_3\", \"LONDON_RURAL_4\")\n\nx = c(x,2.1599154, 2.19904748, 2.2230235, 2.1670374, 2.2290286, 1.9649098)\ny = c(y, 41.3879580, 41.42672217, 41.4274755, 41.4556412, 41.4823003, 41.3235823)\nname = c(name, \"BARCELONA_URBAN_1\", \"BARCELONA_URBAN_2\", \"BARCELONA_URBAN_3\", \"BARCELONA_RURAL_1\", \"BARCELONA_RURAL_2\", \"BARCELONA_RURAL_3\")\n\npts = data.frame(x = x, y = y, name = name)\n\nlibrary(sf)\nsf = st_as_sf(pts, coords = c(\"x\",\"y\"), crs = st_crs(4326))\n\nIn the next step, we build a 1km 8-daily cube over Europe, convert the measurements to degree Celsius and extract the time series using the extract_geom() function.\n\ngdalcubes_options(parallel = 8)\nv = cube_view(extent=MODIS.collection, srs = \"EPSG:3035\", dx = 1000, dy = 1000, dt = \"P8D\")\nraster_cube(MODIS.collection, v)  |>\n  select_bands(c(\"LST_DAY\")) |>\n  apply_pixel(\"LST_DAY * 0.02 - 273.15\", \"LST\") |>\n  extract_geom(sf) -> result\nhead(result, n = 40)\n##    FID       time   LST\n## 1   16 2018-01-01 13.33\n## 2   17 2018-01-01 13.63\n## 3   18 2018-01-01 13.33\n## 4   19 2018-01-01 12.15\n## 5   20 2018-01-01 14.73\n## 6   21 2018-01-01 15.91\n## 7   16 2018-01-09 12.23\n## 8   17 2018-01-09 12.15\n## 9   18 2018-01-09 12.07\n## 10  19 2018-01-09 10.19\n## 11  20 2018-01-09  9.83\n## 12  21 2018-01-09  9.81\n## 13  16 2018-01-17 17.13\n## 14  17 2018-01-17 16.87\n## 15  18 2018-01-17 16.03\n## 16  19 2018-01-17 14.03\n## 17  20 2018-01-17 13.65\n## 18  21 2018-01-17 13.81\n## 19   1 2018-01-09  6.83\n## 20   2 2018-01-09  6.29\n## 21   3 2018-01-09  7.37\n## 22   4 2018-01-09  7.67\n## 23   5 2018-01-09  5.57\n## 24   6 2018-01-09  0.79\n## 25   7 2018-01-09  6.33\n## 26  16 2018-02-02  9.21\n## 27  17 2018-02-02  5.43\n## 28  18 2018-02-02  7.33\n## 29  19 2018-02-02  7.39\n## 30  20 2018-02-02  8.41\n## 31  21 2018-02-02  7.15\n## 32  16 2018-01-25 15.11\n## 33  17 2018-01-25 14.85\n## 34  18 2018-01-25 15.11\n## 35  19 2018-01-25 13.51\n## 36  20 2018-01-25 12.91\n## 37  21 2018-01-25 11.67\n## 38  16 2018-02-18 14.05\n## 39  17 2018-02-18 15.11\n## 40  18 2018-02-18 16.17\n\nThe result contains FID, time, and LST as columns and we can combine the data with the original sf object with merge():\n\nsf$FID = rownames(sf)\ndf = merge(sf, result, by = \"FID\")\n\nWe can plot the time series as in the example below, showing some differences between the rural and the urban locations for Paris and Barcelona.\n\nlibrary(ggplot2)\n\ndf |>\n  dplyr::filter(startsWith(name, \"PARIS\")) |>\n  ggplot( aes(x = as.Date(time), y = LST, color = FID, group = FID)) +\n  geom_line() + geom_point() + ggtitle(\"Paris\") + xlab(\"Time\") + ylab(\"LST [K]\")\n\n\n\n\n\n\n\n  \ndf |>\n  dplyr::filter(startsWith(name, \"BARCELONA\")) |>\n  ggplot( aes(x = as.Date(time), y = LST, color = FID, group = FID)) +\n  geom_line() + geom_point()  + ggtitle(\"Barcelona\") + xlab(\"Time\") + ylab(\"LST [K]\")\n\n\n\n\n\n\n\n\nA similar workflow can e.g. be used to create patterns for time series classification using the dtwSat package."
  },
  {
    "objectID": "source/tutorials/vignettes/gc03_ML_training_data.html#combining-satellite-observations-with-in-situ-observations",
    "href": "source/tutorials/vignettes/gc03_ML_training_data.html#combining-satellite-observations-with-in-situ-observations",
    "title": "3. Extracting training data for machine learning models",
    "section": "3. Combining satellite observations with in-situ observations",
    "text": "3. Combining satellite observations with in-situ observations\nThe previous examples have used spatial features without time information. For applications where interest lies in the combination of satellite-based and in-situ observations or adding satellite observations to movement data such as animal tracks, time information is available for the spatial features (mostly points) and should be considered in the analysis. In this example, we will use primary data from the European Land Use and Coverage Area frame Survey (LUCAS) containing land cover point samples from 2018. The data can be downloaded as country-wise CSV files (see here). We will use observations over Germany, subset some specific crop types and combine the points with Sentinel-2 NDVI observations.\nAs a first step, we load the data, remove rows with missing coordinates and convert the data.frame to an sf object. ::: {.cell}\nx = read.csv(\"https://ec.europa.eu/eurostat/cache/lucas/DE_2018_20200213.CSV\")\nx = x[-which(is.na(x$TH_LAT) | is.na(x$TH_LONG)),]\nx = st_as_sf(x, coords = c(\"TH_LONG\", \"TH_LAT\"), crs = \"EPSG:4326\")\n:::\nAfterwards we extract the observation date from points and add it as a new column t.\n\nx$t = as.Date(x$SURVEY_DATE, format = \"%d/%m/%y\") \n\nThe dominant land cover type is encoded in the LC1 column, where a letter indicates the major class (e.g., forest, agriculture, water, or urban) that is followed by a number to identify more specific types (e.g. wheat, barley, oat, and others for class agriculture). Here, we are interested in four different crop types (“common wheat”, “barley”, “rye”, and “maize”). Below, we select corresponding points and randomly sample 100 points for each type and add common names to the relevant land cover types.\n\nx[startsWith(x$LC1, c(\"B11\", \"B13\", \"B14\", \"B16\")), c(\"LC1\",\"t\")] |>\n  dplyr::group_by(LC1) |>\n  dplyr::slice_sample(n = 100) -> training\n\nnames = c(\"B11\" = \"Common Wheat\",\n          \"B13\" = \"Barley\",\n          \"B14\" = \"Rye\",\n          \"B16\" = \"Maize\")\n\ntraining$LC1_NAME = names[training$LC1]\ntable(training$LC1_NAME)\n## \n##       Barley Common Wheat        Maize          Rye \n##          100          100          100          100\nplot(training[,\"LC1_NAME\"], key.pos = 1)\n\n\n\n\n\n\n\n\nThe result contains 400 samples with observations at different dates. To add NDVI measurements to the data, we now request available Sentinel-2 images from the Sentinel-2 cloud-optimized GeoTIFF collection on AWS within the area and time of interest using rstac.\n\nbbox = st_bbox(training) \nbbox\n##      xmin      ymin      xmax      ymax \n##  6.223914 47.753108 14.595403 54.885928\nlibrary(rstac)\ns = stac(\"https://earth-search.aws.element84.com/v0\")\nitems = s |>\n  stac_search(collections = \"sentinel-s2-l2a-cogs\",\n              bbox = c(bbox[\"xmin\"],bbox[\"ymin\"],\n                       bbox[\"xmax\"],bbox[\"ymax\"]), \n              datetime = \"2018-04-01/2018-12-31\") |>\n  post_request() |> items_fetch(progress = FALSE)\n\nThe result contains 9486 images. Next, we load the gdalcubes package, create an image collection object from the STAC result and at the same time filter images by cloud cover.\n\nlibrary(gdalcubes)\ns2_collection = stac_image_collection(items$features, property_filter = function(x) {x[[\"eo:cloud_cover\"]] < 10})\n\nThe collection contains 2387 remaining images with less than 10% cloud cover. Now we create a data cube at original 10m spatial resolution and use the revisit time (5 days) as temporal resolution. We also derive NDVI measurements and drop unneeded bands on-the-fly.\n\nv = cube_view(extent=s2_collection, dt=\"P5D\", dx=10, dy=10, srs=\"EPSG:3857\", \n              aggregation = \"median\", resampling = \"nearest\")\n\nraster_cube(s2_collection, v, chunking = c(1,512,512)) |> \n  select_bands(c(\"B04\",\"B08\")) |>\n  apply_pixel(\"(B08-B04)/(B08+B04)\", \"NDVI\") -> cube\ncube\n## A GDAL data cube proxy object\n## \n## Dimensions:\n##                low             high  count pixel_size chunk_size\n## t       2018-04-01       2018-12-31     55        P5D          1\n## y  5908460.4569991  7370990.4569991 146253         10        512\n## x 503996.201529035 1686796.20152904 118280         10        512\n## \n## Bands:\n##   name offset scale nodata unit\n## 1 NDVI      0     1    NaN\n\nNotice that the selection of resolution here has some important implications:\n\nSpatially larger pixels increase the likelihood that the pixel corresponding with a point contains different land cover classes, a moderate increasement, however, may still be helpful to include a bit of spatial context and reduce noise.\nUsing a lower temporal resolution (e.g. in a monthly aggregated cube) reduces the amount of missing data (e.g. due to clouds) but of course decreases the time accuracy of measurements.\n\nTo extract the samples from the cube, we call extract_geom(), provide the training data and the name of the time column. Please notice that we use quite a few parallel worker instances (even more than the number of cores of the machine) to make downloading the data a little faster. Although the extraction will only need to download smaller patches of images that intersect (in space and time) with the points, it is still the most time consuming part of the extraction when working locally (not on AWS, where the data is stored). As a result, the extraction might take a few minutes on your local machine.\n\ngdalcubes_options(parallel = 12)\ncubex <- extract_geom(cube,training, time_column = \"t\")\nnrow(cubex)\n## [1] 200\n\nOnce available, notice that the number of results is smaller than the number of selected sample points simply because for some points there was no (cloud-free) image available. We can now merge the results with the point features and plot the NDVI by time for the different crop types.\n\nsf = training\nsf$FID = rownames(sf)\ndf = merge(sf, cubex, by = \"FID\")\n\nlibrary(ggplot2)\nlibrary(cowplot)\np = lapply(names, function(x) {\n  df |>\n    dplyr::filter(LC1_NAME == x) |>\n    ggplot( aes(x = as.Date(t), y = NDVI)) +\n    geom_smooth(method = \"loess\") +\n    geom_point(size = 2) + \n    ylim(c(0,1)) + xlim(c(as.Date(\"2018-05-01\"),as.Date(\"2018-09-30\"))) + \n    xlab(\"Time\") + ylab(\"NDVI\")  + ggtitle(x)\n})\nplot_grid(plotlist = p)\n## `geom_smooth()` using formula 'y ~ x'\n## `geom_smooth()` using formula 'y ~ x'\n## `geom_smooth()` using formula 'y ~ x'\n## `geom_smooth()` using formula 'y ~ x'"
  },
  {
    "objectID": "source/tutorials/vignettes/gc03_ML_training_data.html#further-options-to-extract-data",
    "href": "source/tutorials/vignettes/gc03_ML_training_data.html#further-options-to-extract-data",
    "title": "3. Extracting training data for machine learning models",
    "section": "Further options to extract data",
    "text": "Further options to extract data\nNotice that extraction with extract_geom() is not the only possible way to extract pixels or time series from data cubes. For smaller amounts of samples, extraction can be performed entirely using the available operations crop(), slice_time(), slice_space(), or the general selection operator [. For example, extraction of a few spatiotetemporal points on the LUCAS data (see last example) can also achieved by iterating over all samples and extracting a single point using cube[x$geometry, x$t].\n\nNDVI = NULL\nfor (i in 1:nrow(training)) {\n  y = cube[x$geometry[i],x$t[i]]\n  ndvi_pixel <- as_array(y)\n  NDVI = c(NDVI, as.vector(ndvi_pixel))\n}\n\nThere are of course other applications that require a different preparation of training data. As an example, gdalcubes can also be used for the creation of spatial (or even spatiotemporal) blocks in order to apply convolutional neural networks for object detection, or segmentation tasks."
  },
  {
    "objectID": "source/tutorials/Landsat8_getting_started/Landsat8_getting_started.html",
    "href": "source/tutorials/Landsat8_getting_started/Landsat8_getting_started.html",
    "title": "Introduction to gdalcubes using local Landsat 8 imagery",
    "section": "",
    "text": "This document is based on the tutorial “Processing Large Satellite Image Collections as Data Cubes with the gdalcubes R package”, presented ad OpenGeoHub Summer School 2019 (see https://github.com/appelmar/opengeohub_summerschool2019)."
  },
  {
    "objectID": "source/tutorials/Landsat8_getting_started/Landsat8_getting_started.html#the-problem",
    "href": "source/tutorials/Landsat8_getting_started/Landsat8_getting_started.html#the-problem",
    "title": "Introduction to gdalcubes using local Landsat 8 imagery",
    "section": "The Problem",
    "text": "The Problem\nRaw satellite imagery is mostly distributed as collection of files, whether on download portals of space agencies, or in cloud computing environments (Amazon Web Services, Google Cloud, …). If we want to analyze more than a single image, or even images from multiple satellites, we quickly run into the following challenges:\n\nspectral bands at different spatial resolutions\nspatially overlapping images\nirregular time series for pixels from different tiles (or in overlapping areas)\ndifferent spatial reference systems of images\ndifferent data formats and structures\n\nTo do time series analysis, process larger areas, and / or combine datasets from different sensors / satellites, we first must restructure our data, e.g. as a data cube with a single spatial reference system, regular pixel sizes, both in time and in space.\n\nNotice that what we call cube is actually not really a cube. It has (up to) four dimensions, and the lengths of the dimensions may be different. Therefore, four dimensional regular raster data cubes also cover simple time series, multiband time series, grayscale images, multispectral images, and time-series of images."
  },
  {
    "objectID": "source/tutorials/Landsat8_getting_started/Landsat8_getting_started.html#existing-tools-with-a-focus-on-r",
    "href": "source/tutorials/Landsat8_getting_started/Landsat8_getting_started.html#existing-tools-with-a-focus-on-r",
    "title": "Introduction to gdalcubes using local Landsat 8 imagery",
    "section": "Existing Tools (with a focus on R)",
    "text": "Existing Tools (with a focus on R)\nGDAL, the Geospatial Data Abstraction Library is a software library reading and writing all relevant raster (and vector) data formats, and providing functions to warp (reproject, rescale, resample, and crop) multiband raster images. It has a three dimensional (space, bands) raster data model and solves some of the problems (data formats, image warping). However, it does not know about the organization of data products, and time. GDAL is written in C / C++ but the rgdalpackage (Bivand, Keitt, and Rowlingson 2019) provides an easy to use interface in R.\nThere are further R packages to process satellite imagery:\nraster (Hijmans 2019)\n\nwell established, stable, reliable\nthree-dimensional only, no multispectral AND multitemporal stacks\nchaining operations on rasters (stacks / bricks) always writes intermediate results to disk\nworks on full resolution data, requires additional steps e.g. to try out things on lower resolution\ncurrently being rewritten (see https://github.com/rspatial/terra)\n\nstars (Pebesma 2019) (see parallel session)\n\narbitrary dimensions\nassumes a data cube as input (does not do spatial mosaicing, temporal aggregation)\nhas vector data cubes\nlazy evaluation approach, compute only the pixels you see."
  },
  {
    "objectID": "source/tutorials/Landsat8_getting_started/Landsat8_getting_started.html#first-steps-with-gdalcubes",
    "href": "source/tutorials/Landsat8_getting_started/Landsat8_getting_started.html#first-steps-with-gdalcubes",
    "title": "Introduction to gdalcubes using local Landsat 8 imagery",
    "section": "First Steps with gdalcubes",
    "text": "First Steps with gdalcubes\ngdalcubes is a relatively new R package that mostly wraps functions written in C++. It uses GDAL to read, write, and warp images, but understands date/time and how complex satellite image data products are organized. To get started, please install the gdalcubes package from CRAN with:\n\ninstall.packages(\"gdalcubes\")\n\nWe can load the package and make sure that all computations later in this tutorial use up to 8 parallel processes with:\n\nlibrary(gdalcubes)\ngdalcubes_options(parallel = 8)\n\nPlease notice that this tutorial needs package version >= 0.6.0, which you can check by running:\n\npackageVersion(\"gdalcubes\")\n\n[1] '0.6.1.9999'"
  },
  {
    "objectID": "source/tutorials/Landsat8_getting_started/Landsat8_getting_started.html#creating-an-image-collection",
    "href": "source/tutorials/Landsat8_getting_started/Landsat8_getting_started.html#creating-an-image-collection",
    "title": "Introduction to gdalcubes using local Landsat 8 imagery",
    "section": "Creating an Image Collection",
    "text": "Creating an Image Collection\nTo analyze our sample dataset, we must first tell gdalcubes, which files belong to the image collection, and where to find them.\nAt first, we simply list (recursively) all GeoTIFF files in the directory with the Landsat 8 images:\n\nL8.files = list.files(\"L8_Amazon\", pattern = \".tif\", recursive = TRUE, full.names = TRUE) \nhead(L8.files, 15)\n\n [1] \"L8_Amazon/LC082260632014071901T1-SC20190715045926/LC08_L1TP_226063_20140719_20170421_01_T1_pixel_qa.tif\"  \n [2] \"L8_Amazon/LC082260632014071901T1-SC20190715045926/LC08_L1TP_226063_20140719_20170421_01_T1_radsat_qa.tif\" \n [3] \"L8_Amazon/LC082260632014071901T1-SC20190715045926/LC08_L1TP_226063_20140719_20170421_01_T1_sr_aerosol.tif\"\n [4] \"L8_Amazon/LC082260632014071901T1-SC20190715045926/LC08_L1TP_226063_20140719_20170421_01_T1_sr_band1.tif\"  \n [5] \"L8_Amazon/LC082260632014071901T1-SC20190715045926/LC08_L1TP_226063_20140719_20170421_01_T1_sr_band2.tif\"  \n [6] \"L8_Amazon/LC082260632014071901T1-SC20190715045926/LC08_L1TP_226063_20140719_20170421_01_T1_sr_band3.tif\"  \n [7] \"L8_Amazon/LC082260632014071901T1-SC20190715045926/LC08_L1TP_226063_20140719_20170421_01_T1_sr_band4.tif\"  \n [8] \"L8_Amazon/LC082260632014071901T1-SC20190715045926/LC08_L1TP_226063_20140719_20170421_01_T1_sr_band5.tif\"  \n [9] \"L8_Amazon/LC082260632014071901T1-SC20190715045926/LC08_L1TP_226063_20140719_20170421_01_T1_sr_band6.tif\"  \n[10] \"L8_Amazon/LC082260632014071901T1-SC20190715045926/LC08_L1TP_226063_20140719_20170421_01_T1_sr_band7.tif\"  \n[11] \"L8_Amazon/LC082260632014082001T1-SC20190715051515/LC08_L1TP_226063_20140820_20170420_01_T1_pixel_qa.tif\"  \n[12] \"L8_Amazon/LC082260632014082001T1-SC20190715051515/LC08_L1TP_226063_20140820_20170420_01_T1_radsat_qa.tif\" \n[13] \"L8_Amazon/LC082260632014082001T1-SC20190715051515/LC08_L1TP_226063_20140820_20170420_01_T1_sr_aerosol.tif\"\n[14] \"L8_Amazon/LC082260632014082001T1-SC20190715051515/LC08_L1TP_226063_20140820_20170420_01_T1_sr_band1.tif\"  \n[15] \"L8_Amazon/LC082260632014082001T1-SC20190715051515/LC08_L1TP_226063_20140820_20170420_01_T1_sr_band2.tif\"  \n\nsum(file.size(L8.files)) / 1000^3 # gigabytes\n\n[1] 2.012341\n\n\nWe see that every image is represented by a directory, with individual files for spectral bands. We can then add all images to an image collection with:\n\nL8.col = create_image_collection(L8.files, format = \"L8_SR\", out_file = \"L8.db\")\n# L8.col = image_collection(\"L8.db\") \nL8.col\n\nImage collection object, referencing 180 images with 10 bands\nImages:\n                                      name      left       top    bottom\n1 LC08_L1TP_226063_20140719_20170421_01_T1 -54.15776 -3.289862 -5.392073\n2 LC08_L1TP_226063_20140820_20170420_01_T1 -54.16858 -3.289828 -5.392054\n3 LC08_L1GT_226063_20160114_20170405_01_T2 -54.16317 -3.289845 -5.392064\n4 LC08_L1TP_226063_20160724_20170322_01_T1 -54.16317 -3.289845 -5.392064\n5 LC08_L1TP_226063_20170609_20170616_01_T1 -54.17399 -3.289810 -5.392044\n6 LC08_L1TP_226063_20170711_20170726_01_T1 -54.15506 -3.289870 -5.392083\n      right            datetime        srs\n1 -52.10338 2014-07-19T00:00:00 EPSG:32622\n2 -52.11418 2014-08-20T00:00:00 EPSG:32622\n3 -52.10878 2016-01-14T00:00:00 EPSG:32622\n4 -52.10878 2016-07-24T00:00:00 EPSG:32622\n5 -52.11958 2017-06-09T00:00:00 EPSG:32622\n6 -52.09798 2017-07-11T00:00:00 EPSG:32622\n[ omitted 174 images ] \n\nBands:\n        name offset scale unit       nodata image_count\n1    AEROSOL      0     1                           180\n2        B01      0     1      -9999.000000         180\n3        B02      0     1      -9999.000000         180\n4        B03      0     1      -9999.000000         180\n5        B04      0     1      -9999.000000         180\n6        B05      0     1      -9999.000000         180\n7        B06      0     1      -9999.000000         180\n8        B07      0     1      -9999.000000         180\n9   PIXEL_QA      0     1                           180\n10 RADSAT_QA      0     1                           180\n\n\nThis opens all provided files once, reads some relevant metadata (spatial extent, reference system, recording date/time, and how the file relates to the spectral bands of the data product). The format argument describes, how this information can be extracted. The gdalcubes package comes with a set of predefined image collection formats for particular data products. We can list available formats with:\n\ncollection_formats()\n\n   CHIRPS_v2_0_daily_p05_tif | Image collection format for CHIRPS v 2.0 daily\n                             | global precipitation dataset (0.05 degrees\n                             | resolution) from GeoTIFFs, expects list of .tif\n                             | or .tif.gz files as input. [TAGS: CHIRPS,\n                             | precipitation]\n CHIRPS_v2_0_monthly_p05_tif | Image collection format for CHIRPS v 2.0 monthly\n                             | global precipitation dataset (0.05 degrees\n                             | resolution) from GeoTIFFs, expects list of .tif\n                             | or .tif.gz files as input. [TAGS: CHIRPS,\n                             | precipitation]\n           ESA_CCI_SM_ACTIVE | Collection format for ESA CCI soil moisture\n                             | active product (version 4.7) [TAGS: Soil\n                             | Moisture, ESA, CCI]\n          ESA_CCI_SM_PASSIVE | Collection format for ESA CCI soil moisture\n                             | passive product (version 4.7) [TAGS: Soil\n                             | Moisture, ESA, CCI]\n   GPM_IMERG_3B_DAY_GIS_V06A | Collection format for daily\n                             | IMERG_3B_DAY_GIS_V06A data [TAGS: Precipitation,\n                             | GPM, IMERG]\n                     L8_L1TP | Collection format for Landsat 8 Level 1 TP\n                             | product [TAGS: Landsat, USGS, Level 1, NASA]\n                       L8_SR | Collection format for Landsat 8 surface\n                             | reflectance product [TAGS: Landsat, USGS, Level\n                             | 2, NASA, surface reflectance]\n                     MCD64A1 | Collection format for the MODIS MCD64A1 product\n                             | (burned area by day) [TAGS: MODIS, Fire]\n                     MxD09GA | Collection format for selected bands from the\n                             | MODIS MxD09GA (Aqua and Terra) product [TAGS:\n                             | MODIS, surface reflectance]\n                     MxD10A2 | Collection format for selected bands from the\n                             | MODIS MxD10A2 (Aqua and Terra) v006 Snow Cover\n                             | product [TAGS: MODIS, Snow Cover]\n                     MxD11A1 | Collection format for selected bands from the\n                             | MODIS MxD11A2 (Aqua and Terra) v006 Land Surface\n                             | Temperature product [TAGS: MODIS, LST]\n                     MxD11A2 | Collection format for selected bands from the\n                             | MODIS MxD11A2 (Aqua and Terra) v006 Land Surface\n                             | Temperature product [TAGS: MODIS, LST]\n                     MxD13A2 | Collection format for selected bands from the\n                             | MODIS MxD13A2 (Aqua and Terra) product [TAGS:\n                             | MODIS, VI, NDVI, EVI]\n                     MxD13A3 | Collection format for selected bands from the\n                             | MODIS MxD13A3 (Aqua and Terra) product [TAGS:\n                             | MODIS, VI, NDVI, EVI]\n                     MxD13Q1 | Collection format for selected bands from the\n                             | MODIS MxD13Q1 (Aqua and Terra) product [TAGS:\n                             | MODIS, VI, NDVI, EVI]\n                     MxD14A2 | Collection format for the MODIS MxD14A2 (Aqua\n                             | and Terra) product [TAGS: MODIS, Fire]\nPlanetScope_3B_AnalyticMS_SR | Image collection format for PlanetScope 4-band\n                             | scenes [TAGS: PlanetScope, BOA, Surface\n                             | Reflectance]\n            Sentinel1_IW_GRD | Image collection format for Sentinel 1 Level 1\n                             | GRD data as downloaded from the Copernicus Open\n                             | Access Hub, expects a list of file paths as\n                             | input. The format works on original ZIP\n                             | compressed as well as uncompressed imagery.\n                             | [TAGS: Sentinel, Copernicus, ESA, SAR]\n               Sentinel2_L1C | Image collection format for Sentinel 2 Level 1C\n                             | data as downloaded from the Copernicus Open\n                             | Access Hub, expects a list of file paths as\n                             | input. The format works on original ZIP\n                             | compressed as well as uncompressed imagery.\n                             | [TAGS: Sentinel, Copernicus, ESA, TOA]\n           Sentinel2_L1C_AWS | Image collection format for Sentinel 2 Level 1C\n                             | data in AWS [TAGS: Sentinel, Copernicus, ESA,\n                             | TOA]\n               Sentinel2_L2A | Image collection format for Sentinel 2 Level 2A\n                             | data as downloaded from the Copernicus Open\n                             | Access Hub, expects a list of file paths as\n                             | input. The format should work on original ZIP\n                             | compressed as well as uncompressed imagery.\n                             | [TAGS: Sentinel, Copernicus, ESA, BOA, Surface\n                             | Reflectance]\n         Sentinel2_L2A_THEIA | Image collection format for Sentinel 2 Level 2A\n                             | data as downloaded from Theia. [TAGS: Sentinel,\n                             | ESA, Flat Reflectance, Theia]\n\n\nThe number of available formats is still rather limited, but continues to grow and is extensible (using add_collection_format()). In fact, a collection format is a single JSON (JavaScript Object Notation) file, describing some rules how to extract e.g. date/time, and bands from filenames (examples at https://github.com/appelmar/gdalcubes_formats). Writing collection formats for your own non-standard datasets is not too difficult and documented here.\nIn our example, we used the predefined format \"L8_SR\" for Landsat 8 surface reflectance data as downloaded from the USGS portal.\nThe creation of image collections is typically done only once. We can add images to an existing collection with add_images().\nWe can extract the spatiotemporal extent of the collection with:\n\nextent(L8.col, srs=\"EPSG:4326\")\n\n$left\n[1] -59.12746\n\n$right\n[1] -52.09798\n\n$top\n[1] -1.844241\n\n$bottom\n[1] -6.84404\n\n$t0\n[1] \"2013-06-12T00:00:00\"\n\n$t1\n[1] \"2019-07-06T00:00:00\""
  },
  {
    "objectID": "source/tutorials/Landsat8_getting_started/Landsat8_getting_started.html#defining-a-data-cube-view-a-virtual-data-cube",
    "href": "source/tutorials/Landsat8_getting_started/Landsat8_getting_started.html#defining-a-data-cube-view-a-virtual-data-cube",
    "title": "Introduction to gdalcubes using local Landsat 8 imagery",
    "section": "Defining a Data Cube View: A Virtual Data Cube",
    "text": "Defining a Data Cube View: A Virtual Data Cube\nWe can define a target data cube by its geometry, i.e., the spatiotemporal extent, the spatial reference system, the spatial size, and the temporal duration of cells. We call this a data cube view, i.e. the geometry of a cube without connecting it to any data. To create a data cube view, we can use the cube_view() function:\n\n# Coarse resolution overview\nv.overview.500m = cube_view(srs=\"EPSG:3857\", extent=L8.col, dx=500, dy=500, dt = \"P1Y\", resampling=\"average\", aggregation=\"median\")\nv.overview.500m\n\nA data cube view object\n\nDimensions:\n                low              high count pixel_size\nt        2013-01-01        2019-12-31     7        P1Y\ny -763764.387686915 -205264.387686915  1117        500\nx -6582280.06164712 -5799280.06164712  1566        500\n\nSRS: \"EPSG:3857\"\nTemporal aggregation method: \"median\"\nSpatial resampling method: \"average\"\n\nv.subarea.60m = cube_view(extent=list(left=-6180000, right=-6080000, bottom=-550000, top=-450000, \n   t0=\"2014-01-01\", t1=\"2018-12-31\"), dt=\"P1Y\", dx=60, dy=60, srs=\"EPSG:3857\", \n   aggregation = \"median\", resampling = \"average\")\nv.subarea.60m\n\nA data cube view object\n\nDimensions:\n         low       high count pixel_size\nt 2014-01-01 2018-12-31     5        P1Y\ny    -550010    -449990  1667         60\nx   -6180010   -6079990  1667         60\n\nSRS: \"EPSG:3857\"\nTemporal aggregation method: \"median\"\nSpatial resampling method: \"average\"\n\nv.subarea.60m.daily =  cube_view(view = v.subarea.60m, dt=\"P1D\") \nv.subarea.60m.daily\n\nA data cube view object\n\nDimensions:\n         low       high count pixel_size\nt 2014-01-01 2018-12-31  1826        P1D\ny    -550010    -449990  1667         60\nx   -6180010   -6079990  1667         60\n\nSRS: \"EPSG:3857\"\nTemporal aggregation method: \"median\"\nSpatial resampling method: \"average\"\n\n\nNotice that the data cube view does not contain any information on bands, because it is independent from particular data products."
  },
  {
    "objectID": "source/tutorials/Landsat8_getting_started/Landsat8_getting_started.html#creating-data-cubes",
    "href": "source/tutorials/Landsat8_getting_started/Landsat8_getting_started.html#creating-data-cubes",
    "title": "Introduction to gdalcubes using local Landsat 8 imagery",
    "section": "Creating Data Cubes",
    "text": "Creating Data Cubes\nHaving defined an image collection, and a data cube view, a data cube is simply the combination of the two. We can create a data cube with the raster_cube() function:\n\nL8.cube.overview = raster_cube(L8.col, v.overview.500m)\nL8.cube.overview\n\nA GDAL data cube proxy object\n\nDimensions:\n                low              high count pixel_size chunk_size\nt        2013-01-01        2019-12-31     7        P1Y          1\ny -763764.387686915 -205264.387686915  1117        500        384\nx -6582280.06164712 -5799280.06164712  1566        500        384\n\nBands:\n        name offset scale nodata unit\n1    AEROSOL      0     1    NaN     \n2        B01      0     1    NaN     \n3        B02      0     1    NaN     \n4        B03      0     1    NaN     \n5        B04      0     1    NaN     \n6        B05      0     1    NaN     \n7        B06      0     1    NaN     \n8        B07      0     1    NaN     \n9   PIXEL_QA      0     1    NaN     \n10 RADSAT_QA      0     1    NaN     \n\nL8.cube.subarea = raster_cube(L8.col, v.subarea.60m)\nL8.cube.subarea\n\nA GDAL data cube proxy object\n\nDimensions:\n         low       high count pixel_size chunk_size\nt 2014-01-01 2018-12-31     5        P1Y          1\ny    -550010    -449990  1667         60        448\nx   -6180010   -6079990  1667         60        448\n\nBands:\n        name offset scale nodata unit\n1    AEROSOL      0     1    NaN     \n2        B01      0     1    NaN     \n3        B02      0     1    NaN     \n4        B03      0     1    NaN     \n5        B04      0     1    NaN     \n6        B05      0     1    NaN     \n7        B06      0     1    NaN     \n8        B07      0     1    NaN     \n9   PIXEL_QA      0     1    NaN     \n10 RADSAT_QA      0     1    NaN     \n\nL8.cube.subarea.daily = raster_cube(L8.col, v.subarea.60m.daily)\nL8.cube.subarea.daily\n\nA GDAL data cube proxy object\n\nDimensions:\n         low       high count pixel_size chunk_size\nt 2014-01-01 2018-12-31  1826        P1D          1\ny    -550010    -449990  1667         60        448\nx   -6180010   -6079990  1667         60        448\n\nBands:\n        name offset scale nodata unit\n1    AEROSOL      0     1    NaN     \n2        B01      0     1    NaN     \n3        B02      0     1    NaN     \n4        B03      0     1    NaN     \n5        B04      0     1    NaN     \n6        B05      0     1    NaN     \n7        B06      0     1    NaN     \n8        B07      0     1    NaN     \n9   PIXEL_QA      0     1    NaN     \n10 RADSAT_QA      0     1    NaN     \n\n\nThis is very cheap, simply returning proxy objects, but not reading any image data. The package delays the computational intensive parts as much as possible (e.g., until users call plot()). The returned object knows about the bands of the data product. We can use select_bands() to get only the bands we are interested in:\n\nL8.cube.overview.rgb = select_bands(L8.cube.overview, c(\"B02\", \"B03\", \"B04\"))\nL8.cube.overview.rgb\n\nA GDAL data cube proxy object\n\nDimensions:\n                low              high count pixel_size chunk_size\nt        2013-01-01        2019-12-31     7        P1Y          1\ny -763764.387686915 -205264.387686915  1117        500        384\nx -6582280.06164712 -5799280.06164712  1566        500        384\n\nBands:\n  name offset scale nodata unit\n1  B02      0     1    NaN     \n2  B03      0     1    NaN     \n3  B04      0     1    NaN     \n\n\nThere are some utility functions on data cubes, including:\n\nnames(L8.cube.overview.rgb)\n\n[1] \"B02\" \"B03\" \"B04\"\n\nsrs(L8.cube.overview.rgb)\n\n[1] \"EPSG:3857\"\n\nbands(L8.cube.overview.rgb)\n\n  name offset scale nodata unit\n1  B02      0     1    NaN     \n2  B03      0     1    NaN     \n3  B04      0     1    NaN"
  },
  {
    "objectID": "source/tutorials/Landsat8_getting_started/Landsat8_getting_started.html#plotting-data-cubes",
    "href": "source/tutorials/Landsat8_getting_started/Landsat8_getting_started.html#plotting-data-cubes",
    "title": "Introduction to gdalcubes using local Landsat 8 imagery",
    "section": "Plotting Data Cubes",
    "text": "Plotting Data Cubes\nThe plot function can be used to visualize data cubes. Calling plot() will start reading and processing the data:\nFor a simple RGB plot, we use the rgb argument to specify which bands correspond to the red, green, and blue channels, and specify the black and white points of the channels (to control contrast and brightness) in zlim.\n\nplot(L8.cube.overview.rgb, rgb=3:1, zlim=c(0,1500))\n\n\n\nplot(select_bands(L8.cube.subarea, c(\"B02\", \"B03\", \"B04\")), rgb=3:1, zlim=c(0,1500))\n\n\n\n\nNotice that we can also plot bands individually, creating a two-dimensional plot layout of bands and time. Using key.pos = 1, and col= viridis::viridis, we plot a legend at the bottom of the plot, and use the viridis color scales (this requires the viridis package).\n\nplot(L8.cube.overview.rgb, zlim=c(0,1500), key.pos=1, col=viridis::viridis, t=2:5) \n\n\n\nplot(select_bands(raster_cube(L8.col,view = v.subarea.60m), c(\"B05\")),col=viridis::viridis,  zlim=c(0,6000), key.pos=1)\n\n\n\n\nPlotting an identical data cube twice, with different visualization arguments zlim, col, and others will not need to reprocess the data cube again. plot() internally writes netCDF files to a temporary directory and remembers that a specific cube is already available.\nThe plot() function also considers different types of data cubes. For example, if the number of cells in x and y direction equals one, we get a simple time series plot, as we will see later in this tutorial.\n\nAnimations\nThe data cube representation makes it straightforward to create animations, by plotting time slices of the cube individually, and use these plots as animation frames:\n\nanimate(select_bands(raster_cube(L8.col, v.subarea.60m), c(\"B02\",\"B03\",\"B04\")), rgb=3:1, zlim=c(0,1500))\n\n[1] \"/tmp/RtmpPBzhh3/file9a45642345bc6.gif\""
  },
  {
    "objectID": "source/tutorials/Landsat8_getting_started/Landsat8_getting_started.html#exporting-data-cubes-to-disk",
    "href": "source/tutorials/Landsat8_getting_started/Landsat8_getting_started.html#exporting-data-cubes-to-disk",
    "title": "Introduction to gdalcubes using local Landsat 8 imagery",
    "section": "Exporting Data Cubes to Disk",
    "text": "Exporting Data Cubes to Disk\nSometimes we want to process data cubes further, e.g. with external software. We can export data cubes either as single netCDF files, or as a collection of GeoTIFF files, where each time-slice of a cube will be stored as one (multiband) file.\nBoth, netCDF and GeoTIFF export support compression, and packing (converting double precision numeric values to smaller integer types by applying an offset and scale) to reduce the file size if needed (see documentation at ?write_ncdf, and ?write_tif).\n\ngdalcubes_options(ncdf_compression_level = 1)\nwrite_ncdf(L8.cube.overview.rgb, file.path(\"~/Desktop\", basename(tempfile(fileext = \".nc\"))))\ngdalcubes_options(ncdf_compression_level = 0)\n\nwrite_tif() and write_ncdf() both return the path(s) to created file(s) as a character vector."
  },
  {
    "objectID": "source/tutorials/Landsat8_getting_started/Landsat8_getting_started.html#interfacing-existing-r-packages",
    "href": "source/tutorials/Landsat8_getting_started/Landsat8_getting_started.html#interfacing-existing-r-packages",
    "title": "Introduction to gdalcubes using local Landsat 8 imagery",
    "section": "Interfacing Existing R Packages",
    "text": "Interfacing Existing R Packages\nThe package comes with a function as_stars() to convert data cubes to stars objects (Pebesma 2019), data cubes supporting any number of dimensions, and even vector data cubes.\n\nlibrary(stars)\n\nLoading required package: abind\n\n\nLoading required package: sf\n\n\nLinking to GEOS 3.10.1, GDAL 3.4.0, PROJ 8.2.0; sf_use_s2() is TRUE\n\nx = st_as_stars(\n    select_bands(\n      raster_cube(L8.col, v.subarea.60m), \"B05\"))\nx\n\nstars object with 3 dimensions and 1 attribute\nattribute(s), summary of first 1e+05 cells:\n                            Min.  1st Qu.   Median     Mean  3rd Qu. Max.\nfile9a45625088962.nc\":B05  296.5 2984.992 3207.546 3226.604 3459.003 5099\ndimension(s):\n     from   to   offset delta                   refsys point\nx       1 1667 -6180010    60 WGS 84 / Pseudo-Mercator    NA\ny       1 1667  -449990   -60 WGS 84 / Pseudo-Mercator    NA\ntime    1    5       NA    NA                  POSIXct FALSE\n                                                  values x/y\nx                                                   NULL [x]\ny                                                   NULL [y]\ntime [2014-01-01,2015-01-01),...,[2018-01-01,2019-01-01)    \n\nplot(x)\n\ndownsample set to 2\n\n\n\n\n\nThe resulting object considers bands as array attributes that can be converted to a new dimension e.g. with stars::st_redimension().\nIf the raster cube has only a single band, or a single time slice, it is also possible to convert it to a raster (stack), by using write_tif():\n\nx = raster::stack(\n  write_tif(\n    select_bands(\n      raster_cube(L8.col, v.subarea.60m), \"B05\")))\nx\n\nclass      : RasterStack \ndimensions : 1667, 1667, 2778889, 5  (nrow, ncol, ncell, nlayers)\nresolution : 60, 60  (x, y)\nextent     : -6180010, -6079990, -550010, -449990  (xmin, xmax, ymin, ymax)\ncrs        : +proj=merc +a=6378137 +b=6378137 +lat_ts=0 +lon_0=0 +x_0=0 +y_0=0 +k=1 +units=m +nadgrids=@null +wktext +no_defs \nnames      : cube_9a4566449bc062014.01.01, cube_9a4566449bc062015.01.01, cube_9a4566449bc062016.01.01, cube_9a4566449bc062017.01.01, cube_9a4566449bc062018.01.01"
  },
  {
    "objectID": "source/tutorials/Landsat8_getting_started/Landsat8_getting_started.html#more-data-cube-creation-options",
    "href": "source/tutorials/Landsat8_getting_started/Landsat8_getting_started.html#more-data-cube-creation-options",
    "title": "Introduction to gdalcubes using local Landsat 8 imagery",
    "section": "More Data Cube Creation Options",
    "text": "More Data Cube Creation Options\nThe raster_cube() function receives two further optional arguments.\nThe mask argument can be used to apply image masks during construction of the data cube if the data products includes a mask band (e.g. for clouds, cloud shadows, or general quality flags). To define a mask, we typically call the image_mask() function. This function expects the name of the mask band as its first band argument. Additionally, we can either pass a vector of values that are masked (all bands set to NA if the specified band has one of the provided values) as the values argument, or give a range of mask values by passing minimum and maximum values as min and max arguments. Masks can be inverted by setting invert = TRUE. For bit field masks, it is possible to extract specific bits (applying a logical AND) of the band values, before comparing them to the values or range of the mask.\nThe example below will mask all pixels with a \"PIXEL_QA\" value different from the provided values (taken from the Landsat 8 handbook).\n\nL8.clear_mask = image_mask(\"PIXEL_QA\", values=c(322, 386, 834, 898, 1346, 324, 388, 836, 900, 1348), invert = TRUE)\nx = raster_cube(L8.col, v.subarea.60m, mask=L8.clear_mask) \nx = select_bands(x, c(\"B02\",\"B03\",\"B04\"))\nanimate(x, rgb=3:1, zlim=c(0,1500))\n\n[1] \"/tmp/RtmpPBzhh3/file9a45656635eb1.gif\"\n\n\nThe chunking argument defines the size of data cube chunks as a vector with three integer values for the number of pixels in time, y, and x directions respectively. Chunks are read completely into main memory, i.e., smaller chunks will generally reduce the main memory consumption. The size of chunks also has an effect on parallelization. Internally, chunks of the target data cube are read and processed independently, potentially by multiple threads. However, the effect of the chunk size on the performance is much more complex and depends on how we process the data (e.g., time series vs. time slices oriented), and how the data is stored. Some data formats e.g. do not allow efficient range selection reads whereas others do."
  },
  {
    "objectID": "source/tutorials/Landsat8_getting_started/Landsat8_getting_started.html#arithmetic-expressions-on-data-cube-bands",
    "href": "source/tutorials/Landsat8_getting_started/Landsat8_getting_started.html#arithmetic-expressions-on-data-cube-bands",
    "title": "Introduction to gdalcubes using local Landsat 8 imagery",
    "section": "Arithmetic Expressions on Data Cube Bands",
    "text": "Arithmetic Expressions on Data Cube Bands\nThe apply_pixel() function can be used to apply per-pixel arithmetic expressions on band values of a data cube. Examples include the calculation of vegetation indexes. The function takes a data cube, a string vector of arithmetic expressions, and a vector of result band names as arguments. Below, we derive the normalized difference vegetation index (NDVI) from the red and near infrared (NIR) channel. We can apply multiple expressions at the same time by providing a vector of expressions (and names).\n\nL8.ndvi = raster_cube(L8.col, v.subarea.60m, mask=L8.clear_mask) |>\n  select_bands(c(\"B04\",\"B05\")) |>\n  apply_pixel(\"(B05-B04)/(B05+B04)\" , names = \"NDVI\", keep_bands=FALSE)\n\nL8.ndvi\n\nA GDAL data cube proxy object\n\nDimensions:\n         low       high count pixel_size chunk_size\nt 2014-01-01 2018-12-31     5        P1Y          1\ny    -550010    -449990  1667         60        448\nx   -6180010   -6079990  1667         60        448\n\nBands:\n  name offset scale nodata unit\n1 NDVI      0     1    NaN     \n\nplot(L8.ndvi, col=viridis::viridis, zlim=c(-0.3,1), key.pos = 1)\n\n\n\n\nCreating a chain of data cube operations still returns proxy objects, knowing the size and shape of the output data cube, before calling plot will start computations. In the example, we do not need the original bands after computing the NDVI and set keep_bands = FALSE (this is the default).\nSimilar to apply_pixel() we can filter pixels by arithmetic expressions with filter_pixel(). Values of all bands for pixels not fulfilling a logical expression will be set to NA.\n\nraster_cube(L8.col, v.subarea.60m, mask=L8.clear_mask) |>\n  select_bands(c(\"B05\",\"B07\")) |>\n  apply_pixel(\"(B05-B07)/(B05+B07)\" , names = \"NBR\") |>\n  filter_pixel(\"NBR < 0.5\") |>\n  plot(col=viridis::viridis, zlim=c(-1,0.5), key.pos = 1)"
  },
  {
    "objectID": "source/tutorials/Landsat8_getting_started/Landsat8_getting_started.html#reduction-over-time-and-space",
    "href": "source/tutorials/Landsat8_getting_started/Landsat8_getting_started.html#reduction-over-time-and-space",
    "title": "Introduction to gdalcubes using local Landsat 8 imagery",
    "section": "Reduction Over Time and Space",
    "text": "Reduction Over Time and Space\nData cubes can be reduced over the space and time dimensions. The reduce_time() function applies one or more reducer functions over pixel time series, producing a single (multiband) result image, whereas reduce_space() reduces time slices in the cube to single values (per band), resulting in a single (multiband) time series.\nThe example below derives median NDVI values over all pixel time series.\n\nraster_cube(L8.col, v.subarea.60m, mask=L8.clear_mask) |>\n  select_bands(c(\"B04\",\"B05\")) |>\n  apply_pixel(\"(B05-B04)/(B05+B04)\", names = \"NDVI\", keep_bands=FALSE) |>\n  reduce_time(\"median(NDVI)\") |>\n  plot(col=viridis::viridis, nbreaks=100, zlim=c(-0.3,1), key.pos = 1)\n\n\n\n\nPossible reducers include \"min\", \"mean\", \"median\", \"max\", \"count\" (count non-missing values), \"sum\", \"var\" (variance), and \"sd\" (standard deviation). Reducer expressions are always given as a string starting with the reducer name followed by the band name in parentheses. Notice that it is not possible to apply more complex arithmetic expressions here. It is however possible to mix reducers and bands:\n\nraster_cube(L8.col, v.subarea.60m, mask=L8.clear_mask) |>\n  select_bands(c(\"B04\",\"B05\")) |>\n  apply_pixel(\"(B05-B04)/(B05+B04)\", names = \"NDVI\", keep_bands=TRUE) |>\n  reduce_time(\"median(NDVI)\", \"mean(NDVI)\",\"max(B05)\")\n\nA GDAL data cube proxy object\n\nDimensions:\n         low       high count pixel_size chunk_size\nt 2014-01-01 2018-12-31     1        P5Y          1\ny    -550010    -449990  1667         60        448\nx   -6180010   -6079990  1667         60        448\n\nBands:\n         name offset scale nodata unit\n1 NDVI_median      0     1    NaN     \n2   NDVI_mean      0     1    NaN     \n3     B05_max      0     1    NaN     \n\n\nResults of reduce_space() are plotted as simple time series.\n\nraster_cube(L8.col, v.subarea.60m,  mask=L8.clear_mask) |>\n  select_bands(c(\"B04\",\"B05\")) |>\n  apply_pixel(\"(B05-B04)/(B05+B04)\", names = \"NDVI\") |>\n  reduce_space(\"median(NDVI)\", \"sd(NDVI)\") |>\n  plot()\n\n\n\n\nThe \"count\" reducer is often very useful to get an initial understanding of an image collection.\n\nraster_cube(L8.col, cube_view(view=v.overview.500m, dt=\"P1D\"), mask=L8.clear_mask) |>\n  select_bands(c(\"B01\")) |>\n  reduce_time(\"count(B01)\") |>\n  plot(key.pos=1)\n\n\n\n\n\nraster_cube(L8.col, cube_view(view=v.overview.500m, dt=\"P1M\"), mask=L8.clear_mask) |>\n  select_bands(\"B01\") |>\n  reduce_space(\"count(B01)\") |>\n  plot()\n\n\n\n\nWe can see that there are almost no observations during the months from October to May, because the download was limited to images with low cloud percentages."
  },
  {
    "objectID": "source/tutorials/Landsat8_getting_started/Landsat8_getting_started.html#time-series-methods",
    "href": "source/tutorials/Landsat8_getting_started/Landsat8_getting_started.html#time-series-methods",
    "title": "Introduction to gdalcubes using local Landsat 8 imagery",
    "section": "Time-series methods",
    "text": "Time-series methods\nThere are two more built-in functions that operate on individual pixel time series.\nThe fill_time() function interpolates missing values by preceding or succeeding values (using simple linear or nearest neighbor interpolation, or carrying observations forwards or backwards), The window_time() function can either apply a moving window kernel, or apply a reducer function over moving windows.\nIn the example below, we sum NDVI changes between subsequent time slices in the data cube, and visualize the result using a diverging color scale from the RColorBrewer package.\n\nraster_cube(L8.col, cube_view(view = v.subarea.60m, extent=list(t0=\"2014-01\",t1=\"2018-12\")), mask=L8.clear_mask) |>\n  select_bands(c(\"B04\",\"B05\")) |>\n  apply_pixel(\"(B05-B04)/(B05+B04)\", names = \"NDVI\") |>\n  fill_time(method = \"locf\") |>\n  window_time(kernel = c(-1,1), window=c(1,0)) |>\n  reduce_time(\"sum(NDVI)\") |>\n  plot(zlim=c(-0.4,0.4),nbreaks = 12, col=RColorBrewer::brewer.pal(11, \"RdYlBu\"), key.pos=1)"
  },
  {
    "objectID": "source/tutorials/Landsat8_getting_started/Landsat8_getting_started.html#user-defined-functions",
    "href": "source/tutorials/Landsat8_getting_started/Landsat8_getting_started.html#user-defined-functions",
    "title": "Introduction to gdalcubes using local Landsat 8 imagery",
    "section": "User-defined Functions",
    "text": "User-defined Functions\nSo far, we have provided expressions and reducers as characters / strings. The reasons was that these methods automatically translate to C++, i.e. are evaluated in the C++ code. In the current version, reduce_time(), and apply_pixel() may also receive R functions as argument. This opens up quite a bunch of things we can do, e.g. using functions from our favorite R packages to process pixel time series. In the example below, we simply fit a line to individual NDVI pixel time series and return its slope (trend).\n\nraster_cube(L8.col, cube_view(view = v.subarea.60m, dx=200), mask = L8.clear_mask) |>\n  select_bands(c(\"B04\",\"B05\")) |>\n  apply_pixel(\"(B05-B04)/(B05+B04)\", names = \"NDVI\") |>\n  reduce_time(names=c(\"ndvi_trend\"), FUN=function(x) {\n    z = data.frame(t=1:ncol(x), ndvi=x[\"NDVI\",])\n    result = NA\n    if (sum(!is.na(z$ndvi)) > 3) {\n      result = coef(lm(ndvi ~ t, z, na.action = na.exclude))[2]\n    }\n    return(result) \n  }) |>\n  plot(key.pos=1, col=viridis::viridis)\n\n\n\n\nThere is no limit in what we can do in the provided R function, but we must take care of a few things:\n\nThe reducer function is executed in a new R process without access to the current workspace. It is not possible to access variables defined outside of the function and packages must be loaded within the function.\nThe reducer function must always return a vector with the same length (for all time series).\nIt is a good idea to think about NA values, i.e. you should check whether the complete time series is NA, and that missing values do not produce errors."
  },
  {
    "objectID": "source/tutorials/Landsat8_getting_started/Landsat8_getting_started.html#for-developers-process-graphs",
    "href": "source/tutorials/Landsat8_getting_started/Landsat8_getting_started.html#for-developers-process-graphs",
    "title": "Introduction to gdalcubes using local Landsat 8 imagery",
    "section": "For Developers: Process Graphs",
    "text": "For Developers: Process Graphs\nChaining processes works lazliy; internally gdalcubes creates a process graph of operations that can be serialized as JSON:\n\nraster_cube(L8.col, cube_view(view = v.subarea.60m, extent=list(t0=\"2014-01\",t1=\"2018-12\")), mask=L8.clear_mask) |>\n  select_bands(c(\"B04\",\"B05\")) |>\n  apply_pixel(\"(B05-B04)/(B05+B04)\", names = \"NDVI\") |>\n  fill_time(method = \"locf\") |>\n  window_time(kernel = c(-1,1), window=c(1,0)) |>\n  reduce_time(\"sum(NDVI)\") |>\n  as_json() |>\n  cat()\n\n{\n    \"cube_type\": \"reduce_time\",\n    \"in_cube\": {\n        \"cube_type\": \"window_time\",\n        \"in_cube\": {\n            \"cube_type\": \"fill_time\",\n            \"in_cube\": {\n                \"band_names\": [\n                    \"NDVI\"\n                ],\n                \"cube_type\": \"apply_pixel\",\n                \"expr\": [\n                    \"(b05-b04)/(b05+b04)\"\n                ],\n                \"in_cube\": {\n                    \"bands\": [\n                        \"B04\",\n                        \"B05\"\n                    ],\n                    \"cube_type\": \"select_bands\",\n                    \"in_cube\": {\n                        \"chunk_size\": [\n                            1,\n                            448,\n                            448\n                        ],\n                        \"cube_type\": \"image_collection\",\n                        \"file\": \"L8.db\",\n                        \"mask\": {\n                            \"bits\": [\n\n                            ],\n                            \"invert\": true,\n                            \"mask_type\": \"value_mask\",\n                            \"values\": [\n                                900,\n                                388,\n                                324,\n                                1346,\n                                898,\n                                1348,\n                                834,\n                                836,\n                                386,\n                                322\n                            ]\n                        },\n                        \"mask_band\": \"PIXEL_QA\",\n                        \"view\": {\n                            \"aggregation\": \"median\",\n                            \"resampling\": \"average\",\n                            \"space\": {\n                                \"bottom\": -550010,\n                                \"left\": -6180010,\n                                \"nx\": 1667,\n                                \"ny\": 1667,\n                                \"right\": -6079990,\n                                \"srs\": \"EPSG:3857\",\n                                \"top\": -449990\n                            },\n                            \"time\": {\n                                \"dt\": \"P1Y\",\n                                \"t0\": \"2014-01-01\",\n                                \"t1\": \"2018-12-31\"\n                            }\n                        }\n                    }\n                },\n                \"keep_bands\": false\n            },\n            \"method\": \"locf\"\n        },\n        \"kernel\": [\n            -1,\n            1\n        ],\n        \"win_size_l\": 1,\n        \"win_size_r\": 0\n    },\n    \"reducer_bands\": [\n        [\n            \"sum\",\n            \"NDVI\"\n        ]\n    ]\n}\n\n\nThis is allows to easily recreate chains of operations, and helps e.g. to cache results."
  },
  {
    "objectID": "source/tutorials/index.html",
    "href": "source/tutorials/index.html",
    "title": "gdalcubes",
    "section": "",
    "text": "Detailed tutorials to get started with gdalcubes and to learn advanced topics including how to access imagery from cloud storage, and how to apply user-defined R functions on data cubes.\nThe table below lists available tutorials and their core topics. Notice that further tutorials will be added from time to time.\n\n\n\nTutorial\nLevel\nTopics\n\n\n\n\nIntroduction to gdalcubes using local Landsat 8 imagery\nBeginner\nCollection formatsLocal file accessUser-defined functions\n\n\nCreating data cubes from local MODIS imagery\nBeginner\nCollection formatsLocal file access\n\n\nData cubes from Sentinel-2 data in the cloud\nAdvanced\nCloud data access\n\n\nExtracting training data for machine learning models\nAdvanced\nCloud data accessMachine learning\n\n\nLand cover change detection with bfast\nAdvanced\nTime series analysisUser-defined functionsCloud data access"
  },
  {
    "objectID": "source/reference/ref/size.html",
    "href": "source/reference/ref/size.html",
    "title": "gdalcubes",
    "section": "",
    "text": "Query data cube properties\n\n\nQuery data cube properties\n\n\n\nsize(obj)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobj\na data cube proxy object (class cube)\n\n\n\n\n\n\nsize of a data cube (number of cells) as integer vector in the order t, y, x\n\n\n\n\n# create image collection from example Landsat data only \n# if not already done in other examples\nif (!file.exists(file.path(tempdir(), \"L8.db\"))) {\n  L8_files <- list.files(system.file(\"L8NY18\", package = \"gdalcubes\"),\n                         \".TIF\", recursive = TRUE, full.names = TRUE)\n  create_image_collection(L8_files, \"L8_L1TP\", file.path(tempdir(), \"L8.db\"), quiet = TRUE) \n}\n\nL8.col = image_collection(file.path(tempdir(), \"L8.db\"))\nv = cube_view(extent=list(left=388941.2, right=766552.4, \n              bottom=4345299, top=4744931, t0=\"2018-04\", t1=\"2018-06\"),\n              srs=\"EPSG:32618\", nx = 497, ny=526, dt=\"P1M\")\nsize(raster_cube(L8.col, v))\n\n[1]   3 526 497\n\n\n\n\n\ndim.cube"
  },
  {
    "objectID": "source/reference/ref/apply_pixel.html",
    "href": "source/reference/ref/apply_pixel.html",
    "title": "gdalcubes",
    "section": "",
    "text": "Apply a function over (multi-band) pixels\n\n\nThis generic function applies a function on pixels of a data cube, an R array, or other classes if implemented.\n\n\n\napply_pixel(x, ...)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\ninput data\n\n\n…\nadditional arguments passed to method implementations\n\n\n\n\n\n\nreturn value and type depend on the class of x\n\n\n\n\n# create image collection from example Landsat data only \n# if not already done in other examples\nif (!file.exists(file.path(tempdir(), \"L8.db\"))) {\n  L8_files <- list.files(system.file(\"L8NY18\", package = \"gdalcubes\"),\n                         \".TIF\", recursive = TRUE, full.names = TRUE)\n  create_image_collection(L8_files, \"L8_L1TP\", file.path(tempdir(), \"L8.db\"), quiet = TRUE) \n}\n\nv = cube_view(extent=list(left=388941.2, right=766552.4, \n              bottom=4345299, top=4744931, t0=\"2018-04\", t1=\"2018-06\"),\n              srs=\"EPSG:32618\", nx = 497, ny=526, dt=\"P1M\")\n              \nL8.col = image_collection(file.path(tempdir(), \"L8.db\"))\napply_pixel(raster_cube(L8.col, v), \"(B05-B04)/(B05+B04)\", \"NDVI\") \n\nA GDAL data cube proxy object\n\nDimensions:\n         low       high count       pixel_size chunk_size\nt 2018-04-01 2018-06-30     3              P1M          1\ny    4345299    4744931   526 759.756653992395        384\nx   388941.2   766552.4   497 759.781086519115        384\n\nBands:\n  name offset scale nodata unit\n1 NDVI      0     1    NaN     \n\nd <- c(4,16,128,128)\nx <- array(rnorm(prod(d)), d)\ny <- apply_pixel(x, function(v) {\n  v[1] + v[2] + v[3] - v[4]\n})\n\n\n\n\napply_pixel.cube\napply_pixel.array"
  },
  {
    "objectID": "source/reference/ref/crop.html",
    "href": "source/reference/ref/crop.html",
    "title": "gdalcubes",
    "section": "",
    "text": "Crop data cube extent by space and/or time\n\n\nCreate a proxy data cube, which crops a data cube by a spatial and/or temporal extent.\n\n\n\ncrop(cube, extent = NULL, iextent = NULL, snap = \"near\")\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ncube\nsource data cube\n\n\nextent\nlist with numeric items left, right, top, bottom, and character items t0 and t1, or a subset thereof, see examples\n\n\niextent\nlist with length-two integer items named x, y, and t, defining the lower and upper boundaries as integer coordinates, see examples\n\n\nsnap\none of ‘near’, ‘in’, or ‘out’; ignored if using iextent\n\n\n\n\n\n\nThe new extent can be specified by spatial coordinates and datetime values (using the extent argument), or as zero-based integer indexes (using the iextent argument). In the former case, extent expects a list with numeric items left, right, top, bottom, t0, and t1, or a subset thereof. In the latter case, iextent is expected as a list with length-two integer vectors x, y, and t as items, defining the lower and upper cell indexes per dimension.\nNotice that it is possible to crop only selected boundaries (e.g., only the right boundary) as missing boundaries in the extent or NA / NULL values in the iextent arguments are considered as “no change”. It is, however, not possible to mix arguments extent and iextent.\nIf extent is given, the snap argument can be used to define what happens if the new boundary falls within a data cube cell.\n\n\n\nThis function returns a proxy object, i.e., it will not start any computations besides deriving the shape of the result.\n\n\n\n\n# create image collection from example Landsat data only \n# if not already done in other examples\nif (!file.exists(file.path(tempdir(), \"L8.db\"))) {\n  L8_files <- list.files(system.file(\"L8NY18\", package = \"gdalcubes\"),\n                         \".TIF\", recursive = TRUE, full.names = TRUE)\n  create_image_collection(L8_files, \"L8_L1TP\", file.path(tempdir(), \"L8.db\"), quiet = TRUE) \n}\nL8.col = image_collection(file.path(tempdir(), \"L8.db\"))\nv = cube_view(extent=list(left=388941.2, right=766552.4, \n              bottom=4345299, top=4744931, t0=\"2018-01\", t1=\"2018-12\"),\n              srs=\"EPSG:32618\", nx = 497, ny=526, dt=\"P3M\", aggregation = \"median\")\nL8.cube = raster_cube(L8.col, v, mask=image_mask(\"BQA\", bits=4, values=16))\nL8.rgb = select_bands(L8.cube, c(\"B02\", \"B03\", \"B04\"))\n\n# crop by integer indexes\nL8.cropped = crop(L8.rgb, iextent = list(x=c(0,400), y=c(0,400), t=c(1,1)))\n\n# crop by spatiotemporal coordinates\nL8.cropped = crop(L8.rgb, extent = list(left=388941.2, right=766552.4, \n   bottom=4345299, top=4744931, t0=\"2018-01\", t1=\"2018-06\"), snap = \"in\")\nL8.cropped \n\nA GDAL data cube proxy object\n\nDimensions:\n         low       high count       pixel_size chunk_size\nt 2018-01-01 2018-06-30     2              P3M          1\ny    4345299    4744931   526 759.756653992395        384\nx   388941.2   766552.4   497 759.781086519115        384\n\nBands:\n  name offset scale nodata unit\n1  B02      0     1    NaN     \n2  B03      0     1    NaN     \n3  B04      0     1    NaN     \n\nL8.cropped = crop(L8.rgb, extent = list(left=388941.2, right=766552.4, \n   bottom=4345299, top=4744931, t0=\"2018-01\", t1=\"2018-06\"), snap = \"near\")\nL8.cropped \n\nA GDAL data cube proxy object\n\nDimensions:\n         low       high count       pixel_size chunk_size\nt 2018-01-01 2018-09-30     3              P3M          1\ny    4345299    4744931   526 759.756653992395        384\nx   388941.2   766552.4   497 759.781086519115        384\n\nBands:\n  name offset scale nodata unit\n1  B02      0     1    NaN     \n2  B03      0     1    NaN     \n3  B04      0     1    NaN     \n\nplot(L8.cropped, rgb = 3:1, zlim=c(5000,10000))"
  },
  {
    "objectID": "source/reference/ref/gdalcubes_options.html",
    "href": "source/reference/ref/gdalcubes_options.html",
    "title": "gdalcubes",
    "section": "",
    "text": "Set or read global options of the gdalcubes package\n\n\nSet global package options to change the default behavior of gdalcubes. These include how many parallel processes are used to process data cubes, how created netCDF files are compressed, and whether or not debug messages should be printed.\n\n\n\ngdalcubes_options(\n  ...,\n  parallel,\n  ncdf_compression_level,\n  debug,\n  cache,\n  ncdf_write_bounds,\n  use_overview_images,\n  show_progress,\n  default_chunksize,\n  streaming_dir,\n  log_file,\n  threads\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\n…\nnot used\n\n\nparallel\nnumber of parallel workers used to process data cubes or TRUE to use the number of available cores automatically\n\n\nncdf_compression_level\ninteger; compression level for created netCDF files, 0=no compression, 1=fast compression, 9=small compression\n\n\ndebug\nlogical; print debug messages\n\n\ncache\nlogical; TRUE if temporary data cubes should be cached to support fast reprocessing of the same cubes\n\n\nncdf_write_bounds\nlogical; write dimension bounds as additional variables in netCDF files\n\n\nuse_overview_images\nlogical; if FALSE, all images are read on original resolution and existing overviews will be ignored\n\n\nshow_progress\nlogical; if TRUE, a progress bar will be shown for actual computations\n\n\ndefault_chunksize\nlength-three vector with chunk size in t, y, x directions or a function taking a data cube size and returning a suggested chunk size\n\n\nstreaming_dir\ndirectory where temporary binary files for process streaming will be written to\n\n\nlog_file\ncharacter, if empty string or NULL, diagnostic messages will be printed to the console, otherwise to the provided file\n\n\nthreads\nnumber of threads used to process data cubes (deprecated)\n\n\n\n\n\n\nData cubes can be processed in parallel where the number of chunks in a cube is distributed among parallel worker processes. The actual number of used workers can be lower if a data cube as less chunks. If parallel is TRUE, the number of available cores is used. Setting parallel = FALSE can be used to disable parallel processing. Notice that since version 0.6.0, separate processes are being used instead of parallel threads to avoid possible R session crashes due to some multithreading issues.\nCaching has no effect on disk or memory consumption, it simply tries to reuse existing temporary files where possible. For example, changing only parameters to plot will void reprocessing the same data cube if cache is TRUE.\nThe streaming directory can be used to control the performance of user-defined functions, if disk IO is a bottleneck. Ideally, this can be set to a directory on a shared memory device.\nPassing no arguments will return the current options as a list.\n\n\n\n\ngdalcubes_options(parallel=4) # set the number \ngdalcubes_options() # print current options\n\n$parallel\n[1] 4\n\n$ncdf_compression_level\n[1] 1\n\n$debug\n[1] FALSE\n\n$cache\n[1] TRUE\n\n$ncdf_write_bounds\n[1] TRUE\n\n$use_overview_images\n[1] TRUE\n\n$show_progress\n[1] FALSE\n\n$default_chunksize\nfunction(nt, ny, nx) {\n  nparallel = .pkgenv$parallel\n  target_nchunks_space = ceiling(2*nparallel)\n  cx = sqrt(nx*ny / target_nchunks_space)\n  cx = ceiling(cx / 64)*64 # use multiples of 64 only\n  cy = cx\n  \n  # apply limits\n  cx = min(cx, 1024)\n  cy = min(cy, 1024)\n  cx = max(cx, 64)\n  cy = max(cy, 64)\n  cx = min(nx, cx)\n  cy = min(ny, cy)\n  \n  return(c(1, ceiling(cy), ceiling(cx)))\n}\n<bytecode: 0x558c073a3af0>\n<environment: namespace:gdalcubes>\n\n$streaming_dir\n[1] \"/tmp/RtmpKdArvL\"\n\ngdalcubes_options(parallel=FALSE) # reset"
  },
  {
    "objectID": "source/reference/ref/memsize.html",
    "href": "source/reference/ref/memsize.html",
    "title": "gdalcubes",
    "section": "",
    "text": "Query data cube properties\n\n\nQuery data cube properties\n\n\n\nmemsize(obj, unit = \"MiB\")\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobj\na data cube proxy object (class cube)\n\n\nunit\nUnit of data size, can be “B”, “KB”, “KiB”, “MB”, “MiB”, “GB”, “GiB”, “TB”, “TiB”, “PB”, “PiB”\n\n\n\n\n\n\nTotal data size of data cube values expressed in the given unit\n\n\n\n\n# create image collection from example Landsat data only \n# if not already done in other examples\nif (!file.exists(file.path(tempdir(), \"L8.db\"))) {\n  L8_files <- list.files(system.file(\"L8NY18\", package = \"gdalcubes\"),\n                         \".TIF\", recursive = TRUE, full.names = TRUE)\n  create_image_collection(L8_files, \"L8_L1TP\", file.path(tempdir(), \"L8.db\"), quiet = TRUE) \n}\n\nL8.col = image_collection(file.path(tempdir(), \"L8.db\"))\nv = cube_view(extent=list(left=388941.2, right=766552.4, \n              bottom=4345299, top=4744931, t0=\"2018-04\", t1=\"2018-06\"),\n              srs=\"EPSG:32618\", nx = 497, ny=526, dt=\"P1M\")\nmemsize(raster_cube(L8.col, v))\n\n[1] 71.8017"
  },
  {
    "objectID": "source/reference/ref/gdalcubes_gdalversion.html",
    "href": "source/reference/ref/gdalcubes_gdalversion.html",
    "title": "gdalcubes",
    "section": "",
    "text": "Get the GDAL version used by gdalcubes\n\n\nGet the GDAL version used by gdalcubes\n\n\n\ngdalcubes_gdalversion()\n\n\n\n\ngdalcubes_gdalversion()\n\n[1] \"GDAL 3.4.0, released 2021/11/04\""
  },
  {
    "objectID": "source/reference/ref/dimension_bounds.html",
    "href": "source/reference/ref/dimension_bounds.html",
    "title": "gdalcubes",
    "section": "",
    "text": "Query coordinate bounds for all dimensions of a data cube\n\n\nDimension values give the coordinates bounds the spatial and temporal axes of a data cube.\n\n\n\ndimension_bounds(obj, datetime_unit = NULL)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobj\na data cube proxy (class cube)\n\n\ndatetime_unit\nunit used to format values in the datetime dimension, one of “Y”, “m”, “d”, “H”, “M”, “S”, defaults to the unit of the cube.\n\n\n\n\n\n\nlist with elements t,y,x, each a list with two elements, start and end\n\n\n\n\n# create image collection from example Landsat data only \n# if not already done in other examples\nif (!file.exists(file.path(tempdir(), \"L8.db\"))) {\n  L8_files <- list.files(system.file(\"L8NY18\", package = \"gdalcubes\"),\n                         \".TIF\", recursive = TRUE, full.names = TRUE)\n  create_image_collection(L8_files, \"L8_L1TP\", file.path(tempdir(), \"L8.db\"), quiet = TRUE) \n}\n\nL8.col = image_collection(file.path(tempdir(), \"L8.db\"))\nv = cube_view(extent=list(left=388941.2, right=766552.4, \n              bottom=4345299, top=4744931, t0=\"2018-04\", t1=\"2018-06\"),\n              srs=\"EPSG:32618\", nx = 497, ny=526, dt=\"P1M\")\ndimension_bounds(raster_cube(L8.col, v))\n\n$t\n$t$start\n[1] \"2018-04-01\" \"2018-05-01\" \"2018-06-01\"\n\n$t$end\n[1] \"2018-05-01\" \"2018-06-01\" \"2018-07-01\"\n\n\n$y\n$y$start\n  [1] 4345299 4346059 4346819 4347578 4348338 4349098 4349858 4350617 4351377\n [10] 4352137 4352897 4353656 4354416 4355176 4355936 4356695 4357455 4358215\n [19] 4358975 4359734 4360494 4361254 4362014 4362773 4363533 4364293 4365053\n [28] 4365812 4366572 4367332 4368092 4368851 4369611 4370371 4371131 4371890\n [37] 4372650 4373410 4374170 4374930 4375689 4376449 4377209 4377969 4378728\n [46] 4379488 4380248 4381008 4381767 4382527 4383287 4384047 4384806 4385566\n [55] 4386326 4387086 4387845 4388605 4389365 4390125 4390884 4391644 4392404\n [64] 4393164 4393923 4394683 4395443 4396203 4396962 4397722 4398482 4399242\n [73] 4400001 4400761 4401521 4402281 4403041 4403800 4404560 4405320 4406080\n [82] 4406839 4407599 4408359 4409119 4409878 4410638 4411398 4412158 4412917\n [91] 4413677 4414437 4415197 4415956 4416716 4417476 4418236 4418995 4419755\n[100] 4420515 4421275 4422034 4422794 4423554 4424314 4425073 4425833 4426593\n[109] 4427353 4428112 4428872 4429632 4430392 4431152 4431911 4432671 4433431\n[118] 4434191 4434950 4435710 4436470 4437230 4437989 4438749 4439509 4440269\n[127] 4441028 4441788 4442548 4443308 4444067 4444827 4445587 4446347 4447106\n[136] 4447866 4448626 4449386 4450145 4450905 4451665 4452425 4453184 4453944\n[145] 4454704 4455464 4456223 4456983 4457743 4458503 4459262 4460022 4460782\n[154] 4461542 4462302 4463061 4463821 4464581 4465341 4466100 4466860 4467620\n[163] 4468380 4469139 4469899 4470659 4471419 4472178 4472938 4473698 4474458\n[172] 4475217 4475977 4476737 4477497 4478256 4479016 4479776 4480536 4481295\n[181] 4482055 4482815 4483575 4484334 4485094 4485854 4486614 4487373 4488133\n[190] 4488893 4489653 4490413 4491172 4491932 4492692 4493452 4494211 4494971\n[199] 4495731 4496491 4497250 4498010 4498770 4499530 4500289 4501049 4501809\n[208] 4502569 4503328 4504088 4504848 4505608 4506367 4507127 4507887 4508647\n[217] 4509406 4510166 4510926 4511686 4512445 4513205 4513965 4514725 4515484\n[226] 4516244 4517004 4517764 4518524 4519283 4520043 4520803 4521563 4522322\n[235] 4523082 4523842 4524602 4525361 4526121 4526881 4527641 4528400 4529160\n[244] 4529920 4530680 4531439 4532199 4532959 4533719 4534478 4535238 4535998\n[253] 4536758 4537517 4538277 4539037 4539797 4540556 4541316 4542076 4542836\n[262] 4543595 4544355 4545115 4545875 4546635 4547394 4548154 4548914 4549674\n[271] 4550433 4551193 4551953 4552713 4553472 4554232 4554992 4555752 4556511\n[280] 4557271 4558031 4558791 4559550 4560310 4561070 4561830 4562589 4563349\n[289] 4564109 4564869 4565628 4566388 4567148 4567908 4568667 4569427 4570187\n[298] 4570947 4571706 4572466 4573226 4573986 4574746 4575505 4576265 4577025\n[307] 4577785 4578544 4579304 4580064 4580824 4581583 4582343 4583103 4583863\n[316] 4584622 4585382 4586142 4586902 4587661 4588421 4589181 4589941 4590700\n[325] 4591460 4592220 4592980 4593739 4594499 4595259 4596019 4596778 4597538\n[334] 4598298 4599058 4599817 4600577 4601337 4602097 4602857 4603616 4604376\n[343] 4605136 4605896 4606655 4607415 4608175 4608935 4609694 4610454 4611214\n[352] 4611974 4612733 4613493 4614253 4615013 4615772 4616532 4617292 4618052\n[361] 4618811 4619571 4620331 4621091 4621850 4622610 4623370 4624130 4624889\n[370] 4625649 4626409 4627169 4627928 4628688 4629448 4630208 4630968 4631727\n[379] 4632487 4633247 4634007 4634766 4635526 4636286 4637046 4637805 4638565\n[388] 4639325 4640085 4640844 4641604 4642364 4643124 4643883 4644643 4645403\n[397] 4646163 4646922 4647682 4648442 4649202 4649961 4650721 4651481 4652241\n[406] 4653000 4653760 4654520 4655280 4656039 4656799 4657559 4658319 4659078\n[415] 4659838 4660598 4661358 4662118 4662877 4663637 4664397 4665157 4665916\n[424] 4666676 4667436 4668196 4668955 4669715 4670475 4671235 4671994 4672754\n[433] 4673514 4674274 4675033 4675793 4676553 4677313 4678072 4678832 4679592\n[442] 4680352 4681111 4681871 4682631 4683391 4684150 4684910 4685670 4686430\n[451] 4687189 4687949 4688709 4689469 4690229 4690988 4691748 4692508 4693268\n[460] 4694027 4694787 4695547 4696307 4697066 4697826 4698586 4699346 4700105\n[469] 4700865 4701625 4702385 4703144 4703904 4704664 4705424 4706183 4706943\n[478] 4707703 4708463 4709222 4709982 4710742 4711502 4712261 4713021 4713781\n[487] 4714541 4715300 4716060 4716820 4717580 4718340 4719099 4719859 4720619\n[496] 4721379 4722138 4722898 4723658 4724418 4725177 4725937 4726697 4727457\n[505] 4728216 4728976 4729736 4730496 4731255 4732015 4732775 4733535 4734294\n[514] 4735054 4735814 4736574 4737333 4738093 4738853 4739613 4740372 4741132\n[523] 4741892 4742652 4743411 4744171\n\n$y$end\n  [1] 4346059 4346819 4347578 4348338 4349098 4349858 4350617 4351377 4352137\n [10] 4352897 4353656 4354416 4355176 4355936 4356695 4357455 4358215 4358975\n [19] 4359734 4360494 4361254 4362014 4362773 4363533 4364293 4365053 4365812\n [28] 4366572 4367332 4368092 4368851 4369611 4370371 4371131 4371890 4372650\n [37] 4373410 4374170 4374930 4375689 4376449 4377209 4377969 4378728 4379488\n [46] 4380248 4381008 4381767 4382527 4383287 4384047 4384806 4385566 4386326\n [55] 4387086 4387845 4388605 4389365 4390125 4390884 4391644 4392404 4393164\n [64] 4393923 4394683 4395443 4396203 4396962 4397722 4398482 4399242 4400001\n [73] 4400761 4401521 4402281 4403041 4403800 4404560 4405320 4406080 4406839\n [82] 4407599 4408359 4409119 4409878 4410638 4411398 4412158 4412917 4413677\n [91] 4414437 4415197 4415956 4416716 4417476 4418236 4418995 4419755 4420515\n[100] 4421275 4422034 4422794 4423554 4424314 4425073 4425833 4426593 4427353\n[109] 4428112 4428872 4429632 4430392 4431152 4431911 4432671 4433431 4434191\n[118] 4434950 4435710 4436470 4437230 4437989 4438749 4439509 4440269 4441028\n[127] 4441788 4442548 4443308 4444067 4444827 4445587 4446347 4447106 4447866\n[136] 4448626 4449386 4450145 4450905 4451665 4452425 4453184 4453944 4454704\n[145] 4455464 4456223 4456983 4457743 4458503 4459262 4460022 4460782 4461542\n[154] 4462302 4463061 4463821 4464581 4465341 4466100 4466860 4467620 4468380\n[163] 4469139 4469899 4470659 4471419 4472178 4472938 4473698 4474458 4475217\n[172] 4475977 4476737 4477497 4478256 4479016 4479776 4480536 4481295 4482055\n[181] 4482815 4483575 4484334 4485094 4485854 4486614 4487373 4488133 4488893\n[190] 4489653 4490413 4491172 4491932 4492692 4493452 4494211 4494971 4495731\n[199] 4496491 4497250 4498010 4498770 4499530 4500289 4501049 4501809 4502569\n[208] 4503328 4504088 4504848 4505608 4506367 4507127 4507887 4508647 4509406\n[217] 4510166 4510926 4511686 4512445 4513205 4513965 4514725 4515484 4516244\n[226] 4517004 4517764 4518524 4519283 4520043 4520803 4521563 4522322 4523082\n[235] 4523842 4524602 4525361 4526121 4526881 4527641 4528400 4529160 4529920\n[244] 4530680 4531439 4532199 4532959 4533719 4534478 4535238 4535998 4536758\n[253] 4537517 4538277 4539037 4539797 4540556 4541316 4542076 4542836 4543595\n[262] 4544355 4545115 4545875 4546635 4547394 4548154 4548914 4549674 4550433\n[271] 4551193 4551953 4552713 4553472 4554232 4554992 4555752 4556511 4557271\n[280] 4558031 4558791 4559550 4560310 4561070 4561830 4562589 4563349 4564109\n[289] 4564869 4565628 4566388 4567148 4567908 4568667 4569427 4570187 4570947\n[298] 4571706 4572466 4573226 4573986 4574746 4575505 4576265 4577025 4577785\n[307] 4578544 4579304 4580064 4580824 4581583 4582343 4583103 4583863 4584622\n[316] 4585382 4586142 4586902 4587661 4588421 4589181 4589941 4590700 4591460\n[325] 4592220 4592980 4593739 4594499 4595259 4596019 4596778 4597538 4598298\n[334] 4599058 4599817 4600577 4601337 4602097 4602857 4603616 4604376 4605136\n[343] 4605896 4606655 4607415 4608175 4608935 4609694 4610454 4611214 4611974\n[352] 4612733 4613493 4614253 4615013 4615772 4616532 4617292 4618052 4618811\n[361] 4619571 4620331 4621091 4621850 4622610 4623370 4624130 4624889 4625649\n[370] 4626409 4627169 4627928 4628688 4629448 4630208 4630968 4631727 4632487\n[379] 4633247 4634007 4634766 4635526 4636286 4637046 4637805 4638565 4639325\n[388] 4640085 4640844 4641604 4642364 4643124 4643883 4644643 4645403 4646163\n[397] 4646922 4647682 4648442 4649202 4649961 4650721 4651481 4652241 4653000\n[406] 4653760 4654520 4655280 4656039 4656799 4657559 4658319 4659078 4659838\n[415] 4660598 4661358 4662118 4662877 4663637 4664397 4665157 4665916 4666676\n[424] 4667436 4668196 4668955 4669715 4670475 4671235 4671994 4672754 4673514\n[433] 4674274 4675033 4675793 4676553 4677313 4678072 4678832 4679592 4680352\n[442] 4681111 4681871 4682631 4683391 4684150 4684910 4685670 4686430 4687189\n[451] 4687949 4688709 4689469 4690229 4690988 4691748 4692508 4693268 4694027\n[460] 4694787 4695547 4696307 4697066 4697826 4698586 4699346 4700105 4700865\n[469] 4701625 4702385 4703144 4703904 4704664 4705424 4706183 4706943 4707703\n[478] 4708463 4709222 4709982 4710742 4711502 4712261 4713021 4713781 4714541\n[487] 4715300 4716060 4716820 4717580 4718340 4719099 4719859 4720619 4721379\n[496] 4722138 4722898 4723658 4724418 4725177 4725937 4726697 4727457 4728216\n[505] 4728976 4729736 4730496 4731255 4732015 4732775 4733535 4734294 4735054\n[514] 4735814 4736574 4737333 4738093 4738853 4739613 4740372 4741132 4741892\n[523] 4742652 4743411 4744171 4744931\n\n\n$x\n$x$start\n  [1] 388941.2 389701.0 390460.8 391220.5 391980.3 392740.1 393499.9 394259.7\n  [9] 395019.4 395779.2 396539.0 397298.8 398058.6 398818.4 399578.1 400337.9\n [17] 401097.7 401857.5 402617.3 403377.0 404136.8 404896.6 405656.4 406416.2\n [25] 407175.9 407935.7 408695.5 409455.3 410215.1 410974.9 411734.6 412494.4\n [33] 413254.2 414014.0 414773.8 415533.5 416293.3 417053.1 417812.9 418572.7\n [41] 419332.4 420092.2 420852.0 421611.8 422371.6 423131.3 423891.1 424650.9\n [49] 425410.7 426170.5 426930.3 427690.0 428449.8 429209.6 429969.4 430729.2\n [57] 431488.9 432248.7 433008.5 433768.3 434528.1 435287.8 436047.6 436807.4\n [65] 437567.2 438327.0 439086.8 439846.5 440606.3 441366.1 442125.9 442885.7\n [73] 443645.4 444405.2 445165.0 445924.8 446684.6 447444.3 448204.1 448963.9\n [81] 449723.7 450483.5 451243.2 452003.0 452762.8 453522.6 454282.4 455042.2\n [89] 455801.9 456561.7 457321.5 458081.3 458841.1 459600.8 460360.6 461120.4\n [97] 461880.2 462640.0 463399.7 464159.5 464919.3 465679.1 466438.9 467198.7\n[105] 467958.4 468718.2 469478.0 470237.8 470997.6 471757.3 472517.1 473276.9\n[113] 474036.7 474796.5 475556.2 476316.0 477075.8 477835.6 478595.4 479355.1\n[121] 480114.9 480874.7 481634.5 482394.3 483154.1 483913.8 484673.6 485433.4\n[129] 486193.2 486953.0 487712.7 488472.5 489232.3 489992.1 490751.9 491511.6\n[137] 492271.4 493031.2 493791.0 494550.8 495310.6 496070.3 496830.1 497589.9\n[145] 498349.7 499109.5 499869.2 500629.0 501388.8 502148.6 502908.4 503668.1\n[153] 504427.9 505187.7 505947.5 506707.3 507467.0 508226.8 508986.6 509746.4\n[161] 510506.2 511266.0 512025.7 512785.5 513545.3 514305.1 515064.9 515824.6\n[169] 516584.4 517344.2 518104.0 518863.8 519623.5 520383.3 521143.1 521902.9\n[177] 522662.7 523422.5 524182.2 524942.0 525701.8 526461.6 527221.4 527981.1\n[185] 528740.9 529500.7 530260.5 531020.3 531780.0 532539.8 533299.6 534059.4\n[193] 534819.2 535578.9 536338.7 537098.5 537858.3 538618.1 539377.9 540137.6\n[201] 540897.4 541657.2 542417.0 543176.8 543936.5 544696.3 545456.1 546215.9\n[209] 546975.7 547735.4 548495.2 549255.0 550014.8 550774.6 551534.4 552294.1\n[217] 553053.9 553813.7 554573.5 555333.3 556093.0 556852.8 557612.6 558372.4\n[225] 559132.2 559891.9 560651.7 561411.5 562171.3 562931.1 563690.8 564450.6\n[233] 565210.4 565970.2 566730.0 567489.8 568249.5 569009.3 569769.1 570528.9\n[241] 571288.7 572048.4 572808.2 573568.0 574327.8 575087.6 575847.3 576607.1\n[249] 577366.9 578126.7 578886.5 579646.3 580406.0 581165.8 581925.6 582685.4\n[257] 583445.2 584204.9 584964.7 585724.5 586484.3 587244.1 588003.8 588763.6\n[265] 589523.4 590283.2 591043.0 591802.8 592562.5 593322.3 594082.1 594841.9\n[273] 595601.7 596361.4 597121.2 597881.0 598640.8 599400.6 600160.3 600920.1\n[281] 601679.9 602439.7 603199.5 603959.2 604719.0 605478.8 606238.6 606998.4\n[289] 607758.2 608517.9 609277.7 610037.5 610797.3 611557.1 612316.8 613076.6\n[297] 613836.4 614596.2 615356.0 616115.7 616875.5 617635.3 618395.1 619154.9\n[305] 619914.7 620674.4 621434.2 622194.0 622953.8 623713.6 624473.3 625233.1\n[313] 625992.9 626752.7 627512.5 628272.2 629032.0 629791.8 630551.6 631311.4\n[321] 632071.1 632830.9 633590.7 634350.5 635110.3 635870.1 636629.8 637389.6\n[329] 638149.4 638909.2 639669.0 640428.7 641188.5 641948.3 642708.1 643467.9\n[337] 644227.6 644987.4 645747.2 646507.0 647266.8 648026.6 648786.3 649546.1\n[345] 650305.9 651065.7 651825.5 652585.2 653345.0 654104.8 654864.6 655624.4\n[353] 656384.1 657143.9 657903.7 658663.5 659423.3 660183.0 660942.8 661702.6\n[361] 662462.4 663222.2 663982.0 664741.7 665501.5 666261.3 667021.1 667780.9\n[369] 668540.6 669300.4 670060.2 670820.0 671579.8 672339.5 673099.3 673859.1\n[377] 674618.9 675378.7 676138.5 676898.2 677658.0 678417.8 679177.6 679937.4\n[385] 680697.1 681456.9 682216.7 682976.5 683736.3 684496.0 685255.8 686015.6\n[393] 686775.4 687535.2 688294.9 689054.7 689814.5 690574.3 691334.1 692093.9\n[401] 692853.6 693613.4 694373.2 695133.0 695892.8 696652.5 697412.3 698172.1\n[409] 698931.9 699691.7 700451.4 701211.2 701971.0 702730.8 703490.6 704250.4\n[417] 705010.1 705769.9 706529.7 707289.5 708049.3 708809.0 709568.8 710328.6\n[425] 711088.4 711848.2 712607.9 713367.7 714127.5 714887.3 715647.1 716406.8\n[433] 717166.6 717926.4 718686.2 719446.0 720205.8 720965.5 721725.3 722485.1\n[441] 723244.9 724004.7 724764.4 725524.2 726284.0 727043.8 727803.6 728563.3\n[449] 729323.1 730082.9 730842.7 731602.5 732362.3 733122.0 733881.8 734641.6\n[457] 735401.4 736161.2 736920.9 737680.7 738440.5 739200.3 739960.1 740719.8\n[465] 741479.6 742239.4 742999.2 743759.0 744518.7 745278.5 746038.3 746798.1\n[473] 747557.9 748317.7 749077.4 749837.2 750597.0 751356.8 752116.6 752876.3\n[481] 753636.1 754395.9 755155.7 755915.5 756675.2 757435.0 758194.8 758954.6\n[489] 759714.4 760474.2 761233.9 761993.7 762753.5 763513.3 764273.1 765032.8\n[497] 765792.6\n\n$x$end\n  [1] 389701.0 390460.8 391220.5 391980.3 392740.1 393499.9 394259.7 395019.4\n  [9] 395779.2 396539.0 397298.8 398058.6 398818.4 399578.1 400337.9 401097.7\n [17] 401857.5 402617.3 403377.0 404136.8 404896.6 405656.4 406416.2 407175.9\n [25] 407935.7 408695.5 409455.3 410215.1 410974.9 411734.6 412494.4 413254.2\n [33] 414014.0 414773.8 415533.5 416293.3 417053.1 417812.9 418572.7 419332.4\n [41] 420092.2 420852.0 421611.8 422371.6 423131.3 423891.1 424650.9 425410.7\n [49] 426170.5 426930.3 427690.0 428449.8 429209.6 429969.4 430729.2 431488.9\n [57] 432248.7 433008.5 433768.3 434528.1 435287.8 436047.6 436807.4 437567.2\n [65] 438327.0 439086.8 439846.5 440606.3 441366.1 442125.9 442885.7 443645.4\n [73] 444405.2 445165.0 445924.8 446684.6 447444.3 448204.1 448963.9 449723.7\n [81] 450483.5 451243.2 452003.0 452762.8 453522.6 454282.4 455042.2 455801.9\n [89] 456561.7 457321.5 458081.3 458841.1 459600.8 460360.6 461120.4 461880.2\n [97] 462640.0 463399.7 464159.5 464919.3 465679.1 466438.9 467198.7 467958.4\n[105] 468718.2 469478.0 470237.8 470997.6 471757.3 472517.1 473276.9 474036.7\n[113] 474796.5 475556.2 476316.0 477075.8 477835.6 478595.4 479355.1 480114.9\n[121] 480874.7 481634.5 482394.3 483154.1 483913.8 484673.6 485433.4 486193.2\n[129] 486953.0 487712.7 488472.5 489232.3 489992.1 490751.9 491511.6 492271.4\n[137] 493031.2 493791.0 494550.8 495310.6 496070.3 496830.1 497589.9 498349.7\n[145] 499109.5 499869.2 500629.0 501388.8 502148.6 502908.4 503668.1 504427.9\n[153] 505187.7 505947.5 506707.3 507467.0 508226.8 508986.6 509746.4 510506.2\n[161] 511266.0 512025.7 512785.5 513545.3 514305.1 515064.9 515824.6 516584.4\n[169] 517344.2 518104.0 518863.8 519623.5 520383.3 521143.1 521902.9 522662.7\n[177] 523422.5 524182.2 524942.0 525701.8 526461.6 527221.4 527981.1 528740.9\n[185] 529500.7 530260.5 531020.3 531780.0 532539.8 533299.6 534059.4 534819.2\n[193] 535578.9 536338.7 537098.5 537858.3 538618.1 539377.9 540137.6 540897.4\n[201] 541657.2 542417.0 543176.8 543936.5 544696.3 545456.1 546215.9 546975.7\n[209] 547735.4 548495.2 549255.0 550014.8 550774.6 551534.4 552294.1 553053.9\n[217] 553813.7 554573.5 555333.3 556093.0 556852.8 557612.6 558372.4 559132.2\n[225] 559891.9 560651.7 561411.5 562171.3 562931.1 563690.8 564450.6 565210.4\n[233] 565970.2 566730.0 567489.8 568249.5 569009.3 569769.1 570528.9 571288.7\n[241] 572048.4 572808.2 573568.0 574327.8 575087.6 575847.3 576607.1 577366.9\n[249] 578126.7 578886.5 579646.3 580406.0 581165.8 581925.6 582685.4 583445.2\n[257] 584204.9 584964.7 585724.5 586484.3 587244.1 588003.8 588763.6 589523.4\n[265] 590283.2 591043.0 591802.8 592562.5 593322.3 594082.1 594841.9 595601.7\n[273] 596361.4 597121.2 597881.0 598640.8 599400.6 600160.3 600920.1 601679.9\n[281] 602439.7 603199.5 603959.2 604719.0 605478.8 606238.6 606998.4 607758.2\n[289] 608517.9 609277.7 610037.5 610797.3 611557.1 612316.8 613076.6 613836.4\n[297] 614596.2 615356.0 616115.7 616875.5 617635.3 618395.1 619154.9 619914.7\n[305] 620674.4 621434.2 622194.0 622953.8 623713.6 624473.3 625233.1 625992.9\n[313] 626752.7 627512.5 628272.2 629032.0 629791.8 630551.6 631311.4 632071.1\n[321] 632830.9 633590.7 634350.5 635110.3 635870.1 636629.8 637389.6 638149.4\n[329] 638909.2 639669.0 640428.7 641188.5 641948.3 642708.1 643467.9 644227.6\n[337] 644987.4 645747.2 646507.0 647266.8 648026.6 648786.3 649546.1 650305.9\n[345] 651065.7 651825.5 652585.2 653345.0 654104.8 654864.6 655624.4 656384.1\n[353] 657143.9 657903.7 658663.5 659423.3 660183.0 660942.8 661702.6 662462.4\n[361] 663222.2 663982.0 664741.7 665501.5 666261.3 667021.1 667780.9 668540.6\n[369] 669300.4 670060.2 670820.0 671579.8 672339.5 673099.3 673859.1 674618.9\n[377] 675378.7 676138.5 676898.2 677658.0 678417.8 679177.6 679937.4 680697.1\n[385] 681456.9 682216.7 682976.5 683736.3 684496.0 685255.8 686015.6 686775.4\n[393] 687535.2 688294.9 689054.7 689814.5 690574.3 691334.1 692093.9 692853.6\n[401] 693613.4 694373.2 695133.0 695892.8 696652.5 697412.3 698172.1 698931.9\n[409] 699691.7 700451.4 701211.2 701971.0 702730.8 703490.6 704250.4 705010.1\n[417] 705769.9 706529.7 707289.5 708049.3 708809.0 709568.8 710328.6 711088.4\n[425] 711848.2 712607.9 713367.7 714127.5 714887.3 715647.1 716406.8 717166.6\n[433] 717926.4 718686.2 719446.0 720205.8 720965.5 721725.3 722485.1 723244.9\n[441] 724004.7 724764.4 725524.2 726284.0 727043.8 727803.6 728563.3 729323.1\n[449] 730082.9 730842.7 731602.5 732362.3 733122.0 733881.8 734641.6 735401.4\n[457] 736161.2 736920.9 737680.7 738440.5 739200.3 739960.1 740719.8 741479.6\n[465] 742239.4 742999.2 743759.0 744518.7 745278.5 746038.3 746798.1 747557.9\n[473] 748317.7 749077.4 749837.2 750597.0 751356.8 752116.6 752876.3 753636.1\n[481] 754395.9 755155.7 755915.5 756675.2 757435.0 758194.8 758954.6 759714.4\n[489] 760474.2 761233.9 761993.7 762753.5 763513.3 764273.1 765032.8 765792.6\n[497] 766552.4"
  },
  {
    "objectID": "source/reference/ref/slice_time.html",
    "href": "source/reference/ref/slice_time.html",
    "title": "gdalcubes",
    "section": "",
    "text": "Extract a single time slice from a data cube\n\n\nCreate a proxy data cube, which extracts a time slice from a data cube defined by label (datetime string) or integer index.\n\n\n\nslice_time(cube, datetime = NULL, it = NULL)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ncube\nsource data cube\n\n\ndatetime\ncharacter; datetime string of the time slice\n\n\nit\ninteger; index of the time slice (zero-based)\n\n\n\n\n\n\nEither datetime or it must be non-NULL. If both arguments are provided, the integer index it is ignored.\n\n\n\nThis function returns a proxy object, i.e., it will not start any computations besides deriving the shape of the result.\n\n\n\n\n# create image collection from example Landsat data only \n# if not already done in other examples\nif (!file.exists(file.path(tempdir(), \"L8.db\"))) {\n  L8_files <- list.files(system.file(\"L8NY18\", package = \"gdalcubes\"),\n                         \".TIF\", recursive = TRUE, full.names = TRUE)\n  create_image_collection(L8_files, \"L8_L1TP\", file.path(tempdir(), \"L8.db\"), quiet = TRUE) \n}\nL8.col = image_collection(file.path(tempdir(), \"L8.db\"))\nv = cube_view(extent=list(left=388941.2, right=766552.4, \n              bottom=4345299, top=4744931, t0=\"2018-01\", t1=\"2018-12\"),\n              srs=\"EPSG:32618\", nx = 497, ny=526, dt=\"P1M\", aggregation = \"median\")\nL8.cube = raster_cube(L8.col, v, mask=image_mask(\"BQA\", bits=4, values=16))\nL8.rgb = select_bands(L8.cube, c(\"B02\", \"B03\", \"B04\"))\nL8.slice = slice_time(L8.rgb, \"2018-03\")\nL8.slice\n\nA GDAL data cube proxy object\n\nDimensions:\n         low       high count       pixel_size chunk_size\nt 2018-03-01 2018-03-31     1              P1M          1\ny    4345299    4744931   526 759.756653992395        384\nx   388941.2   766552.4   497 759.781086519115        384\n\nBands:\n  name offset scale nodata unit\n1  B02      0     1    NaN     \n2  B03      0     1    NaN     \n3  B04      0     1    NaN     \n\nplot(L8.slice, rgb=3:1, zlim=c(5000,12000))"
  },
  {
    "objectID": "source/reference/ref/print.cube.html",
    "href": "source/reference/ref/print.cube.html",
    "title": "gdalcubes",
    "section": "",
    "text": "Print data cube information\n\n\nPrints information about the dimensions and bands of a data cube.\n\n\n\nprint.cube(x, ...)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nObject of class “cube”\n\n\n…\nFurther arguments passed to the generic print function\n\n\n\n\n\n\n\n# create image collection from example Landsat data only \n# if not already done in other examples\nif (!file.exists(file.path(tempdir(), \"L8.db\"))) {\n  L8_files <- list.files(system.file(\"L8NY18\", package = \"gdalcubes\"),\n                         \".TIF\", recursive = TRUE, full.names = TRUE)\n  create_image_collection(L8_files, \"L8_L1TP\", file.path(tempdir(), \"L8.db\"), quiet = TRUE) \n}\n\nL8.col = image_collection(file.path(tempdir(), \"L8.db\"))\nv = cube_view(extent=list(left=388941.2, right=766552.4, \n              bottom=4345299, top=4744931, t0=\"2018-01\", t1=\"2018-12\"),\n              srs=\"EPSG:32618\", nx = 497, ny=526, dt=\"P1M\")\nprint(raster_cube(L8.col, v))\n\nA GDAL data cube proxy object\n\nDimensions:\n         low       high count       pixel_size chunk_size\nt 2018-01-01 2018-12-31    12              P1M          1\ny    4345299    4744931   526 759.756653992395        384\nx   388941.2   766552.4   497 759.781086519115        384\n\nBands:\n   name offset scale nodata unit\n1   B01      0     1    NaN     \n2   B02      0     1    NaN     \n3   B03      0     1    NaN     \n4   B04      0     1    NaN     \n5   B05      0     1    NaN     \n6   B06      0     1    NaN     \n7   B07      0     1    NaN     \n8   B08      0     1    NaN     \n9   B09      0     1    NaN     \n10  B10      0     1    NaN     \n11  B11      0     1    NaN     \n12  BQA      0     1    NaN"
  },
  {
    "objectID": "source/reference/ref/nt.html",
    "href": "source/reference/ref/nt.html",
    "title": "gdalcubes",
    "section": "",
    "text": "Query data cube properties\n\n\nQuery data cube properties\n\n\n\nnt(obj)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobj\na data cube proxy object (class cube)\n\n\n\n\n\n\nNumber of pixels in the time dimension\n\n\n\n\n# create image collection from example Landsat data only \n# if not already done in other examples\nif (!file.exists(file.path(tempdir(), \"L8.db\"))) {\n  L8_files <- list.files(system.file(\"L8NY18\", package = \"gdalcubes\"),\n                         \".TIF\", recursive = TRUE, full.names = TRUE)\n  create_image_collection(L8_files, \"L8_L1TP\", file.path(tempdir(), \"L8.db\"), quiet = TRUE) \n}\n\nL8.col = image_collection(file.path(tempdir(), \"L8.db\"))\nv = cube_view(extent=list(left=388941.2, right=766552.4, \n              bottom=4345299, top=4744931, t0=\"2018-04\", t1=\"2018-06\"),\n              srs=\"EPSG:32618\", nx = 497, ny=526, dt=\"P1M\")\nnt(raster_cube(L8.col, v))\n\n[1] 3"
  },
  {
    "objectID": "source/reference/ref/filter_geom.html",
    "href": "source/reference/ref/filter_geom.html",
    "title": "gdalcubes",
    "section": "",
    "text": "Filter data cube pixels by a polygon\n\n\nCreate a proxy data cube, which filters pixels by a spatial (multi)polygon For all pixels whose center is within the polygon, the original\n\n\n\nfilter_geom(cube, geom, srs = NULL)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ncube\nsource data cube\n\n\ngeom\neither a WKT string, or an sfc or sfg object (sf package)\n\n\nsrs\nstring identifier of the polygon’s coordinate reference system understandable for GDAL\n\n\n\n\n\n\nThe resulting data cube will not be cropped but pixels outside of the polygon will be set to NAN.\nIf geom is provided as an sfc object with length > 1, geometries will be combined with sf::st_combine() before.\nThe geometry is automatically transformed to the data cube’s spatial reference system if needed.\n\n\n\na proxy data cube object\n\n\n\nThis function returns a proxy object, i.e., it will not start any computations besides deriving the shape of the result.\n\n\n\n\n# create image collection from example Landsat data only \n# if not already done in other examples\nif (!file.exists(file.path(tempdir(), \"L8.db\"))) {\n  L8_files <- list.files(system.file(\"L8NY18\", package = \"gdalcubes\"),\n                         \".TIF\", recursive = TRUE, full.names = TRUE)\n  create_image_collection(L8_files, \"L8_L1TP\", file.path(tempdir(), \"L8.db\"), quiet = TRUE) \n}\n\nL8.col = image_collection(file.path(tempdir(), \"L8.db\"))\nv = cube_view(extent=list(left=388941.2, right=766552.4, \n              bottom=4345299, top=4744931, t0=\"2018-01\", t1=\"2018-06\"),\n              srs=\"EPSG:32618\", nx = 497, ny=526, dt=\"P1M\")\nL8.cube = raster_cube(L8.col, v) \nL8.cube = select_bands(L8.cube, c(\"B04\", \"B05\")) \nL8.ndvi = apply_pixel(L8.cube, \"(B05-B04)/(B05+B04)\", \"NDVI\")\nWKT = gsub(pattern='\\\\n',replacement=\"\",x = \n  \"Polygon ((-74.3541 40.9254, \n             -73.9813 41.2467, \n             -73.9997 41.4400, \n             -74.5362 41.1795, \n             -74.6286 40.9137, \n             -74.3541 40.9254))\")\nL8.ndvi.filtered = filter_geom(L8.ndvi, WKT, \"EPSG:4326\")\nL8.ndvi.filtered\n\nA GDAL data cube proxy object\n\nDimensions:\n         low       high count       pixel_size chunk_size\nt 2018-01-01 2018-06-30     6              P1M          1\ny    4345299    4744931   526 759.756653992395        384\nx   388941.2   766552.4   497 759.781086519115        384\n\nBands:\n  name offset scale nodata unit\n1 NDVI      0     1    NaN     \n\nplot(L8.ndvi.filtered)"
  },
  {
    "objectID": "source/reference/ref/join_bands.html",
    "href": "source/reference/ref/join_bands.html",
    "title": "gdalcubes",
    "section": "",
    "text": "Join bands of two identically shaped data cubes\n\n\nCreate a proxy data cube, which joins the bands of two identically shaped data cubes. The resulting cube will have bands from both input cubes.\n\n\n\njoin_bands(cube_list, cube_names = NULL)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ncube_list\na list with two or more source data cubes\n\n\ncube_names\nlist or character vector with optional name prefixes for bands in the output data cube (see Details)\n\n\n\n\n\n\nThe number of provided cube_names must match the number of provided input cubes. If no cube_names are provided, bands of the output cube will adopt original names from the input cubes (without any prefix). If any two of the input bands have identical names, prefixes default prefixes (“X1”, “X2”, …) will be used.\n\n\n\nproxy data cube object\n\n\n\nThis function returns a proxy object, i.e., it will not start any computations besides deriving the shape of the result.\n\n\n\n\n# create image collection from example Landsat data only \n# if not already done in other examples\nif (!file.exists(file.path(tempdir(), \"L8.db\"))) {\n  L8_files <- list.files(system.file(\"L8NY18\", package = \"gdalcubes\"),\n                         \".TIF\", recursive = TRUE, full.names = TRUE)\n  create_image_collection(L8_files, \"L8_L1TP\", file.path(tempdir(), \"L8.db\"), quiet = TRUE) \n}\n\nL8.col = image_collection(file.path(tempdir(), \"L8.db\"))\nv = cube_view(extent=list(left=388941.2, right=766552.4,\n                          bottom=4345299, top=4744931, t0=\"2018-01\", t1=\"2018-05\"),\n                          srs=\"EPSG:32618\", nx = 497, ny=526, dt=\"P1M\")\nL8.cube = raster_cube(L8.col, v)\nL8.cube.b04 = select_bands(raster_cube(L8.col, v), c(\"B04\"))\nL8.cube.b05 = select_bands(raster_cube(L8.col, v), c(\"B05\"))\njoin_bands(list(L8.cube.b04,L8.cube.b05))\n\nA GDAL data cube proxy object\n\nDimensions:\n         low       high count       pixel_size chunk_size\nt 2018-01-01 2018-05-31     5              P1M          1\ny    4345299    4744931   526 759.756653992395        384\nx   388941.2   766552.4   497 759.781086519115        384\n\nBands:\n    name offset scale nodata unit\n1 X1.B04      0     1    NaN     \n2 X2.B05      0     1    NaN     \n\nplot(join_bands(list(L8.cube.b04,L8.cube.b05)))"
  },
  {
    "objectID": "source/reference/ref/select_bands.html",
    "href": "source/reference/ref/select_bands.html",
    "title": "gdalcubes",
    "section": "",
    "text": "Select bands of a data cube\n\n\nCreate a proxy data cube, which selects specific bands of a data cube. The resulting cube will drop any other bands.\n\n\n\nselect_bands(cube, bands)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ncube\nsource data cube\n\n\nbands\ncharacter vector with band names\n\n\n\n\n\n\nproxy data cube object\n\n\n\nThis function returns a proxy object, i.e., it will not start any computations besides deriving the shape of the result.\nFor performance reasons, select_bands should always be called directly on a cube created with raster_cube and drop all unneded bands. This allows to reduce RasterIO and warp operations in GDAL.\n\n\n\n\n# create image collection from example Landsat data only \n# if not already done in other examples\nif (!file.exists(file.path(tempdir(), \"L8.db\"))) {\n  L8_files <- list.files(system.file(\"L8NY18\", package = \"gdalcubes\"),\n                         \".TIF\", recursive = TRUE, full.names = TRUE)\n  create_image_collection(L8_files, \"L8_L1TP\", file.path(tempdir(), \"L8.db\"), quiet = TRUE) \n}\n\nL8.col = image_collection(file.path(tempdir(), \"L8.db\"))\nv = cube_view(extent=list(left=388941.2, right=766552.4, \n              bottom=4345299, top=4744931, t0=\"2018-04\", t1=\"2018-07\"),\n              srs=\"EPSG:32618\", nx = 497, ny=526, dt=\"P1M\")\nL8.cube = raster_cube(L8.col, v) \nL8.rgb = select_bands(L8.cube, c(\"B02\", \"B03\", \"B04\"))\nL8.rgb\n\nA GDAL data cube proxy object\n\nDimensions:\n         low       high count       pixel_size chunk_size\nt 2018-04-01 2018-07-31     4              P1M          1\ny    4345299    4744931   526 759.756653992395        384\nx   388941.2   766552.4   497 759.781086519115        384\n\nBands:\n  name offset scale nodata unit\n1  B02      0     1    NaN     \n2  B03      0     1    NaN     \n3  B04      0     1    NaN     \n\nplot(L8.rgb, rgb=3:1)"
  },
  {
    "objectID": "source/reference/ref/collection_formats.html",
    "href": "source/reference/ref/collection_formats.html",
    "title": "gdalcubes",
    "section": "",
    "text": "List predefined image collection formats\n\n\ngdalcubes comes with some predefined collection formats e.g. to scan Sentinel 2 data. This function lists available formats including brief descriptions.\n\n\n\ncollection_formats(print = TRUE)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nprint\nlogical; should available formats and their descriptions be printed nicely, defaults to TRUE\n\n\n\n\n\n\nImage collection formats define how individual files / GDAL datasets relate to an image collection, i.e., which bands they contain, to which image they belong, and how to derive aquisition date/time. They are described as a set of regular expressions in a JSON file and used by gdalcubes to extract this information from the paths and/or filenames.\n\n\n\ndata.frame with columns name and description where the former describes the unique identifier that can be used in create_image_collection and the latter gives a brief description of the format.\n\n\n\n\ncollection_formats()\n\n   CHIRPS_v2_0_daily_p05_tif | Image collection format for CHIRPS v 2.0 daily\n                             | global precipitation dataset (0.05 degrees\n                             | resolution) from GeoTIFFs, expects list of .tif\n                             | or .tif.gz files as input. [TAGS: CHIRPS,\n                             | precipitation]\n CHIRPS_v2_0_monthly_p05_tif | Image collection format for CHIRPS v 2.0 monthly\n                             | global precipitation dataset (0.05 degrees\n                             | resolution) from GeoTIFFs, expects list of .tif\n                             | or .tif.gz files as input. [TAGS: CHIRPS,\n                             | precipitation]\n           ESA_CCI_SM_ACTIVE | Collection format for ESA CCI soil moisture\n                             | active product (version 4.7) [TAGS: Soil\n                             | Moisture, ESA, CCI]\n          ESA_CCI_SM_PASSIVE | Collection format for ESA CCI soil moisture\n                             | passive product (version 4.7) [TAGS: Soil\n                             | Moisture, ESA, CCI]\n   GPM_IMERG_3B_DAY_GIS_V06A | Collection format for daily\n                             | IMERG_3B_DAY_GIS_V06A data [TAGS: Precipitation,\n                             | GPM, IMERG]\n                     L8_L1TP | Collection format for Landsat 8 Level 1 TP\n                             | product [TAGS: Landsat, USGS, Level 1, NASA]\n                       L8_SR | Collection format for Landsat 8 surface\n                             | reflectance product [TAGS: Landsat, USGS, Level\n                             | 2, NASA, surface reflectance]\n                     MCD64A1 | Collection format for the MODIS MCD64A1 product\n                             | (burned area by day) [TAGS: MODIS, Fire]\n                     MxD09GA | Collection format for selected bands from the\n                             | MODIS MxD09GA (Aqua and Terra) product [TAGS:\n                             | MODIS, surface reflectance]\n                     MxD10A2 | Collection format for selected bands from the\n                             | MODIS MxD10A2 (Aqua and Terra) v006 Snow Cover\n                             | product [TAGS: MODIS, Snow Cover]\n                     MxD11A1 | Collection format for selected bands from the\n                             | MODIS MxD11A2 (Aqua and Terra) v006 Land Surface\n                             | Temperature product [TAGS: MODIS, LST]\n                     MxD11A2 | Collection format for selected bands from the\n                             | MODIS MxD11A2 (Aqua and Terra) v006 Land Surface\n                             | Temperature product [TAGS: MODIS, LST]\n                     MxD13A2 | Collection format for selected bands from the\n                             | MODIS MxD13A2 (Aqua and Terra) product [TAGS:\n                             | MODIS, VI, NDVI, EVI]\n                     MxD13A3 | Collection format for selected bands from the\n                             | MODIS MxD13A3 (Aqua and Terra) product [TAGS:\n                             | MODIS, VI, NDVI, EVI]\n                     MxD13Q1 | Collection format for selected bands from the\n                             | MODIS MxD13Q1 (Aqua and Terra) product [TAGS:\n                             | MODIS, VI, NDVI, EVI]\n                     MxD14A2 | Collection format for the MODIS MxD14A2 (Aqua\n                             | and Terra) product [TAGS: MODIS, Fire]\nPlanetScope_3B_AnalyticMS_SR | Image collection format for PlanetScope 4-band\n                             | scenes [TAGS: PlanetScope, BOA, Surface\n                             | Reflectance]\n            Sentinel1_IW_GRD | Image collection format for Sentinel 1 Level 1\n                             | GRD data as downloaded from the Copernicus Open\n                             | Access Hub, expects a list of file paths as\n                             | input. The format works on original ZIP\n                             | compressed as well as uncompressed imagery.\n                             | [TAGS: Sentinel, Copernicus, ESA, SAR]\n               Sentinel2_L1C | Image collection format for Sentinel 2 Level 1C\n                             | data as downloaded from the Copernicus Open\n                             | Access Hub, expects a list of file paths as\n                             | input. The format works on original ZIP\n                             | compressed as well as uncompressed imagery.\n                             | [TAGS: Sentinel, Copernicus, ESA, TOA]\n           Sentinel2_L1C_AWS | Image collection format for Sentinel 2 Level 1C\n                             | data in AWS [TAGS: Sentinel, Copernicus, ESA,\n                             | TOA]\n               Sentinel2_L2A | Image collection format for Sentinel 2 Level 2A\n                             | data as downloaded from the Copernicus Open\n                             | Access Hub, expects a list of file paths as\n                             | input. The format should work on original ZIP\n                             | compressed as well as uncompressed imagery.\n                             | [TAGS: Sentinel, Copernicus, ESA, BOA, Surface\n                             | Reflectance]\n         Sentinel2_L2A_THEIA | Image collection format for Sentinel 2 Level 2A\n                             | data as downloaded from Theia. [TAGS: Sentinel,\n                             | ESA, Flat Reflectance, Theia]"
  },
  {
    "objectID": "source/reference/ref/extent.html",
    "href": "source/reference/ref/extent.html",
    "title": "gdalcubes",
    "section": "",
    "text": "Derive the spatiotemporal extent of an image collection\n\n\nDerive the spatiotemporal extent of an image collection\n\n\n\nextent(x, srs = \"EPSG:4326\")\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nimage collection proxy object\n\n\nsrs\ntarget spatial reference system\n\n\n\n\n\n\na list with elements left, right, bottom, top, t0 (start date/time), and t1 (end date/time)\n\n\n\n\n# create image collection from example Landsat data only \n# if not already done in other examples\nif (!file.exists(file.path(tempdir(), \"L8.db\"))) {\n  L8_files <- list.files(system.file(\"L8NY18\", package = \"gdalcubes\"),\n                         \".TIF\", recursive = TRUE, full.names = TRUE)\n  create_image_collection(L8_files, \"L8_L1TP\", file.path(tempdir(), \"L8.db\"), quiet = TRUE) \n}\n\nL8.col = image_collection(file.path(tempdir(), \"L8.db\"))\nextent(L8.col,\"EPSG:32618\")\n\n$left\n[1] 388941.2\n\n$right\n[1] 766552.4\n\n$top\n[1] 4744931\n\n$bottom\n[1] 4345299\n\n$t0\n[1] \"2018-01-06T00:00:00\"\n\n$t1\n[1] \"2018-12-17T00:00:00\"\n\ncube_view(extent=extent(L8.col,\"EPSG:32618\"),\n          srs=\"EPSG:32618\", nx = 497, ny=526, dt=\"P1M\")\n\nA data cube view object\n\nDimensions:\n               low             high count       pixel_size\nt       2018-01-01       2018-12-31    12              P1M\ny 4345299.48874003 4744931.28639543   526 759.756269306837\nx 388941.155555047 766552.357592417   497 759.781090618451\n\nSRS: \"EPSG:32618\"\nTemporal aggregation method: \"first\"\nSpatial resampling method: \"near\""
  },
  {
    "objectID": "source/reference/ref/as_array.html",
    "href": "source/reference/ref/as_array.html",
    "title": "gdalcubes",
    "section": "",
    "text": "Convert a data cube to an in-memory R array\n\n\nConvert a data cube to an in-memory R array\n\n\n\nas_array(x)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\ndata cube\n\n\n\n\n\n\nFour dimensional array with dimensions band, t, y, x\n\n\n\nDepending on the data cube size, this function may require substantial amounts of main memory, i.e. it makes sense for small data cubes only.\n\n\n\n\n# create image collection from example Landsat data only \n# if not already done in other examples\nif (!file.exists(file.path(tempdir(), \"L8.db\"))) {\n  L8_files <- list.files(system.file(\"L8NY18\", package = \"gdalcubes\"),\n                         \".TIF\", recursive = TRUE, full.names = TRUE)\n  create_image_collection(L8_files, \"L8_L1TP\", file.path(tempdir(), \"L8.db\"), quiet = TRUE) \n}\n\nL8.col = image_collection(file.path(tempdir(), \"L8.db\"))\nv = cube_view(extent=list(left=388941.2, right=766552.4, \n              bottom=4345299, top=4744931, t0=\"2018-04\", t1=\"2018-05\"),\n              srs=\"EPSG:32618\", nx = 100, ny=100, dt=\"P1M\")\nx = as_array(select_bands(raster_cube(L8.col, v), c(\"B04\", \"B05\")))\ndim(x)\n\n[1]   2   2 100 100\n\ndimnames(x)\n\n$bands\n[1] \"B04\" \"B05\"\n\n$t\n[1] \"2018-04-01\" \"2018-05-01\"\n\n$y\n  [1] \"4345299\"    \"4349295.32\" \"4353291.64\" \"4357287.96\" \"4361284.28\"\n  [6] \"4365280.6\"  \"4369276.92\" \"4373273.24\" \"4377269.56\" \"4381265.88\"\n [11] \"4385262.2\"  \"4389258.52\" \"4393254.84\" \"4397251.16\" \"4401247.48\"\n [16] \"4405243.8\"  \"4409240.12\" \"4413236.44\" \"4417232.76\" \"4421229.08\"\n [21] \"4425225.4\"  \"4429221.72\" \"4433218.04\" \"4437214.36\" \"4441210.68\"\n [26] \"4445207\"    \"4449203.32\" \"4453199.64\" \"4457195.96\" \"4461192.28\"\n [31] \"4465188.6\"  \"4469184.92\" \"4473181.24\" \"4477177.56\" \"4481173.88\"\n [36] \"4485170.2\"  \"4489166.52\" \"4493162.84\" \"4497159.16\" \"4501155.48\"\n [41] \"4505151.8\"  \"4509148.12\" \"4513144.44\" \"4517140.76\" \"4521137.08\"\n [46] \"4525133.4\"  \"4529129.72\" \"4533126.04\" \"4537122.36\" \"4541118.68\"\n [51] \"4545115\"    \"4549111.32\" \"4553107.64\" \"4557103.96\" \"4561100.28\"\n [56] \"4565096.6\"  \"4569092.92\" \"4573089.24\" \"4577085.56\" \"4581081.88\"\n [61] \"4585078.2\"  \"4589074.52\" \"4593070.84\" \"4597067.16\" \"4601063.48\"\n [66] \"4605059.8\"  \"4609056.12\" \"4613052.44\" \"4617048.76\" \"4621045.08\"\n [71] \"4625041.4\"  \"4629037.72\" \"4633034.04\" \"4637030.36\" \"4641026.68\"\n [76] \"4645023\"    \"4649019.32\" \"4653015.64\" \"4657011.96\" \"4661008.28\"\n [81] \"4665004.6\"  \"4669000.92\" \"4672997.24\" \"4676993.56\" \"4680989.88\"\n [86] \"4684986.2\"  \"4688982.52\" \"4692978.84\" \"4696975.16\" \"4700971.48\"\n [91] \"4704967.8\"  \"4708964.12\" \"4712960.44\" \"4716956.76\" \"4720953.08\"\n [96] \"4724949.4\"  \"4728945.72\" \"4732942.04\" \"4736938.36\" \"4740934.68\"\n\n$x\n  [1] \"388941.2\"   \"392717.312\" \"396493.424\" \"400269.536\" \"404045.648\"\n  [6] \"407821.76\"  \"411597.872\" \"415373.984\" \"419150.096\" \"422926.208\"\n [11] \"426702.32\"  \"430478.432\" \"434254.544\" \"438030.656\" \"441806.768\"\n [16] \"445582.88\"  \"449358.992\" \"453135.104\" \"456911.216\" \"460687.328\"\n [21] \"464463.44\"  \"468239.552\" \"472015.664\" \"475791.776\" \"479567.888\"\n [26] \"483344\"     \"487120.112\" \"490896.224\" \"494672.336\" \"498448.448\"\n [31] \"502224.56\"  \"506000.672\" \"509776.784\" \"513552.896\" \"517329.008\"\n [36] \"521105.12\"  \"524881.232\" \"528657.344\" \"532433.456\" \"536209.568\"\n [41] \"539985.68\"  \"543761.792\" \"547537.904\" \"551314.016\" \"555090.128\"\n [46] \"558866.24\"  \"562642.352\" \"566418.464\" \"570194.576\" \"573970.688\"\n [51] \"577746.8\"   \"581522.912\" \"585299.024\" \"589075.136\" \"592851.248\"\n [56] \"596627.36\"  \"600403.472\" \"604179.584\" \"607955.696\" \"611731.808\"\n [61] \"615507.92\"  \"619284.032\" \"623060.144\" \"626836.256\" \"630612.368\"\n [66] \"634388.48\"  \"638164.592\" \"641940.704\" \"645716.816\" \"649492.928\"\n [71] \"653269.04\"  \"657045.152\" \"660821.264\" \"664597.376\" \"668373.488\"\n [76] \"672149.6\"   \"675925.712\" \"679701.824\" \"683477.936\" \"687254.048\"\n [81] \"691030.16\"  \"694806.272\" \"698582.384\" \"702358.496\" \"706134.608\"\n [86] \"709910.72\"  \"713686.832\" \"717462.944\" \"721239.056\" \"725015.168\"\n [91] \"728791.28\"  \"732567.392\" \"736343.504\" \"740119.616\" \"743895.728\"\n [96] \"747671.84\"  \"751447.952\" \"755224.064\" \"759000.176\" \"762776.288\""
  },
  {
    "objectID": "source/reference/ref/rename_bands.html",
    "href": "source/reference/ref/rename_bands.html",
    "title": "gdalcubes",
    "section": "",
    "text": "Rename bands of a data cube\n\n\nCreate a proxy data cube, which renames specific bands of a data cube.\n\n\n\nrename_bands(cube, ...)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ncube\nsource data cube\n\n\n…\nnamed arguments with bands that will be renamed, see Details\n\n\n\n\n\n\nThe result data cube always contains the same number of bands. No subsetting is done if only names for some of the bands are provided. In this case, only provided bands are renamed whereas other bands keep their original name. Variable arguments must be named by the old band name and the new names must be provided as simple character values (see example).\n\n\n\nproxy data cube object\n\n\n\nThis function returns a proxy object, i.e., it will not start any computations besides deriving the shape of the result.\n\n\n\n\n# create image collection from example Landsat data only \n# if not already done in other examples\nif (!file.exists(file.path(tempdir(), \"L8.db\"))) {\n  L8_files <- list.files(system.file(\"L8NY18\", package = \"gdalcubes\"),\n                         \".TIF\", recursive = TRUE, full.names = TRUE)\n  create_image_collection(L8_files, \"L8_L1TP\", file.path(tempdir(), \"L8.db\"), quiet = TRUE) \n}\n\nL8.col = image_collection(file.path(tempdir(), \"L8.db\"))\nv = cube_view(extent=list(left=388941.2, right=766552.4, \n              bottom=4345299, top=4744931, t0=\"2018-04\", t1=\"2018-07\"),\n              srs=\"EPSG:32618\", nx = 497, ny=526, dt=\"P1M\")\nL8.cube = raster_cube(L8.col, v) \nL8.rgb = select_bands(L8.cube, c(\"B02\", \"B03\", \"B04\"))\nL8.rgb\n\nA GDAL data cube proxy object\n\nDimensions:\n         low       high count       pixel_size chunk_size\nt 2018-04-01 2018-07-31     4              P1M          1\ny    4345299    4744931   526 759.756653992395        384\nx   388941.2   766552.4   497 759.781086519115        384\n\nBands:\n  name offset scale nodata unit\n1  B02      0     1    NaN     \n2  B03      0     1    NaN     \n3  B04      0     1    NaN     \n\nL8.rgb = rename_bands(L8.cube, B02 = \"blue\", B03 = \"green\", B04 = \"red\")\nL8.rgb\n\nA GDAL data cube proxy object\n\nDimensions:\n         low       high count       pixel_size chunk_size\nt 2018-04-01 2018-07-31     4              P1M          1\ny    4345299    4744931   526 759.756653992395        384\nx   388941.2   766552.4   497 759.781086519115        384\n\nBands:\n   name offset scale nodata unit\n1  blue      0     1    NaN     \n2 green      0     1    NaN     \n3   red      0     1    NaN"
  },
  {
    "objectID": "source/reference/ref/print.image_collection.html",
    "href": "source/reference/ref/print.image_collection.html",
    "title": "gdalcubes",
    "section": "",
    "text": "Print image collection information\n\n\nPrints information about images in an image collection.\n\n\n\nprint.image_collection(x, ..., n = 6)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nObject of class “image_collection”\n\n\n…\nFurther arguments passed to the generic print function\n\n\nn\nNumber of images for which details are printed\n\n\n\n\n\n\n\n# create image collection from example Landsat data only \n# if not already done in other examples\nif (!file.exists(file.path(tempdir(), \"L8.db\"))) {\n  L8_files <- list.files(system.file(\"L8NY18\", package = \"gdalcubes\"),\n                         \".TIF\", recursive = TRUE, full.names = TRUE)\n  create_image_collection(L8_files, \"L8_L1TP\", file.path(tempdir(), \"L8.db\"), quiet = TRUE) \n}\n\nL8.col = image_collection(file.path(tempdir(), \"L8.db\"))\nprint(L8.col)\n\nImage collection object, referencing 19 images with 12 bands\nImages:\n                                      name      left      top   bottom\n1 LC08_L1TP_013032_20180131_20180207_01_T1 -74.67898 41.39099 39.25027\n2 LC08_L1TP_013032_20180405_20180417_01_T1 -74.70333 41.39106 39.25080\n3 LC08_L1TP_013032_20180421_20180502_01_T1 -74.70681 41.39107 39.25098\n4 LC08_L1TP_013032_20180710_20180717_01_T1 -74.66854 41.39096 39.24991\n5 LC08_L1TP_013032_20180827_20180911_01_T1 -74.67202 41.39097 39.25000\n6 LC08_L1TP_013032_20181030_20181115_01_T1 -74.69637 41.39104 39.25062\n      right            datetime        srs\n1 -71.92546 2018-01-31T00:00:00 EPSG:32618\n2 -71.94695 2018-04-05T00:00:00 EPSG:32618\n3 -71.95411 2018-04-21T00:00:00 EPSG:32618\n4 -71.91114 2018-07-10T00:00:00 EPSG:32618\n5 -71.91472 2018-08-27T00:00:00 EPSG:32618\n6 -71.93979 2018-10-30T00:00:00 EPSG:32618\n[ omitted 13 images ] \n\nBands:\n   name offset scale unit   nodata image_count\n1   B01      0     1      0.000000          19\n2   B02      0     1      0.000000          19\n3   B03      0     1      0.000000          19\n4   B04      0     1      0.000000          19\n5   B05      0     1      0.000000          19\n6   B06      0     1      0.000000          19\n7   B07      0     1      0.000000          19\n8   B08      0     1      0.000000          19\n9   B09      0     1      0.000000          19\n10  B10      0     1      0.000000          19\n11  B11      0     1      0.000000          19\n12  BQA      0     1                        19"
  },
  {
    "objectID": "source/reference/ref/dimensions.html",
    "href": "source/reference/ref/dimensions.html",
    "title": "gdalcubes",
    "section": "",
    "text": "Query data cube properties\n\n\nQuery data cube properties\n\n\n\ndimensions(obj)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobj\na data cube proxy object (class cube)\n\n\n\n\n\n\nElements of the returned list represent individual dimensions with properties such as dimension boundaries, names, and chunk size stored as inner lists\n\n\n\nDimension information as a list\n\n\n\n\n# create image collection from example Landsat data only \n# if not already done in other examples\nif (!file.exists(file.path(tempdir(), \"L8.db\"))) {\n  L8_files <- list.files(system.file(\"L8NY18\", package = \"gdalcubes\"),\n                         \".TIF\", recursive = TRUE, full.names = TRUE)\n  create_image_collection(L8_files, \"L8_L1TP\", file.path(tempdir(), \"L8.db\"), quiet = TRUE) \n}\n\nL8.col = image_collection(file.path(tempdir(), \"L8.db\"))\nv = cube_view(extent=list(left=388941.2, right=766552.4, \n              bottom=4345299, top=4744931, t0=\"2018-04\", t1=\"2018-06\"),\n              srs=\"EPSG:32618\", nx = 497, ny=526, dt=\"P1M\")\ndimensions(raster_cube(L8.col, v))\n\n$t\n$t$low\n[1] \"2018-04-01\"\n\n$t$high\n[1] \"2018-06-30\"\n\n$t$count\n[1] 3\n\n$t$pixel_size\n[1] \"P1M\"\n\n$t$chunk_size\n[1] 1\n\n\n$y\n$y$low\n[1] 4345299\n\n$y$high\n[1] 4744931\n\n$y$count\n[1] 526\n\n$y$pixel_size\n[1] 759.7567\n\n$y$chunk_size\n[1] 384\n\n\n$x\n$x$low\n[1] 388941.2\n\n$x$high\n[1] 766552.4\n\n$x$count\n[1] 497\n\n$x$pixel_size\n[1] 759.7811\n\n$x$chunk_size\n[1] 384"
  },
  {
    "objectID": "source/reference/ref/fill_time.html",
    "href": "source/reference/ref/fill_time.html",
    "title": "gdalcubes",
    "section": "",
    "text": "Fill NA data cube pixels by simple time series interpolation\n\n\nCreate a proxy data cube, which fills NA pixels of a data cube by nearest neighbor or linear time series interpolation.\n\n\n\nfill_time(cube, method = \"near\")\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ncube\nsource data cube\n\n\nmethod\ninterpolation method, can be “near” (nearest neighbor), “linear” (linear interpolation), “locf” (last observation carried forward), or “nocb” (next observation carried backward)\n\n\n\n\n\n\nPlease notice that completely empty (NA) time series will not be filled, i.e. the result cube might still contain NA values.\n\n\n\na proxy data cube object\n\n\n\nThis function returns a proxy object, i.e., it will not start any computations besides deriving the shape of the result.\n\n\n\n\n# create image collection from example Landsat data only \n# if not already done in other examples\nif (!file.exists(file.path(tempdir(), \"L8.db\"))) {\n  L8_files <- list.files(system.file(\"L8NY18\", package = \"gdalcubes\"),\n                         \".TIF\", recursive = TRUE, full.names = TRUE)\n  create_image_collection(L8_files, \"L8_L1TP\", file.path(tempdir(), \"L8.db\"), quiet = TRUE) \n}\nL8.col = image_collection(file.path(tempdir(), \"L8.db\"))\nv = cube_view(extent=list(left=388941.2, right=766552.4, \n              bottom=4345299, top=4744931, t0=\"2018-01\", t1=\"2018-12\"),\n              srs=\"EPSG:32618\", nx = 497, ny=526, dt=\"P3M\", aggregation = \"median\")\nL8.cube = raster_cube(L8.col, v, mask=image_mask(\"BQA\", bits=4, values=16))\nL8.rgb = select_bands(L8.cube, c(\"B02\", \"B03\", \"B04\"))\nL8.filled = fill_time(L8.rgb, \"linear\")\nL8.filled\n\nA GDAL data cube proxy object\n\nDimensions:\n         low       high count       pixel_size chunk_size\nt 2018-01-01 2018-12-31     4              P3M          1\ny    4345299    4744931   526 759.756653992395        384\nx   388941.2   766552.4   497 759.781086519115        384\n\nBands:\n  name offset scale nodata unit\n1  B02      0     1    NaN     \n2  B03      0     1    NaN     \n3  B04      0     1    NaN     \n\nplot(L8.filled, rgb=3:1, zlim=c(5000,12000))"
  },
  {
    "objectID": "source/reference/ref/reduce_space.html",
    "href": "source/reference/ref/reduce_space.html",
    "title": "gdalcubes",
    "section": "",
    "text": "Reduce multidimensional data over space\n\n\nThis generic function applies a reducer function over a data cube, an R array, or other classes if implemented.\n\n\n\nreduce_space(x, ...)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nobject to be reduced\n\n\n…\nfurther arguments passed to specific implementations\n\n\n\n\n\n\nreturn value and type depend on the class of x\n\n\n\n\n# create image collection from example Landsat data only \n# if not already done in other examples\nif (!file.exists(file.path(tempdir(), \"L8.db\"))) {\n  L8_files <- list.files(system.file(\"L8NY18\", package = \"gdalcubes\"),\n                         \".TIF\", recursive = TRUE, full.names = TRUE)\n  create_image_collection(L8_files, \"L8_L1TP\", file.path(tempdir(), \"L8.db\"), quiet = TRUE) \n}\n\nL8.col = image_collection(file.path(tempdir(), \"L8.db\"))\nv = cube_view(extent=list(left=388941.2, right=766552.4, \n              bottom=4345299, top=4744931, t0=\"2018-01\", t1=\"2018-12\"),\n              srs=\"EPSG:32618\", nx = 497, ny=526, dt=\"P1M\")\nreduce_space(raster_cube(L8.col, v) , \"median(B02)\")  \n\nA GDAL data cube proxy object\n\nDimensions:\n         low       high count pixel_size chunk_size\nt 2018-01-01 2018-12-31    12        P1M          1\ny    4345299    4744931     1     399632          1\nx   388941.2   766552.4     1   377611.2          1\n\nBands:\n        name offset scale nodata unit\n1 B02_median      0     1    NaN     \n\nd <- c(4,16,32,32)\nx <- array(rnorm(prod(d)), d)\ny <- reduce_space(x, function(v) {\n  apply(v, 1, mean)\n})\n\n\n\n\nreduce_space.cube\nreduce_space.array"
  },
  {
    "objectID": "source/reference/ref/aggregate_time.html",
    "href": "source/reference/ref/aggregate_time.html",
    "title": "gdalcubes",
    "section": "",
    "text": "Aggregate data cube time series to lower temporal resolution\n\n\nCreate a proxy data cube, which applies an aggregation function over pixel time series to lower temporal resolution.\n\n\n\naggregate_time(cube, dt, method = \"mean\", fact = NULL)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ncube\nsource data cube\n\n\ndt\ncharacter; new temporal resolution, datetime period string, e.g. “P1M”\n\n\nmethod\naggregation method, one of “mean”, “min”, “max”, “median”, “count”, “sum”, “prod”, “var”, and “sd”\n\n\nfact\nsimple integer factor defining how many cells become aggregated to a single new cell, can be used instead of dt\n\n\n\n\n\n\nThis function can be used to aggregate time series to lower resolution or to regularize a data cube with irregular (labeled) time axis. It is possible to change the unit of the temporal resolution (e.g. to create monthly composites from daily images). The size of the cube may be expanded automatically if the original temporal extent is not divisible by the new temporal size of pixels.\n\n\n\nThis function returns a proxy object, i.e., it will not start any computations besides deriving the shape of the result.\n\n\n\n\n# create image collection from example Landsat data only \n# if not already done in other examples\nif (!file.exists(file.path(tempdir(), \"L8.db\"))) {\n  L8_files <- list.files(system.file(\"L8NY18\", package = \"gdalcubes\"),\n                         \".TIF\", recursive = TRUE, full.names = TRUE)\n  create_image_collection(L8_files, \"L8_L1TP\", file.path(tempdir(), \"L8.db\"), quiet = TRUE) \n}\nL8.col = image_collection(file.path(tempdir(), \"L8.db\"))\nv = cube_view(extent=list(left=388941.2, right=766552.4, \n              bottom=4345299, top=4744931, t0=\"2018-01\", t1=\"2018-12\"),\n              srs=\"EPSG:32618\", nx = 497, ny=526, dt=\"P3M\", aggregation = \"median\")\nL8.cube = raster_cube(L8.col, v, mask=image_mask(\"BQA\", bits=4, values=16))\nL8.rgb = select_bands(L8.cube, c(\"B02\", \"B03\", \"B04\"))\nL8.two_monthly = aggregate_time(L8.rgb, \"P6M\", \"min\")\nL8.two_monthly\n\nA GDAL data cube proxy object\n\nDimensions:\n         low       high count       pixel_size chunk_size\nt 2018-01-01 2018-12-31     2              P6M          1\ny    4345299    4744931   526 759.756653992395        384\nx   388941.2   766552.4   497 759.781086519115        384\n\nBands:\n  name offset scale nodata unit\n1  B02      0     1    NaN     \n2  B03      0     1    NaN     \n3  B04      0     1    NaN     \n\nplot(L8.two_monthly, rgb=3:1, zlim=c(5000,12000))"
  },
  {
    "objectID": "source/reference/ref/reduce_space.array.html",
    "href": "source/reference/ref/reduce_space.array.html",
    "title": "gdalcubes",
    "section": "",
    "text": "Apply a function over space and bands in a four-dimensional (band, time, y, x) array and reduce spatial dimensions\n\n\nApply a function over space and bands in a four-dimensional (band, time, y, x) array and reduce spatial dimensions\n\n\n\nreduce_space.array(x, FUN, ...)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nfour-dimensional input array with dimensions band, time, y, x (in this order)\n\n\nFUN\nfunction which receives one spatial slice in a three-dimensional array with dimensions bands, y, x as input\n\n\n…\nfurther arguments passed to FUN\n\n\n\n\n\n\nFUN is expected to produce a numeric vector (or scalar) where elements are interpreted as new bands in the result.\n\n\n\nThis is a helper function that uses the same dimension ordering as gdalcubes streaming. It can be used to simplify the application of R functions e.g. over spatial slices in a data cube.\n\n\n\n\nd <- c(4,16,32,32)\nx <- array(rnorm(prod(d)), d)\n# reduce individual bands over spatial slices \ny <- reduce_space(x, function(v) {\n  apply(v, 1, mean)\n})\ndim(y)\n\n[1]  4 16  1  1"
  },
  {
    "objectID": "source/reference/ref/nbands.html",
    "href": "source/reference/ref/nbands.html",
    "title": "gdalcubes",
    "section": "",
    "text": "Query data cube properties\n\n\nQuery data cube properties\n\n\n\nnbands(obj)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobj\na data cube proxy object (class cube)\n\n\n\n\n\n\nNumber of bands\n\n\n\n\n# create image collection from example Landsat data only \n# if not already done in other examples\nif (!file.exists(file.path(tempdir(), \"L8.db\"))) {\n  L8_files <- list.files(system.file(\"L8NY18\", package = \"gdalcubes\"),\n                         \".TIF\", recursive = TRUE, full.names = TRUE)\n  create_image_collection(L8_files, \"L8_L1TP\", file.path(tempdir(), \"L8.db\"), quiet = TRUE) \n}\n\nL8.col = image_collection(file.path(tempdir(), \"L8.db\"))\nv = cube_view(extent=list(left=388941.2, right=766552.4, \n              bottom=4345299, top=4744931, t0=\"2018-04\", t1=\"2018-06\"),\n              srs=\"EPSG:32618\", nx = 497, ny=526, dt=\"P1M\")\nnbands(raster_cube(L8.col, v))\n\n[1] 12"
  },
  {
    "objectID": "source/reference/ref/reduce_space.cube.html",
    "href": "source/reference/ref/reduce_space.cube.html",
    "title": "gdalcubes",
    "section": "",
    "text": "Reduce a data cube over spatial (x,y or lat,lon) dimensions\n\n\nCreate a proxy data cube, which applies one or more reducer functions to selected bands over spatial slices of a data cube\n\n\n\nreduce_space.cube(x, expr, ..., FUN, names = NULL)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nsource data cube\n\n\nexpr\neither a single string, or a vector of strings defining which reducers will be applied over which bands of the input cube\n\n\n…\noptional additional expressions (if expr is not a vector)\n\n\nFUN\na user-defined R function applied over pixel time series (see Details)\n\n\nnames\ncharacter vector; if FUN is provided, names can be used to define the number and name of output bands\n\n\n\n\n\n\nNotice that expressions have a very simple format: the reducer is followed by the name of a band in parantheses. You cannot add more complex functions or arguments.\nPossible reducers currently are “min”, “max”, “sum”, “prod”, “count”, “mean”, “median”, “var”, “sd”.\n\n\n\nproxy data cube object\n\n\n\nImplemented reducers will ignore any NAN values (as na.rm=TRUE does).\nThis function returns a proxy object, i.e., it will not start any computations besides deriving the shape of the result.\n\n\n\n\n# create image collection from example Landsat data only \n# if not already done in other examples\nif (!file.exists(file.path(tempdir(), \"L8.db\"))) {\n  L8_files <- list.files(system.file(\"L8NY18\", package = \"gdalcubes\"),\n                         \".TIF\", recursive = TRUE, full.names = TRUE)\n  create_image_collection(L8_files, \"L8_L1TP\", file.path(tempdir(), \"L8.db\"), quiet = TRUE) \n}\n\nL8.col = image_collection(file.path(tempdir(), \"L8.db\"))\nv = cube_view(extent=list(left=388941.2, right=766552.4, \n              bottom=4345299, top=4744931, t0=\"2018-01\", t1=\"2018-12\"),\n              srs=\"EPSG:32618\", nx = 497, ny=526, dt=\"P1M\")\nL8.cube = raster_cube(L8.col, v) \nL8.b02 = select_bands(L8.cube, c(\"B02\"))\nL8.b02.median = reduce_space(L8.b02, \"median(B02)\")  \nL8.b02.median\n\nA GDAL data cube proxy object\n\nDimensions:\n         low       high count pixel_size chunk_size\nt 2018-01-01 2018-12-31    12        P1M          1\ny    4345299    4744931     1     399632          1\nx   388941.2   766552.4     1   377611.2          1\n\nBands:\n        name offset scale nodata unit\n1 B02_median      0     1    NaN     \n\nplot(L8.b02.median, key.pos=1)\n\nWarning in plot.cube(L8.b02.median, key.pos = 1): data cube is a pure time-\nseries, ignoring key.pos"
  },
  {
    "objectID": "source/reference/ref/ny.html",
    "href": "source/reference/ref/ny.html",
    "title": "gdalcubes",
    "section": "",
    "text": "Query data cube properties\n\n\nQuery data cube properties\n\n\n\nny(obj)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobj\na data cube proxy object (class cube)\n\n\n\n\n\n\nNumber of pixels in the y dimension\n\n\n\n\n# create image collection from example Landsat data only \n# if not already done in other examples\nif (!file.exists(file.path(tempdir(), \"L8.db\"))) {\n  L8_files <- list.files(system.file(\"L8NY18\", package = \"gdalcubes\"),\n                         \".TIF\", recursive = TRUE, full.names = TRUE)\n  create_image_collection(L8_files, \"L8_L1TP\", file.path(tempdir(), \"L8.db\"), quiet = TRUE) \n}\n\nL8.col = image_collection(file.path(tempdir(), \"L8.db\"))\nv = cube_view(extent=list(left=388941.2, right=766552.4, \n              bottom=4345299, top=4744931, t0=\"2018-04\", t1=\"2018-06\"),\n              srs=\"EPSG:32618\", nx = 497, ny=526, dt=\"P1M\")\nny(raster_cube(L8.col, v))\n\n[1] 526"
  },
  {
    "objectID": "source/reference/ref/as_json.html",
    "href": "source/reference/ref/as_json.html",
    "title": "gdalcubes",
    "section": "",
    "text": "Query data cube properties\n\n\ngdalcubes internally uses a graph to serialize data cubes (including chained operations on cubes). This function derives a JSON representation, which can be used to save data cube objects without pixel data to disk.\n\n\n\nas_json(obj, file = NULL)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobj\na data cube proxy object (class cube)\n\n\nfile\noptional output file\n\n\n\n\n\n\nIf file is NULL, the function returns a JSON string representing a graph that can be used to recreate the same chain of gdalcubes operations even in a different R sessions.\n\n\n\n\n# create image collection from example Landsat data only \n# if not already done in other examples\nif (!file.exists(file.path(tempdir(), \"L8.db\"))) {\n  L8_files <- list.files(system.file(\"L8NY18\", package = \"gdalcubes\"),\n                         \".TIF\", recursive = TRUE, full.names = TRUE)\n  create_image_collection(L8_files, \"L8_L1TP\", file.path(tempdir(), \"L8.db\"), quiet = TRUE) \n}\n\nL8.col = image_collection(file.path(tempdir(), \"L8.db\"))\nv = cube_view(extent=list(left=388941.2, right=766552.4, \n              bottom=4345299, top=4744931, t0=\"2018-04\", t1=\"2018-04\"),\n              srs=\"EPSG:32618\", nx = 497, ny=526, dt=\"P1M\")\ncat(as_json(select_bands(raster_cube(L8.col, v), c(\"B04\", \"B05\"))))\n\n{\n    \"bands\": [\n        \"B04\",\n        \"B05\"\n    ],\n    \"cube_type\": \"select_bands\",\n    \"in_cube\": {\n        \"chunk_size\": [\n            1,\n            384,\n            384\n        ],\n        \"cube_type\": \"image_collection\",\n        \"file\": \"/tmp/Rtmpvg7ehf/L8.db\",\n        \"view\": {\n            \"aggregation\": \"first\",\n            \"resampling\": \"near\",\n            \"space\": {\n                \"bottom\": 4345299,\n                \"left\": 388941.20000000001,\n                \"nx\": 497,\n                \"ny\": 526,\n                \"right\": 766552.40000000002,\n                \"srs\": \"EPSG:32618\",\n                \"top\": 4744931\n            },\n            \"time\": {\n                \"dt\": \"P1M\",\n                \"t0\": \"2018-04-01\",\n                \"t1\": \"2018-04-30\"\n            }\n        }\n    }\n}"
  },
  {
    "objectID": "source/reference/ref/dimension_values.html",
    "href": "source/reference/ref/dimension_values.html",
    "title": "gdalcubes",
    "section": "",
    "text": "Query coordinate values for all dimensions of a data cube\n\n\nDimension values give the coordinates along the spatial and temporal axes of a data cube.\n\n\n\ndimension_values(obj, datetime_unit = NULL)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobj\na data cube proxy (class cube), or a data cube view object\n\n\ndatetime_unit\nunit used to format values in the datetime dimension, one of “Y”, “m”, “d”, “H”, “M”, “S”, defaults to the unit of the cube.\n\n\n\n\n\n\nlist with elements t,y,x\n\n\n\n\n# create image collection from example Landsat data only \n# if not already done in other examples\nif (!file.exists(file.path(tempdir(), \"L8.db\"))) {\n  L8_files <- list.files(system.file(\"L8NY18\", package = \"gdalcubes\"),\n                         \".TIF\", recursive = TRUE, full.names = TRUE)\n  create_image_collection(L8_files, \"L8_L1TP\", file.path(tempdir(), \"L8.db\"), quiet = TRUE) \n}\n\nL8.col = image_collection(file.path(tempdir(), \"L8.db\"))\nv = cube_view(extent=list(left=388941.2, right=766552.4, \n              bottom=4345299, top=4744931, t0=\"2018-04\", t1=\"2018-06\"),\n              srs=\"EPSG:32618\", nx = 497, ny=526, dt=\"P1M\")\ndimension_values(raster_cube(L8.col, v))\n\n$t\n[1] \"2018-04-01\" \"2018-05-01\" \"2018-06-01\"\n\n$y\n  [1] 4345299 4346059 4346819 4347578 4348338 4349098 4349858 4350617 4351377\n [10] 4352137 4352897 4353656 4354416 4355176 4355936 4356695 4357455 4358215\n [19] 4358975 4359734 4360494 4361254 4362014 4362773 4363533 4364293 4365053\n [28] 4365812 4366572 4367332 4368092 4368851 4369611 4370371 4371131 4371890\n [37] 4372650 4373410 4374170 4374930 4375689 4376449 4377209 4377969 4378728\n [46] 4379488 4380248 4381008 4381767 4382527 4383287 4384047 4384806 4385566\n [55] 4386326 4387086 4387845 4388605 4389365 4390125 4390884 4391644 4392404\n [64] 4393164 4393923 4394683 4395443 4396203 4396962 4397722 4398482 4399242\n [73] 4400001 4400761 4401521 4402281 4403041 4403800 4404560 4405320 4406080\n [82] 4406839 4407599 4408359 4409119 4409878 4410638 4411398 4412158 4412917\n [91] 4413677 4414437 4415197 4415956 4416716 4417476 4418236 4418995 4419755\n[100] 4420515 4421275 4422034 4422794 4423554 4424314 4425073 4425833 4426593\n[109] 4427353 4428112 4428872 4429632 4430392 4431152 4431911 4432671 4433431\n[118] 4434191 4434950 4435710 4436470 4437230 4437989 4438749 4439509 4440269\n[127] 4441028 4441788 4442548 4443308 4444067 4444827 4445587 4446347 4447106\n[136] 4447866 4448626 4449386 4450145 4450905 4451665 4452425 4453184 4453944\n[145] 4454704 4455464 4456223 4456983 4457743 4458503 4459262 4460022 4460782\n[154] 4461542 4462302 4463061 4463821 4464581 4465341 4466100 4466860 4467620\n[163] 4468380 4469139 4469899 4470659 4471419 4472178 4472938 4473698 4474458\n[172] 4475217 4475977 4476737 4477497 4478256 4479016 4479776 4480536 4481295\n[181] 4482055 4482815 4483575 4484334 4485094 4485854 4486614 4487373 4488133\n[190] 4488893 4489653 4490413 4491172 4491932 4492692 4493452 4494211 4494971\n[199] 4495731 4496491 4497250 4498010 4498770 4499530 4500289 4501049 4501809\n[208] 4502569 4503328 4504088 4504848 4505608 4506367 4507127 4507887 4508647\n[217] 4509406 4510166 4510926 4511686 4512445 4513205 4513965 4514725 4515484\n[226] 4516244 4517004 4517764 4518524 4519283 4520043 4520803 4521563 4522322\n[235] 4523082 4523842 4524602 4525361 4526121 4526881 4527641 4528400 4529160\n[244] 4529920 4530680 4531439 4532199 4532959 4533719 4534478 4535238 4535998\n[253] 4536758 4537517 4538277 4539037 4539797 4540556 4541316 4542076 4542836\n[262] 4543595 4544355 4545115 4545875 4546635 4547394 4548154 4548914 4549674\n[271] 4550433 4551193 4551953 4552713 4553472 4554232 4554992 4555752 4556511\n[280] 4557271 4558031 4558791 4559550 4560310 4561070 4561830 4562589 4563349\n[289] 4564109 4564869 4565628 4566388 4567148 4567908 4568667 4569427 4570187\n[298] 4570947 4571706 4572466 4573226 4573986 4574746 4575505 4576265 4577025\n[307] 4577785 4578544 4579304 4580064 4580824 4581583 4582343 4583103 4583863\n[316] 4584622 4585382 4586142 4586902 4587661 4588421 4589181 4589941 4590700\n[325] 4591460 4592220 4592980 4593739 4594499 4595259 4596019 4596778 4597538\n[334] 4598298 4599058 4599817 4600577 4601337 4602097 4602857 4603616 4604376\n[343] 4605136 4605896 4606655 4607415 4608175 4608935 4609694 4610454 4611214\n[352] 4611974 4612733 4613493 4614253 4615013 4615772 4616532 4617292 4618052\n[361] 4618811 4619571 4620331 4621091 4621850 4622610 4623370 4624130 4624889\n[370] 4625649 4626409 4627169 4627928 4628688 4629448 4630208 4630968 4631727\n[379] 4632487 4633247 4634007 4634766 4635526 4636286 4637046 4637805 4638565\n[388] 4639325 4640085 4640844 4641604 4642364 4643124 4643883 4644643 4645403\n[397] 4646163 4646922 4647682 4648442 4649202 4649961 4650721 4651481 4652241\n[406] 4653000 4653760 4654520 4655280 4656039 4656799 4657559 4658319 4659078\n[415] 4659838 4660598 4661358 4662118 4662877 4663637 4664397 4665157 4665916\n[424] 4666676 4667436 4668196 4668955 4669715 4670475 4671235 4671994 4672754\n[433] 4673514 4674274 4675033 4675793 4676553 4677313 4678072 4678832 4679592\n[442] 4680352 4681111 4681871 4682631 4683391 4684150 4684910 4685670 4686430\n[451] 4687189 4687949 4688709 4689469 4690229 4690988 4691748 4692508 4693268\n[460] 4694027 4694787 4695547 4696307 4697066 4697826 4698586 4699346 4700105\n[469] 4700865 4701625 4702385 4703144 4703904 4704664 4705424 4706183 4706943\n[478] 4707703 4708463 4709222 4709982 4710742 4711502 4712261 4713021 4713781\n[487] 4714541 4715300 4716060 4716820 4717580 4718340 4719099 4719859 4720619\n[496] 4721379 4722138 4722898 4723658 4724418 4725177 4725937 4726697 4727457\n[505] 4728216 4728976 4729736 4730496 4731255 4732015 4732775 4733535 4734294\n[514] 4735054 4735814 4736574 4737333 4738093 4738853 4739613 4740372 4741132\n[523] 4741892 4742652 4743411 4744171\n\n$x\n  [1] 388941.2 389701.0 390460.8 391220.5 391980.3 392740.1 393499.9 394259.7\n  [9] 395019.4 395779.2 396539.0 397298.8 398058.6 398818.4 399578.1 400337.9\n [17] 401097.7 401857.5 402617.3 403377.0 404136.8 404896.6 405656.4 406416.2\n [25] 407175.9 407935.7 408695.5 409455.3 410215.1 410974.9 411734.6 412494.4\n [33] 413254.2 414014.0 414773.8 415533.5 416293.3 417053.1 417812.9 418572.7\n [41] 419332.4 420092.2 420852.0 421611.8 422371.6 423131.3 423891.1 424650.9\n [49] 425410.7 426170.5 426930.3 427690.0 428449.8 429209.6 429969.4 430729.2\n [57] 431488.9 432248.7 433008.5 433768.3 434528.1 435287.8 436047.6 436807.4\n [65] 437567.2 438327.0 439086.8 439846.5 440606.3 441366.1 442125.9 442885.7\n [73] 443645.4 444405.2 445165.0 445924.8 446684.6 447444.3 448204.1 448963.9\n [81] 449723.7 450483.5 451243.2 452003.0 452762.8 453522.6 454282.4 455042.2\n [89] 455801.9 456561.7 457321.5 458081.3 458841.1 459600.8 460360.6 461120.4\n [97] 461880.2 462640.0 463399.7 464159.5 464919.3 465679.1 466438.9 467198.7\n[105] 467958.4 468718.2 469478.0 470237.8 470997.6 471757.3 472517.1 473276.9\n[113] 474036.7 474796.5 475556.2 476316.0 477075.8 477835.6 478595.4 479355.1\n[121] 480114.9 480874.7 481634.5 482394.3 483154.1 483913.8 484673.6 485433.4\n[129] 486193.2 486953.0 487712.7 488472.5 489232.3 489992.1 490751.9 491511.6\n[137] 492271.4 493031.2 493791.0 494550.8 495310.6 496070.3 496830.1 497589.9\n[145] 498349.7 499109.5 499869.2 500629.0 501388.8 502148.6 502908.4 503668.1\n[153] 504427.9 505187.7 505947.5 506707.3 507467.0 508226.8 508986.6 509746.4\n[161] 510506.2 511266.0 512025.7 512785.5 513545.3 514305.1 515064.9 515824.6\n[169] 516584.4 517344.2 518104.0 518863.8 519623.5 520383.3 521143.1 521902.9\n[177] 522662.7 523422.5 524182.2 524942.0 525701.8 526461.6 527221.4 527981.1\n[185] 528740.9 529500.7 530260.5 531020.3 531780.0 532539.8 533299.6 534059.4\n[193] 534819.2 535578.9 536338.7 537098.5 537858.3 538618.1 539377.9 540137.6\n[201] 540897.4 541657.2 542417.0 543176.8 543936.5 544696.3 545456.1 546215.9\n[209] 546975.7 547735.4 548495.2 549255.0 550014.8 550774.6 551534.4 552294.1\n[217] 553053.9 553813.7 554573.5 555333.3 556093.0 556852.8 557612.6 558372.4\n[225] 559132.2 559891.9 560651.7 561411.5 562171.3 562931.1 563690.8 564450.6\n[233] 565210.4 565970.2 566730.0 567489.8 568249.5 569009.3 569769.1 570528.9\n[241] 571288.7 572048.4 572808.2 573568.0 574327.8 575087.6 575847.3 576607.1\n[249] 577366.9 578126.7 578886.5 579646.3 580406.0 581165.8 581925.6 582685.4\n[257] 583445.2 584204.9 584964.7 585724.5 586484.3 587244.1 588003.8 588763.6\n[265] 589523.4 590283.2 591043.0 591802.8 592562.5 593322.3 594082.1 594841.9\n[273] 595601.7 596361.4 597121.2 597881.0 598640.8 599400.6 600160.3 600920.1\n[281] 601679.9 602439.7 603199.5 603959.2 604719.0 605478.8 606238.6 606998.4\n[289] 607758.2 608517.9 609277.7 610037.5 610797.3 611557.1 612316.8 613076.6\n[297] 613836.4 614596.2 615356.0 616115.7 616875.5 617635.3 618395.1 619154.9\n[305] 619914.7 620674.4 621434.2 622194.0 622953.8 623713.6 624473.3 625233.1\n[313] 625992.9 626752.7 627512.5 628272.2 629032.0 629791.8 630551.6 631311.4\n[321] 632071.1 632830.9 633590.7 634350.5 635110.3 635870.1 636629.8 637389.6\n[329] 638149.4 638909.2 639669.0 640428.7 641188.5 641948.3 642708.1 643467.9\n[337] 644227.6 644987.4 645747.2 646507.0 647266.8 648026.6 648786.3 649546.1\n[345] 650305.9 651065.7 651825.5 652585.2 653345.0 654104.8 654864.6 655624.4\n[353] 656384.1 657143.9 657903.7 658663.5 659423.3 660183.0 660942.8 661702.6\n[361] 662462.4 663222.2 663982.0 664741.7 665501.5 666261.3 667021.1 667780.9\n[369] 668540.6 669300.4 670060.2 670820.0 671579.8 672339.5 673099.3 673859.1\n[377] 674618.9 675378.7 676138.5 676898.2 677658.0 678417.8 679177.6 679937.4\n[385] 680697.1 681456.9 682216.7 682976.5 683736.3 684496.0 685255.8 686015.6\n[393] 686775.4 687535.2 688294.9 689054.7 689814.5 690574.3 691334.1 692093.9\n[401] 692853.6 693613.4 694373.2 695133.0 695892.8 696652.5 697412.3 698172.1\n[409] 698931.9 699691.7 700451.4 701211.2 701971.0 702730.8 703490.6 704250.4\n[417] 705010.1 705769.9 706529.7 707289.5 708049.3 708809.0 709568.8 710328.6\n[425] 711088.4 711848.2 712607.9 713367.7 714127.5 714887.3 715647.1 716406.8\n[433] 717166.6 717926.4 718686.2 719446.0 720205.8 720965.5 721725.3 722485.1\n[441] 723244.9 724004.7 724764.4 725524.2 726284.0 727043.8 727803.6 728563.3\n[449] 729323.1 730082.9 730842.7 731602.5 732362.3 733122.0 733881.8 734641.6\n[457] 735401.4 736161.2 736920.9 737680.7 738440.5 739200.3 739960.1 740719.8\n[465] 741479.6 742239.4 742999.2 743759.0 744518.7 745278.5 746038.3 746798.1\n[473] 747557.9 748317.7 749077.4 749837.2 750597.0 751356.8 752116.6 752876.3\n[481] 753636.1 754395.9 755155.7 755915.5 756675.2 757435.0 758194.8 758954.6\n[489] 759714.4 760474.2 761233.9 761993.7 762753.5 763513.3 764273.1 765032.8\n[497] 765792.6"
  },
  {
    "objectID": "source/reference/ref/write_ncdf.html",
    "href": "source/reference/ref/write_ncdf.html",
    "title": "gdalcubes",
    "section": "",
    "text": "Export a data cube as netCDF file(s)\n\n\nThis function will read chunks of a data cube and write them to a single (the default) or multitple (if chunked = TRUE) netCDF file(s). The resulting file(s) uses the enhanced netCDF-4 format, supporting chunking and compression.\n\n\n\nwrite_ncdf(\n  x,\n  fname = tempfile(pattern = \"gdalcubes\", fileext = \".nc\"),\n  overwrite = FALSE,\n  write_json_descr = FALSE,\n  with_VRT = FALSE,\n  pack = NULL,\n  chunked = FALSE\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\na data cube proxy object (class cube)\n\n\nfname\noutput file name\n\n\noverwrite\nlogical; overwrite output file if it already exists\n\n\nwrite_json_descr\nlogical; write a JSON description of x as additional file\n\n\nwith_VRT\nlogical; write additional VRT datasets (one per time slice)\n\n\npack\nreduce output file size by packing values (see Details), defaults to no packing\n\n\nchunked\nlogical; if TRUE, write one netCDF file per chunk; defaults to FALSE\n\n\n\n\n\n\nThe resulting netCDF file(s) contain three dimensions (t, y, x) and bands as variables.\nIf write_json_descr is TRUE, the function will write an addition file with the same name as the NetCDF file but “.json” suffix. This file includes a serialized description of the input data cube, including all chained data cube operations.\nTo reduce the size of created files, values can be packed by applying a scale factor and an offset value and using a smaller integer data type for storage (only supported if chunked = TRUE). The pack argument can be either NULL (the default), or a list with elements type, scale, offset, and nodata. type can be any of “uint8”, “uint16” , “uint32”, “int16”, or “int32”. scale, offset, and nodata must be numeric vectors with length one or length equal to the number of data cube bands (to use different values for different bands). The helper function pack_minmax can be used to derive offset and scale values with maximum precision from minimum and maximum data values on original scale.\nIf chunked = TRUE, names of the produced files will start with name (with removed extension), followed by an underscore and the internal integer chunk number.\n\n\n\nreturns (invisibly) the path of the created netCDF file(s)\n\n\n\nPacking is currently ignored if chunked = TRUE\n\n\n\n\n# create image collection from example Landsat data only \n# if not already done in other examples\nif (!file.exists(file.path(tempdir(), \"L8.db\"))) {\n  L8_files <- list.files(system.file(\"L8NY18\", package = \"gdalcubes\"),\n                         \".TIF\", recursive = TRUE, full.names = TRUE)\n  create_image_collection(L8_files, \"L8_L1TP\", file.path(tempdir(), \"L8.db\"), quiet = TRUE) \n}\n\nL8.col = image_collection(file.path(tempdir(), \"L8.db\"))\nv = cube_view(extent=list(left=388941.2, right=766552.4, \n              bottom=4345299, top=4744931, t0=\"2018-04\", t1=\"2018-04\"),\n              srs=\"EPSG:32618\", nx = 497, ny=526, dt=\"P1M\")\nwrite_ncdf(select_bands(raster_cube(L8.col, v), c(\"B04\", \"B05\")), fname=tempfile(fileext = \".nc\"))\n\n\n\n\ngdalcubes_options\npack_minmax"
  },
  {
    "objectID": "source/reference/ref/proj4.html",
    "href": "source/reference/ref/proj4.html",
    "title": "gdalcubes",
    "section": "",
    "text": "Query data cube properties\n\n\nQuery data cube properties\n\n\n\nproj4(obj)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobj\na data cube proxy object (class cube)\n\n\n\n\n\n\nThe spatial reference system expressed as proj4 string\n\n\n\n\n# create image collection from example Landsat data only \n# if not already done in other examples\nif (!file.exists(file.path(tempdir(), \"L8.db\"))) {\n  L8_files <- list.files(system.file(\"L8NY18\", package = \"gdalcubes\"),\n                         \".TIF\", recursive = TRUE, full.names = TRUE)\n  create_image_collection(L8_files, \"L8_L1TP\", file.path(tempdir(), \"L8.db\"), quiet = TRUE) \n}\n\nL8.col = image_collection(file.path(tempdir(), \"L8.db\"))\nv = cube_view(extent=list(left=388941.2, right=766552.4, \n              bottom=4345299, top=4744931, t0=\"2018-04\", t1=\"2018-06\"),\n              srs=\"EPSG:32618\", nx = 497, ny=526, dt=\"P1M\")\nproj4(raster_cube(L8.col, v))\n\n[1] \"+proj=utm +zone=18 +datum=WGS84 +units=m +no_defs\""
  },
  {
    "objectID": "source/reference/ref/dot-copy_cube.html",
    "href": "source/reference/ref/dot-copy_cube.html",
    "title": "gdalcubes",
    "section": "",
    "text": "Create a data cube proxy object copy\n\n\nCopy a data cube proxy object without copying any data\n\n\n\n.copy_cube(cube)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ncube\nsource data cube proxy object\n\n\n\n\n\n\nThis internal function copies the complete processing chain / graph of a data cube but does not copy any data It is used internally to avoid in-place modification for operations with potential side effects on source data cubes.\n\n\n\ncopied data cube proxy object"
  },
  {
    "objectID": "source/reference/ref/gdalcubes.html",
    "href": "source/reference/ref/gdalcubes.html",
    "title": "gdalcubes",
    "section": "",
    "text": "gdalcubes: Earth Observation Data Cubes from Satellite Image Collections\n\n\nProcessing collections of Earth observation images as on-demand multispectral, multitemporal raster data cubes. Users define cubes by spatiotemporal extent, resolution, and spatial reference system and let ‘gdalcubes’ automatically apply cropping, reprojection, and resampling using the ‘Geospatial Data Abstraction Library’ (‘GDAL’). Implemented functions on data cubes include reduction over space and time, applying arithmetic expressions on pixel band values, moving window aggregates over time, filtering by space, time, bands, and predicates on pixel values, exporting data cubes as ‘netCDF’ or ‘GeoTIFF’ files, plotting, and extraction from spatial and or spatiotemporal features.\nAll computational parts are implemented in C++, linking to the ‘GDAL’, ‘netCDF’, ‘CURL’, and ‘SQLite’ libraries. See Appel and Pebesma (2019) doi:10.3390/data4030092 for further details."
  },
  {
    "objectID": "source/reference/ref/apply_pixel.array.html",
    "href": "source/reference/ref/apply_pixel.array.html",
    "title": "gdalcubes",
    "section": "",
    "text": "Apply a function over pixels in a four-dimensional (band, time, y, x) array\n\n\nApply a function over pixels in a four-dimensional (band, time, y, x) array\n\n\n\napply_pixel.array(x, FUN, ...)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nfour-dimensional input array with dimensions band, time, y, x (in this order)\n\n\nFUN\nfunction that receives a vector of band values in a one-dimensional array\n\n\n…\nfurther arguments passed to FUN\n\n\n\n\n\n\nFUN is expected to produce a numeric vector (or scalar) where elements are interpreted as new bands in the result.\n\n\n\nThis is a helper function that uses the same dimension ordering as gdalcubes. It can be used to simplify the application of R functions e.g. over time series in a data cube.\n\n\n\n\nd <- c(4,16,32,32)\nx <- array(rnorm(prod(d)), d)\ny <- apply_pixel(x, function(v) {\n  v[1] + v[2] + v[3] - v[4]\n})\ndim(y)\n\n[1]  1 16 32 32"
  },
  {
    "objectID": "source/reference/ref/names.cube.html",
    "href": "source/reference/ref/names.cube.html",
    "title": "gdalcubes",
    "section": "",
    "text": "Query data cube properties\n\n\nQuery data cube properties\n\n\n\nnames.cube(x)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\na data cube proxy object (class cube)\n\n\n\n\n\n\nBand names as character vector\n\n\n\n\n# create image collection from example Landsat data only \n# if not already done in other examples\nif (!file.exists(file.path(tempdir(), \"L8.db\"))) {\n  L8_files <- list.files(system.file(\"L8NY18\", package = \"gdalcubes\"),\n                         \".TIF\", recursive = TRUE, full.names = TRUE)\n  create_image_collection(L8_files, \"L8_L1TP\", file.path(tempdir(), \"L8.db\"), quiet = TRUE) \n}\n\nL8.col = image_collection(file.path(tempdir(), \"L8.db\"))\nv = cube_view(extent=list(left=388941.2, right=766552.4, \n              bottom=4345299, top=4744931, t0=\"2018-04\", t1=\"2018-06\"),\n              srs=\"EPSG:32618\", nx = 497, ny=526, dt=\"P1M\")\nnames(raster_cube(L8.col, v))\n\n [1] \"B01\" \"B02\" \"B03\" \"B04\" \"B05\" \"B06\" \"B07\" \"B08\" \"B09\" \"B10\" \"B11\" \"BQA\""
  },
  {
    "objectID": "source/reference/ref/srs.html",
    "href": "source/reference/ref/srs.html",
    "title": "gdalcubes",
    "section": "",
    "text": "Query data cube properties\n\n\nQuery data cube properties\n\n\n\nsrs(obj)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobj\na data cube proxy object (class cube)\n\n\n\n\n\n\nThe spatial reference system expressed as a string readable by GDAL\n\n\n\n\n# create image collection from example Landsat data only \n# if not already done in other examples\nif (!file.exists(file.path(tempdir(), \"L8.db\"))) {\n  L8_files <- list.files(system.file(\"L8NY18\", package = \"gdalcubes\"),\n                         \".TIF\", recursive = TRUE, full.names = TRUE)\n  create_image_collection(L8_files, \"L8_L1TP\", file.path(tempdir(), \"L8.db\"), quiet = TRUE) \n}\n\nL8.col = image_collection(file.path(tempdir(), \"L8.db\"))\nv = cube_view(extent=list(left=388941.2, right=766552.4, \n              bottom=4345299, top=4744931, t0=\"2018-04\", t1=\"2018-06\"),\n              srs=\"EPSG:32618\", nx = 497, ny=526, dt=\"P1M\")\nsrs(raster_cube(L8.col, v))\n\n[1] \"EPSG:32618\""
  },
  {
    "objectID": "source/reference/ref/extract_geom.html",
    "href": "source/reference/ref/extract_geom.html",
    "title": "gdalcubes",
    "section": "",
    "text": "Extract values from a data cube by spatial or spatiotemporal features\n\n\nExtract pixel values of a data cube from a set of spatial or spatiotemporal features. Applications include the extraction of full time series at irregular points, extraction from spatiotemporal points, extraction of pixel values in polygons, and computing summary statistics over polygons.\n\n\n\nextract_geom(\n  cube,\n  sf,\n  datetime = NULL,\n  time_column = NULL,\n  FUN = NULL,\n  ...,\n  reduce_time = FALSE\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ncube\nsource data cube to extract values from\n\n\nsf\nobject of class sf, see [sf package](sf::st_as_sf)\n\n\ndatetime\nDate, POSIXt, or character vector containing per feature time information; length must be identical to the number of features in sf\n\n\ntime_column\nname of the column in sf containing per feature time information\n\n\nFUN\noptional function to compute per feature summary statistics\n\n\n…\nadditional arguments passed to FUN\n\n\nreduce_time\nlogical; if TRUE, time is ignored when FUN is applied\n\n\n\n\n\n\nThe geometry in sf can be of any simple feature type supported by GDAL, including POINTS, LINES, POLYGONS, MULTI*, and more. If no time information is provided in one of the arguments datetime or time_column, the full time series of pixels with regard to the features are returned.\nPixels with missing values are automatically dropped from the result. It is hence not guaranteed that the result will contain rows for all input features.\nFeatures are automatically reprojected if the coordinate reference system differs from the data cube.\nExtracted values can be aggregated by features by providing a summary function. If reduce_time is FALSE (the default), the values are grouped by feature and time, i.e., the result will contain unique combinations of FID and time. To ignore time and produce a single value per feature, reduce_time can be set to TRUE.\n\n\n\nA data.frame with columns FID, time, and data cube bands / variables\n\n\n\n\n# if not already done in other examples\nif (!file.exists(file.path(tempdir(), \"L8.db\"))) {\n  L8_files <- list.files(system.file(\"L8NY18\", package = \"gdalcubes\"),\n                         \".TIF\", recursive = TRUE, full.names = TRUE)\n  create_image_collection(L8_files, \"L8_L1TP\", file.path(tempdir(), \"L8.db\"), quiet = TRUE)\n}\nL8.col = image_collection(file.path(tempdir(), \"L8.db\"))\nv = cube_view(srs=\"EPSG:32618\", dy=1000, dx=1000, dt=\"P1M\",\n              aggregation = \"median\", resampling = \"bilinear\",\n              extent=list(left=388941.2, right=766552.4,\n                          bottom=4345299, top=4744931,\n                          t0=\"2018-01-01\", t1=\"2018-04-30\"))\nL8.cube = raster_cube(L8.col, v)\nL8.cube = select_bands(L8.cube, c(\"B04\", \"B05\"))\nL8.ndvi = apply_pixel(L8.cube, \"(B05-B04)/(B05+B04)\", \"NDVI\")\nL8.ndvi\n\nA GDAL data cube proxy object\n\nDimensions:\n         low       high count pixel_size chunk_size\nt 2018-01-01 2018-04-30     4        P1M          1\ny    4345115    4745115   400       1000        320\nx   388746.8   766746.8   378       1000        320\n\nBands:\n  name offset scale nodata unit\n1 NDVI      0     1    NaN     \n\nif (gdalcubes_gdal_has_geos()) {\n  if (requireNamespace(\"sf\", quietly = TRUE)) {\n  \n    x = runif(20, v$space$left, v$space$right)\n    y = runif(20, v$space$bottom, v$space$top)\n    t = sample(seq(as.Date(\"2018-01-01\"),as.Date(\"2018-04-30\"), by = 1),20, replace = TRUE)\n    df = sf::st_as_sf(data.frame(x = x, y = y), coords = c(\"x\", \"y\"), crs = v$space$srs)\n\n    # spatiotemporal points\n    extract_geom(L8.ndvi, df, datetime = t)\n\n    # time series at spatial points\n    extract_geom(L8.ndvi, df)\n  \n    # summary statistics over polygons\n    x = sf::st_read(system.file(\"nycd.gpkg\", package = \"gdalcubes\"))\n    zstats = extract_geom(L8.ndvi,x, FUN=median, reduce_time = TRUE)\n    zstats\n    # combine with original sf object\n    x$FID = rownames(x)\n    x = merge(x, zstats, by = \"FID\")\n    x\n    # plot(x[\"NDVI\"])\n  }\n}\n\nReading layer `nycd_1' from data source \n  `/home/marius/R/x86_64-pc-linux-gnu-library/4.1/gdalcubes/nycd.gpkg' \n  using driver `GPKG'\nSimple feature collection with 71 features and 0 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 563069.9 ymin: 4483098 xmax: 609761.1 ymax: 4529895\nProjected CRS: WGS 84 / UTM zone 18N\n\n\nSimple feature collection with 71 features and 2 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 563069.9 ymin: 4483098 xmax: 609761.1 ymax: 4529895\nProjected CRS: WGS 84 / UTM zone 18N\nFirst 10 features:\n   FID        NDVI                       geometry\n1    1 0.026432508 MULTIPOLYGON (((586882.1 44...\n2   10 0.034696086 MULTIPOLYGON (((597308.6 45...\n3   11 0.028883248 MULTIPOLYGON (((592617.7 45...\n4   12 0.066547940 MULTIPOLYGON (((601288 4502...\n5   13 0.071926794 MULTIPOLYGON (((593921.5 45...\n6   14 0.021659255 MULTIPOLYGON (((593432.1 45...\n7   15 0.031520287 MULTIPOLYGON (((594782.6 45...\n8   16 0.068065497 MULTIPOLYGON (((598329 4507...\n9   17 0.033419028 MULTIPOLYGON (((591557.1 44...\n10  18 0.004027017 MULTIPOLYGON (((586678.7 45..."
  },
  {
    "objectID": "source/reference/ref/bands.html",
    "href": "source/reference/ref/bands.html",
    "title": "gdalcubes",
    "section": "",
    "text": "Query data cube properties\n\n\nQuery data cube properties\n\n\n\nbands(obj)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobj\na data cube proxy object (class cube)\n\n\n\n\n\n\nA data.frame with rows representing the bands and columns representing properties of a band (name, type, scale, offset, unit)\n\n\n\n\n# create image collection from example Landsat data only \n# if not already done in other examples\nif (!file.exists(file.path(tempdir(), \"L8.db\"))) {\n  L8_files <- list.files(system.file(\"L8NY18\", package = \"gdalcubes\"),\n                         \".TIF\", recursive = TRUE, full.names = TRUE)\n  create_image_collection(L8_files, \"L8_L1TP\", file.path(tempdir(), \"L8.db\"), quiet = TRUE) \n}\n\nL8.col = image_collection(file.path(tempdir(), \"L8.db\"))\nv = cube_view(extent=list(left=388941.2, right=766552.4, \n              bottom=4345299, top=4744931, t0=\"2018-04\", t1=\"2018-06\"),\n              srs=\"EPSG:32618\", nx = 497, ny=526, dt=\"P1M\")\nbands(raster_cube(L8.col, v))\n\n   name offset scale nodata unit\n1   B01      0     1    NaN     \n2   B02      0     1    NaN     \n3   B03      0     1    NaN     \n4   B04      0     1    NaN     \n5   B05      0     1    NaN     \n6   B06      0     1    NaN     \n7   B07      0     1    NaN     \n8   B08      0     1    NaN     \n9   B09      0     1    NaN     \n10  B10      0     1    NaN     \n11  B11      0     1    NaN     \n12  BQA      0     1    NaN"
  },
  {
    "objectID": "source/reference/ref/image_mask.html",
    "href": "source/reference/ref/image_mask.html",
    "title": "gdalcubes",
    "section": "",
    "text": "Create a mask for images in a raster data cube\n\n\nCreate an image mask based on a band and provided values to filter pixels of images read by raster_cube\n\n\n\nimage_mask(\n  band,\n  min = NULL,\n  max = NULL,\n  values = NULL,\n  bits = NULL,\n  invert = FALSE\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nband\nname of the mask band\n\n\nmin\nminimum value, values between min and max will be masked\n\n\nmax\nmaximum value, values between min and max will be masked\n\n\nvalues\nnumeric vector; specific values that will be masked.\n\n\nbits\nfor bitmasks, extract the given bits (integer vector) with a bitwise AND before filtering the mask values, bit indexes are zero-based\n\n\ninvert\nlogical; invert mask\n\n\n\n\n\n\nValues of the selected mask band can be based on a range (by passing min and max) or on a set of values (by passing values). By default pixels with mask values contained in the range or in the values are masked out, i.e. set to NA. Setting invert = TRUE will invert the masking behavior. Passing values will override min and max.\n\n\n\nNotice that masks are applied per image while reading images as a raster cube. They can be useful to eliminate e.g. cloudy pixels before applying the temporal aggregation to merge multiple values for the same data cube pixel.\n\n\n\n\nimage_mask(\"SCL\", values = c(3,8,9)) # Sentinel 2 L2A: mask cloud and cloud shadows\n\n$band\n[1] \"SCL\"\n\n$values\n[1] 3 8 9\n\n$invert\n[1] FALSE\n\n$bits\nNULL\n\nattr(,\"class\")\n[1] \"image_mask\"\n\nimage_mask(\"BQA\", bits=4, values=16) # Landsat 8: mask clouds\n\n$band\n[1] \"BQA\"\n\n$values\n[1] 16\n\n$invert\n[1] FALSE\n\n$bits\n[1] 4\n\nattr(,\"class\")\n[1] \"image_mask\"\n\nimage_mask(\"B10\", min = 8000, max=65000) \n\n$band\n[1] \"B10\"\n\n$min\n[1] 8000\n\n$max\n[1] 65000\n\n$invert\n[1] FALSE\n\n$bits\nNULL\n\nattr(,\"class\")\n[1] \"image_mask\""
  },
  {
    "objectID": "source/reference/ref/create_image_collection.html",
    "href": "source/reference/ref/create_image_collection.html",
    "title": "gdalcubes",
    "section": "",
    "text": "Create an image collection from a set of GDAL datasets or files\n\n\nThis function iterates over files or GDAL dataset identifiers and extracts datetime, image identifiers, and band information according to a given collection format.\n\n\n\ncreate_image_collection(\n  files,\n  format = NULL,\n  out_file = tempfile(fileext = \".sqlite\"),\n  date_time = NULL,\n  band_names = NULL,\n  use_subdatasets = FALSE,\n  unroll_archives = TRUE,\n  quiet = FALSE,\n  one_band_per_file = NULL\n)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nfiles\ncharacter vector with paths to image files on disk or any GDAL dataset identifiers (including virtual file systems and higher level drivers or GDAL subdatasets)\n\n\nformat\ncollection format, can be either a name to use predefined formats (as output from collection_formats) or a path to a custom JSON format description file\n\n\nout_file\noptional name of the output SQLite database file, defaults to a temporary file\n\n\ndate_time\nvector with date/ time for files; can be of class character, Date, or POSIXct (argument is only applicable for image collections without collection format)\n\n\nband_names\ncharacter vector with band names, length must match the number of bands in provided files (argument is only applicable for image collections without collection format)\n\n\nuse_subdatasets\nlogical; use GDAL subdatasets of provided files (argument is only applicable for image collections without collection format)\n\n\nunroll_archives\nautomatically convert .zip, .tar archives and .gz compressed files to GDAL virtual file system dataset identifiers (e.g. by prepending /vsizip/) and add contained files to the list of considered files\n\n\nquiet\nlogical; if TRUE, do not print resulting image collection if return value is not assigned to a variable\n\n\none_band_per_file\nlogical; if TRUE, assume that band_names are given for all files (argument is only applicable for image collections without collection format, see Details)\n\n\n\n\n\n\nAn image collection is a simple index (a SQLite database) containing references to existing image files / GDAL dataset identifiers.\nCollections can be created in two different ways: First, if a collection format is specified (argument format), date/time, bands, and metadata are automatically extracted from provided files. This is the most general approach but requires a collection format for the specific dataset.\nSecond, image collections can sometimes be created without collection format by manually specifying date/time of images (argument date_time) and names of bands (argument band_names). This is possible if either each image file contains all bands of the collection or only a single band. In the former case band_names simply contains the names of the bands or can be NULL to use default names. In the latter case (image files contain a single band only), the lengths of band_names and date_time must be identical. By default, the function assumes one band per file if length(band_names) == length(files). In the unlikely situation that this is not desired, it can be explicitly set using one_band_per_file.\n\n\n\nimage collection proxy object, which can be used to create a data cube using raster_cube\n\n\n\n\n# 1. create image collection using a collection format \nL8_files <- list.files(system.file(\"L8NY18\", package = \"gdalcubes\"),\n                       \".TIF\", recursive = TRUE, full.names = TRUE)\nx = create_image_collection(L8_files, \"L8_L1TP\")\nx \n\nImage collection object, referencing 19 images with 12 bands\nImages:\n                                      name      left      top   bottom\n1 LC08_L1TP_013032_20180131_20180207_01_T1 -74.67898 41.39099 39.25027\n2 LC08_L1TP_013032_20180405_20180417_01_T1 -74.70333 41.39106 39.25080\n3 LC08_L1TP_013032_20180421_20180502_01_T1 -74.70681 41.39107 39.25098\n4 LC08_L1TP_013032_20180710_20180717_01_T1 -74.66854 41.39096 39.24991\n5 LC08_L1TP_013032_20180827_20180911_01_T1 -74.67202 41.39097 39.25000\n6 LC08_L1TP_013032_20181030_20181115_01_T1 -74.69637 41.39104 39.25062\n      right            datetime        srs\n1 -71.92546 2018-01-31T00:00:00 EPSG:32618\n2 -71.94695 2018-04-05T00:00:00 EPSG:32618\n3 -71.95411 2018-04-21T00:00:00 EPSG:32618\n4 -71.91114 2018-07-10T00:00:00 EPSG:32618\n5 -71.91472 2018-08-27T00:00:00 EPSG:32618\n6 -71.93979 2018-10-30T00:00:00 EPSG:32618\n[ omitted 13 images ] \n\nBands:\n   name offset scale unit   nodata image_count\n1   B01      0     1      0.000000          19\n2   B02      0     1      0.000000          19\n3   B03      0     1      0.000000          19\n4   B04      0     1      0.000000          19\n5   B05      0     1      0.000000          19\n6   B06      0     1      0.000000          19\n7   B07      0     1      0.000000          19\n8   B08      0     1      0.000000          19\n9   B09      0     1      0.000000          19\n10  B10      0     1      0.000000          19\n11  B11      0     1      0.000000          19\n12  BQA      0     1                        19\n\n# 2. create image collection without format for a single band\nL8_files_B4 <- list.files(system.file(\"L8NY18\", package = \"gdalcubes\"),\n                       \"_B4.TIF\", recursive = TRUE, full.names = TRUE)\nd = as.Date(substr(basename(L8_files_B4), 18, 25), \"%Y%m%d\")\ny = create_image_collection(L8_files_B4, date_time = d, band_names = \"B4\")\ny\n\nImage collection object, referencing 19 images with 1 bands\nImages:\n                                                                                                                                       name\n1 /home/marius/R/x86_64-pc-linux-gnu-library/4.2/gdalcubes/L8NY18/LC08_L1TP_013032_20180131_20180207_01_T1/LC08_L1TP_013032_20180131_B4.TIF\n2 /home/marius/R/x86_64-pc-linux-gnu-library/4.2/gdalcubes/L8NY18/LC08_L1TP_013032_20180405_20180417_01_T1/LC08_L1TP_013032_20180405_B4.TIF\n3 /home/marius/R/x86_64-pc-linux-gnu-library/4.2/gdalcubes/L8NY18/LC08_L1TP_013032_20180421_20180502_01_T1/LC08_L1TP_013032_20180421_B4.TIF\n4 /home/marius/R/x86_64-pc-linux-gnu-library/4.2/gdalcubes/L8NY18/LC08_L1TP_013032_20180710_20180717_01_T1/LC08_L1TP_013032_20180710_B4.TIF\n5 /home/marius/R/x86_64-pc-linux-gnu-library/4.2/gdalcubes/L8NY18/LC08_L1TP_013032_20180827_20180911_01_T1/LC08_L1TP_013032_20180827_B4.TIF\n6 /home/marius/R/x86_64-pc-linux-gnu-library/4.2/gdalcubes/L8NY18/LC08_L1TP_013032_20181030_20181115_01_T1/LC08_L1TP_013032_20181030_B4.TIF\n       left      top   bottom     right            datetime        srs\n1 -74.67898 41.39099 39.25027 -71.92546 2018-01-31T00:00:00 EPSG:32618\n2 -74.70333 41.39106 39.25080 -71.94695 2018-04-05T00:00:00 EPSG:32618\n3 -74.70681 41.39107 39.25098 -71.95411 2018-04-21T00:00:00 EPSG:32618\n4 -74.66854 41.39096 39.24991 -71.91114 2018-07-10T00:00:00 EPSG:32618\n5 -74.67202 41.39097 39.25000 -71.91472 2018-08-27T00:00:00 EPSG:32618\n6 -74.69637 41.39104 39.25062 -71.93979 2018-10-30T00:00:00 EPSG:32618\n[ omitted 13 images ] \n\nBands:\n  name offset scale unit nodata image_count\n1   B4      0     1                      19\n\n# 3. create image collection without format for all bands\nd = as.Date(substr(basename(L8_files), 18, 25), \"%Y%m%d\")\nfname = basename(tools::file_path_sans_ext(L8_files))\nb = substr(fname, 27, nchar(fname))\nz = create_image_collection(L8_files, date_time = d, band_names = b)\nz\n\nImage collection object, referencing 228 images with 12 bands\nImages:\n                           name      left      top   bottom     right\n1  LC08_L1TP_013032_20180131_B1 -74.67898 41.39099 39.25027 -71.92546\n2 LC08_L1TP_013032_20180131_B10 -74.67898 41.39099 39.25027 -71.92546\n3 LC08_L1TP_013032_20180131_B11 -74.67898 41.39099 39.25027 -71.92546\n4  LC08_L1TP_013032_20180131_B2 -74.67898 41.39099 39.25027 -71.92546\n5  LC08_L1TP_013032_20180131_B3 -74.67898 41.39099 39.25027 -71.92546\n6  LC08_L1TP_013032_20180131_B4 -74.67898 41.39099 39.25027 -71.92546\n             datetime        srs\n1 2018-01-31T00:00:00 EPSG:32618\n2 2018-01-31T00:00:00 EPSG:32618\n3 2018-01-31T00:00:00 EPSG:32618\n4 2018-01-31T00:00:00 EPSG:32618\n5 2018-01-31T00:00:00 EPSG:32618\n6 2018-01-31T00:00:00 EPSG:32618\n[ omitted 222 images ] \n\nBands:\n   name offset scale unit nodata image_count\n1    B1      0     1                      19\n2   B10      0     1                      19\n3   B11      0     1                      19\n4    B2      0     1                      19\n5    B3      0     1                      19\n6    B4      0     1                      19\n7    B5      0     1                      19\n8    B6      0     1                      19\n9    B7      0     1                      19\n10   B8      0     1                      19\n11   B9      0     1                      19\n12  BQA      0     1                      19"
  },
  {
    "objectID": "source/reference/ref/aggregate_space.html",
    "href": "source/reference/ref/aggregate_space.html",
    "title": "gdalcubes",
    "section": "",
    "text": "Spatial aggregation of data cubes\n\n\nCreate a proxy data cube, which applies an aggregation function to reduce the spatial resolution.\n\n\n\naggregate_space(cube, dx, dy, method = \"mean\", fact = NULL)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ncube\nsource data cube\n\n\ndx\nnumeric value; new spatial resolution in x direction\n\n\ndy\nnumeric value; new spatial resolution in y direction\n\n\nmethod\naggregation method, one of “mean”, “min”, “max”, “median”, “count”, “sum”, “prod”, “var”, and “sd”\n\n\nfact\nsimple integer factor defining how many cells (per axis) become aggregated to a single new cell, can be used instead of dx and dy\n\n\n\n\n\n\nThis function reduces the spatial resolution of a data cube by applying an aggregation function to smaller blocks of pixels.\nThe size of the cube may be expanded automatically in all directions if the original extent is not divisible by the new size of pixels.\nNotice that if boundaries of the target cube do not align with the boundaries of the input cube (for example, if aggregating from 10m to 15m spatial resolution), pixels of the input cube will contribute to the output pixel that contains its center coordinate. If the center coordinate is exactly on a boundary, the input pixel will contribute to the right / bottom pixel of the output cube.\n\n\n\nThis function returns a proxy object, i.e., it will not start any computations besides deriving the shape of the result.\n\n\n\n\n# create image collection from example Landsat data only \n# if not already done in other examples\nif (!file.exists(file.path(tempdir(), \"L8.db\"))) {\n  L8_files <- list.files(system.file(\"L8NY18\", package = \"gdalcubes\"),\n                         \".TIF\", recursive = TRUE, full.names = TRUE)\n  create_image_collection(L8_files, \"L8_L1TP\", file.path(tempdir(), \"L8.db\"), quiet = TRUE) \n}\nL8.col = image_collection(file.path(tempdir(), \"L8.db\"))\nv = cube_view(extent=list(left=388941.2, right=766552.4, \n                          bottom=4345299, top=4744931, t0=\"2018-01\", t1=\"2018-12\"),\n              srs=\"EPSG:32618\", dx = 500, dy=500, dt=\"P3M\", aggregation = \"median\")\nL8.cube = raster_cube(L8.col, v, mask=image_mask(\"BQA\", bits=4, values=16))\nL8.rgb = select_bands(L8.cube, c(\"B02\", \"B03\", \"B04\"))\nL8.5km = aggregate_space(L8.rgb, 5000,5000, \"mean\")\nL8.5km\n\nA GDAL data cube proxy object\n\nDimensions:\n         low       high count pixel_size chunk_size\nt 2018-01-01 2018-12-31     4        P3M          1\ny    4345115    4745115    80       5000         80\nx   387746.8   767746.8    76       5000         76\n\nBands:\n  name offset scale nodata unit\n1  B02      0     1    NaN     \n2  B03      0     1    NaN     \n3  B04      0     1    NaN     \n\nplot(L8.5km, rgb=3:1, zlim=c(5000,12000))"
  },
  {
    "objectID": "source/reference/ref/apply_time.html",
    "href": "source/reference/ref/apply_time.html",
    "title": "gdalcubes",
    "section": "",
    "text": "Apply a function over (multi-band) pixel time series\n\n\nThis generic function applies a function on pixel time series of a data cube, an R array, or other classes if implemented. The resulting object is expected to have the same spatial and temporal shape as the input, i.e., no reduction is performed.\n\n\n\napply_time(x, ...)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\ninput data\n\n\n…\nadditional arguments passed to method implementations\n\n\n\n\n\n\nreturn value and type depend on the class of x\n\n\n\n\n# 1. input is data cube\n# create image collection from example Landsat data only \n# if not already done in other examples\nif (!file.exists(file.path(tempdir(), \"L8.db\"))) {\n  L8_files <- list.files(system.file(\"L8NY18\", package = \"gdalcubes\"),\n                         \".TIF\", recursive = TRUE, full.names = TRUE)\n  create_image_collection(L8_files, \"L8_L1TP\", file.path(tempdir(), \"L8.db\"), quiet = TRUE) \n}\n\nL8.col = image_collection(file.path(tempdir(), \"L8.db\"))\nv = cube_view(extent=list(left=388941.2, right=766552.4, \n              bottom=4345299, top=4744931, t0=\"2018-01\", t1=\"2018-06\"),\n              srs=\"EPSG:32618\", nx = 497, ny=526, dt=\"P1M\")\nL8.cube = raster_cube(L8.col, v) \nL8.cube = select_bands(L8.cube, c(\"B04\", \"B05\")) \nL8.ndvi = apply_pixel(L8.cube, \"(B05-B04)/(B05+B04)\", \"NDVI\")\n\n# Apply a user defined R function\napply_time(L8.ndvi, names=\"NDVI_residuals\", \n   FUN=function(x) {\n      y = x[\"NDVI\",]\n      if (sum(is.finite(y)) < 3) {\n         return(rep(NA,ncol(x)))\n      }\n      t = 1:ncol(x)\n      return(predict(lm(y ~ t)) -  x[\"NDVI\",])})\n\nA GDAL data cube proxy object\n\nDimensions:\n         low       high count       pixel_size chunk_size\nt 2018-01-01 2018-06-30     6              P1M          6\ny    4345299    4744931   526 759.756653992395        384\nx   388941.2   766552.4   497 759.781086519115        384\n\nBands:\n            name offset scale nodata unit\n1 NDVI_residuals      0     1    NaN     \n\n# 2. input is array\nd <- c(4,16,32,32)\nx <- array(rnorm(prod(d)), d)\nz <- apply_time(x, function(v) {\n  y = matrix(NA, ncol=ncol(v), nrow=2)\n  y[1,] = (v[1,] + v[2,]) / 2\n  y[2,] = (v[3,] + v[4,]) / 2\n  y\n})\ndim(z)\n\n[1]  2 16 32 32\n\n\n\n\n\napply_time.cube\napply_time.array"
  },
  {
    "objectID": "source/reference/ref/apply_time.array.html",
    "href": "source/reference/ref/apply_time.array.html",
    "title": "gdalcubes",
    "section": "",
    "text": "Apply a function over pixel time series in a four-dimensional (band, time, y, x) array\n\n\nApply a function over pixel time series in a four-dimensional (band, time, y, x) array\n\n\n\napply_time.array(x, FUN, ...)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nfour-dimensional input array with dimensions band, time, y, x (in this order)\n\n\nFUN\nfunction that receives a vector of band values in a one-dimensional array\n\n\n…\nfurther arguments passed to FUN\n\n\n\n\n\n\nFUN is expected to produce a matrix (or vector if result has only one band) where rows are interpreted as new bands and columns represent time.\n\n\n\nThis is a helper function that uses the same dimension ordering as gdalcubes. It can be used to simplify the application of R functions e.g. over time series in a data cube.\n\n\n\n\nd <- c(4,16,32,32)\nx <- array(rnorm(prod(d)), d)\nz <- apply_time(x, function(v) {\n  y = matrix(NA, ncol=ncol(v), nrow=2)\n  y[1,] = (v[1,] + v[2,]) / 2\n  y[2,] = (v[3,] + v[4,]) / 2\n  y\n})\ndim(z)\n\n[1]  2 16 32 32"
  },
  {
    "objectID": "source/reference/ref/reduce_time.cube.html",
    "href": "source/reference/ref/reduce_time.cube.html",
    "title": "gdalcubes",
    "section": "",
    "text": "Reduce a data cube over the time dimension\n\n\nCreate a proxy data cube, which applies one or more reducer functions to selected bands over pixel time series of a data cube\n\n\n\nreduce_time.cube(x, expr, ..., FUN, names = NULL)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nsource data cube\n\n\nexpr\neither a single string, or a vector of strings defining which reducers will be applied over which bands of the input cube\n\n\n…\noptional additional expressions (if expr is not a vector)\n\n\nFUN\na user-defined R function applied over pixel time series (see Details)\n\n\nnames\ncharacter vector; if FUN is provided, names can be used to define the number and name of output bands\n\n\n\n\n\n\nThe function can either apply a built-in reducer if expr is given, or apply a custom R reducer function if FUN is provided.\nIn the former case, notice that expressions have a very simple format: the reducer is followed by the name of a band in parantheses. You cannot add more complex functions or arguments. Possible reducers currently are “min”, “max”, “sum”, “prod”, “count”, “mean”, “median”, “var”, “sd”, “which_min”, and “which_max”.\nUser-defined R reducer functions receive a two-dimensional array as input where rows correspond to the band and columns represent the time dimension. For example, one row is the time series of a specific band. FUN should always return a numeric vector with the same number of elements, which will be interpreted as bands in the result cube. Notice that it is recommended to specify the names of the output bands as a character vector. If names are missing, the number and names of output bands is tried to be derived automatically, which may fail in some cases.\n\n\n\nproxy data cube object\n\n\n\nImplemented reducers will ignore any NAN values (as na.rm=TRUE does)\nThis function returns a proxy object, i.e., it will not start any computations besides deriving the shape of the result.\n\n\n\n\n# create image collection from example Landsat data only \n# if not already done in other examples\nif (!file.exists(file.path(tempdir(), \"L8.db\"))) {\n  L8_files <- list.files(system.file(\"L8NY18\", package = \"gdalcubes\"),\n                         \".TIF\", recursive = TRUE, full.names = TRUE)\n  create_image_collection(L8_files, \"L8_L1TP\", file.path(tempdir(), \"L8.db\"), quiet = TRUE) \n}\n\nL8.col = image_collection(file.path(tempdir(), \"L8.db\"))\nv = cube_view(extent=list(left=388941.2, right=766552.4, \n              bottom=4345299, top=4744931, t0=\"2018-01\", t1=\"2018-06\"),\n              srs=\"EPSG:32618\", nx = 497, ny=526, dt=\"P1M\")\nL8.cube = raster_cube(L8.col, v) \nL8.rgb = select_bands(L8.cube, c(\"B02\", \"B03\", \"B04\"))\nL8.rgb.median = reduce_time(L8.rgb, \"median(B02)\", \"median(B03)\", \"median(B04)\")  \nL8.rgb.median\n\nA GDAL data cube proxy object\n\nDimensions:\n         low       high count       pixel_size chunk_size\nt 2018-01-01 2018-06-30     1              P6M          1\ny    4345299    4744931   526 759.756653992395        384\nx   388941.2   766552.4   497 759.781086519115        384\n\nBands:\n        name offset scale nodata unit\n1 B02_median      0     1    NaN     \n2 B03_median      0     1    NaN     \n3 B04_median      0     1    NaN     \n\nplot(L8.rgb.median, rgb=3:1)\n\n\n\n# user defined reducer calculating interquartile ranges\nL8.rgb.iqr = reduce_time(L8.rgb, names=c(\"iqr_R\", \"iqr_G\",\"iqr_B\"), FUN = function(x) {\n    c(diff(quantile(x[\"B04\",],c(0.25,0.75), na.rm=TRUE)),\n      diff(quantile(x[\"B03\",],c(0.25,0.75), na.rm=TRUE)),\n      diff(quantile(x[\"B02\",],c(0.25,0.75), na.rm=TRUE)))\n})\nL8.rgb.iqr\n\nA GDAL data cube proxy object\n\nDimensions:\n         low       high count       pixel_size chunk_size\nt 2018-01-01 2018-06-30     1              P6M          1\ny    4345299    4744931   526 759.756653992395        384\nx   388941.2   766552.4   497 759.781086519115        384\n\nBands:\n   name offset scale nodata unit\n1 iqr_R      0     1    NaN     \n2 iqr_G      0     1    NaN     \n3 iqr_B      0     1    NaN     \n\nplot(L8.rgb.iqr, key.pos=1)"
  },
  {
    "objectID": "source/reference/ref/apply_pixel.cube.html",
    "href": "source/reference/ref/apply_pixel.cube.html",
    "title": "gdalcubes",
    "section": "",
    "text": "Apply arithmetic expressions over all pixels of a data cube\n\n\nCreate a proxy data cube, which applies arithmetic expressions over all pixels of a data cube. Expressions may access band values by name.\n\n\n\napply_pixel.cube(x, expr, names = NULL, keep_bands = FALSE, ..., FUN)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nsource data cube\n\n\nexpr\ncharacter vector with one or more arithmetic expressions (see Details)\n\n\nnames\noptional character vector with the same length as expr to specify band names for the output cube\n\n\nkeep_bands\nlogical; keep bands of input data cube, defaults to FALSE, i.e. original bands will be dropped\n\n\n…\nnot used\n\n\nFUN\nuser-defined R function that is applied on all pixels (see Details)\n\n\n\n\n\n\nThe function can either apply simple arithmetic C expressions given as a character vector (expr argument), or apply a custom R reducer function if FUN is provided.\nIn the former case, gdalcubes uses the tinyexpr library to evaluate expressions in C / C++, you can look at the library documentation to see what kind of expressions you can execute. Pixel band values can be accessed by name.\nFUN receives values of the bands from one pixel as a (named) vector and should return a numeric vector with identical length for all pixels. Elements of the result vectors will be interpreted as bands in the result data cube.\n\n\n\na proxy data cube object\n\n\n\nThis function returns a proxy object, i.e., it will not start any computations besides deriving the shape of the result.\n\n\n\n\n# create image collection from example Landsat data only \n# if not already done in other examples\nif (!file.exists(file.path(tempdir(), \"L8.db\"))) {\n  L8_files <- list.files(system.file(\"L8NY18\", package = \"gdalcubes\"),\n                         \".TIF\", recursive = TRUE, full.names = TRUE)\n  create_image_collection(L8_files, \"L8_L1TP\", file.path(tempdir(), \"L8.db\"), quiet = TRUE) \n}\n\n# 1. Apply a C expression\nL8.col = image_collection(file.path(tempdir(), \"L8.db\"))\nv = cube_view(extent=list(left=388941.2, right=766552.4, \n              bottom=4345299, top=4744931, t0=\"2018-04\", t1=\"2018-06\"),\n              srs=\"EPSG:32618\", nx = 497, ny=526, dt=\"P1M\")\nL8.cube = raster_cube(L8.col, v) \nL8.cube = select_bands(L8.cube, c(\"B04\", \"B05\")) \nL8.ndvi = apply_pixel(L8.cube, \"(B05-B04)/(B05+B04)\", \"NDVI\") \nL8.ndvi\n\nA GDAL data cube proxy object\n\nDimensions:\n         low       high count       pixel_size chunk_size\nt 2018-04-01 2018-06-30     3              P1M          1\ny    4345299    4744931   526 759.756653992395        384\nx   388941.2   766552.4   497 759.781086519115        384\n\nBands:\n  name offset scale nodata unit\n1 NDVI      0     1    NaN     \n\nplot(L8.ndvi)\n\n\n\n# 2. Apply a user defined R function\nL8.ndvi.noisy = apply_pixel(L8.cube, names=\"NDVI_noisy\", \n   FUN=function(x) {\n       rnorm(1, 0, 0.1) + (x[\"B05\"]-x[\"B04\"])/(x[\"B05\"]+x[\"B04\"])\n   })\nL8.ndvi.noisy\n\nA GDAL data cube proxy object\n\nDimensions:\n         low       high count       pixel_size chunk_size\nt 2018-04-01 2018-06-30     3              P1M          1\ny    4345299    4744931   526 759.756653992395        384\nx   388941.2   766552.4   497 759.781086519115        384\n\nBands:\n        name offset scale nodata unit\n1 NDVI_noisy      0     1    NaN     \n\nplot(L8.ndvi.noisy)"
  },
  {
    "objectID": "source/reference/ref/gdalcubes_set_gdal_config.html",
    "href": "source/reference/ref/gdalcubes_set_gdal_config.html",
    "title": "gdalcubes",
    "section": "",
    "text": "Set GDAL config options\n\n\nSet GDAL config options\n\n\n\ngdalcubes_set_gdal_config(key, value)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nkey\nname of a GDAL config option to be set\n\n\nvalue\nvalue\n\n\n\n\n\n\nDetails and a list of possible options can be found at https://gdal.org/user/configoptions.html.\n\n\n\n\ngdalcubes_set_gdal_config(\"GDAL_NUM_THREADS\", \"ALL_CPUS\")"
  },
  {
    "objectID": "source/reference/ref/reduce_time.html",
    "href": "source/reference/ref/reduce_time.html",
    "title": "gdalcubes",
    "section": "",
    "text": "Reduce multidimensional data over time\n\n\nThis generic function applies a reducer function over a data cube, an R array, or other classes if implemented.\n\n\n\nreduce_time(x, ...)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nobject to be reduced\n\n\n…\nfurther arguments passed to specific implementations\n\n\n\n\n\n\nreturn value and type depend on the class of x\n\n\n\n\n# create image collection from example Landsat data only \n# if not already done in other examples\nif (!file.exists(file.path(tempdir(), \"L8.db\"))) {\n  L8_files <- list.files(system.file(\"L8NY18\", package = \"gdalcubes\"),\n                         \".TIF\", recursive = TRUE, full.names = TRUE)\n  create_image_collection(L8_files, \"L8_L1TP\", file.path(tempdir(), \"L8.db\"), quiet = TRUE) \n}\n\nL8.col = image_collection(file.path(tempdir(), \"L8.db\"))\nv = cube_view(extent=list(left=388941.2, right=766552.4, \n              bottom=4345299, top=4744931, t0=\"2018-01\", t1=\"2018-06\"),\n              srs=\"EPSG:32618\", nx = 497, ny=526, dt=\"P1M\")\nreduce_time(raster_cube(L8.col, v) , \"median(B02)\", \"median(B03)\", \"median(B04)\")  \n\nA GDAL data cube proxy object\n\nDimensions:\n         low       high count       pixel_size chunk_size\nt 2018-01-01 2018-06-30     1              P6M          1\ny    4345299    4744931   526 759.756653992395        384\nx   388941.2   766552.4   497 759.781086519115        384\n\nBands:\n        name offset scale nodata unit\n1 B02_median      0     1    NaN     \n2 B03_median      0     1    NaN     \n3 B04_median      0     1    NaN     \n\nd <- c(4,16,32,32)\nx <- array(rnorm(prod(d)), d)\ny <- reduce_time(x, function(v) {\n  apply(v, 1, mean)\n})\n\n\n\n\nreduce_time.cube\nreduce_time.array"
  },
  {
    "objectID": "source/reference/ref/add_collection_format.html",
    "href": "source/reference/ref/add_collection_format.html",
    "title": "gdalcubes",
    "section": "",
    "text": "Download and install an image collection format from a URL\n\n\nDownload and install an image collection format from a URL\n\n\n\nadd_collection_format(url, name = NULL)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nurl\nURL pointing to the collection format JSON file\n\n\nname\noptional name used to refer to the collection format\n\n\n\n\n\n\nBy default, the collection format name will be derived from the basename of the URL.\n\n\n\n\nadd_collection_format(\n   \"https://raw.githubusercontent.com/appelmar/gdalcubes/dev/formats/Sentinel1_IW_GRD.json\")\n\nWarning in readLines(destfile): incomplete final line found on '/home/marius/R/\nx86_64-pc-linux-gnu-library/4.2/gdalcubes/formats/Sentinel1_IW_GRD.json'"
  },
  {
    "objectID": "source/reference/ref/read_chunk_as_array.html",
    "href": "source/reference/ref/read_chunk_as_array.html",
    "title": "gdalcubes",
    "section": "",
    "text": "Read chunk data of a data cube from stdin or a file\n\n\nThis function can be used within function passed to chunk_apply in order to read a data cube chunk as a four-dimensional R array. It works only for R processes, which have been started from the gdalcubes C++ library. The resulting array has dimensions band, time, y, x (in this order).\n\n\n\nread_chunk_as_array(with.dimnames = TRUE)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nwith.dimnames\nif TRUE, the resulting array will contain dimnames with coordinates, datetime, and band names\n\n\n\n\n\n\nfour-dimensional array\n\n\n\nCall this function ONLY from a function passed to chunk_apply.\nThis function only works in R sessions started from gdalcubes streaming.\n\n\n\n\n# create image collection from example Landsat data only \n# if not already done in other examples\nif (!file.exists(file.path(tempdir(), \"L8.db\"))) {\n  L8_files <- list.files(system.file(\"L8NY18\", package = \"gdalcubes\"),\n                         \".TIF\", recursive = TRUE, full.names = TRUE)\n  create_image_collection(L8_files, \"L8_L1TP\", file.path(tempdir(), \"L8.db\"), quiet = TRUE) \n}\n\nL8.col = image_collection(file.path(tempdir(), \"L8.db\"))\nv = cube_view(extent=list(left=388941.2, right=766552.4,\n                          bottom=4345299, top=4744931, t0=\"2018-01\", t1=\"2018-12\"),\n                          srs=\"EPSG:32618\", nx = 497, ny=526, dt=\"P1M\")\nL8.cube = raster_cube(L8.col, v)\nL8.cube = select_bands(L8.cube, c(\"B04\", \"B05\"))\nf <- function() {\n  x <- read_chunk_as_array()\n  out <- reduce_time(x, function(x) {\n    cor(x[1,], x[2,], use=\"na.or.complete\", method = \"kendall\")\n  }) \n  write_chunk_from_array(out)\n}\nL8.cor = chunk_apply(L8.cube, f)\nplot(L8.cor, zlim=c(0,1), key.pos=1)"
  },
  {
    "objectID": "source/reference/ref/cube_view.html",
    "href": "source/reference/ref/cube_view.html",
    "title": "gdalcubes",
    "section": "",
    "text": "Create or update a spatiotemporal data cube view\n\n\nData cube views define the shape of a cube, i.e., the spatiotemporal extent, resolution, and spatial reference system (srs). They are used to access image collections as on-demand data cubes. The data cube will filter images based on the view’s extent, read image data at the defined resolution, and warp / reproject images to the target srs automatically.\n\n\n\ncube_view(\n  view,\n  extent,\n  srs,\n  nx,\n  ny,\n  nt,\n  dx,\n  dy,\n  dt,\n  aggregation,\n  resampling,\n  keep.asp = TRUE\n)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nview\nif provided, update this cube_view object instead of creating a new data cube view where fields that are already set will be overwritten\n\n\nextent\nspatioptemporal extent as a list e.g. from extent or an image collection object, see Details\n\n\nsrs\ntarget spatial reference system as a string; can be a proj4 definition, WKT, or in the form “EPSG:XXXX”\n\n\nnx\nnumber of pixels in x-direction (longitude / easting)\n\n\nny\nnumber of pixels in y-direction (latitude / northing)\n\n\nnt\nnumber of pixels in t-direction\n\n\ndx\nsize of pixels in x-direction (longitude / easting)\n\n\ndy\nsize of pixels in y-direction (latitude / northing)\n\n\ndt\nsize of pixels in time-direction, expressed as ISO8601 period string (only 1 number and unit is allowed) such as “P16D”\n\n\naggregation\naggregation method as string, defining how to deal with pixels containing data from multiple images, can be “min”, “max”, “mean”, “median”, or “first”\n\n\nresampling\nresampling method used in gdalwarp when images are read, can be “near”, “bilinear”, “bicubic” or others as supported by gdalwarp (see https://gdal.org/programs/gdalwarp.html)\n\n\nkeep.asp\nif TRUE, derive ny or dy automatically from nx or dx (or vice versa) based on the aspect ratio of the spatial extent\n\n\n\n\n\n\nThe extent argument expects a simple list with elementes left, right, bottom, top, t0 (start date/time), t1 (end date/time) or an image collection object. In the latter case, the extent function is automatically called on the image collection object to get the full spatiotemporal extent of the collection. In the former case, datetimes are expressed as ISO8601 datetime strings.\nThe function can be used in two different ways. First, it can create data cube views from scratch by defining the extent, the spatial reference system, and for each dimension either the cell size (dx, dy, dt) or the total number of cells (nx, ny, nt). Second, the function can update an existing data cube view by overwriting specific fields. In this case, the extent or some elements of the extent may be missing.\nIn some cases, the extent of the view is automatically extended if the provided resolution would end within a pixel. For example, if the spatial extent covers an area of 1km x 1km and dx = dy = 300m, the extent would be enlarged to 1.2 km x 1.2km. The alignment will be reported to the user in a diagnostic message.\n\n\n\nA list with data cube view properties\n\n\n\n\n L8_files <- list.files(system.file(\"L8NY18\", package = \"gdalcubes\"),\n                        \".TIF\", recursive = TRUE, full.names = TRUE)\n L8.col = create_image_collection(L8_files, \"L8_L1TP\")\n \n # 1. Create a new data cube view specification\n v = cube_view(extent=extent(L8.col,\"EPSG:4326\"), srs=\"EPSG:4326\", dt=\"P1M\", \n           nx=1000, ny=500, aggregation = \"mean\", resampling=\"bilinear\")\n v\n\nA data cube view object\n\nDimensions:\n         low       high count  pixel_size\nt 2018-01-01 2018-12-31    12         P1M\ny  39.249912  42.815283   500 0.007130742\nx -76.287075  -71.91114  1000 0.004375935\n\nSRS: \"EPSG:4326\"\nTemporal aggregation method: \"mean\"\nSpatial resampling method: \"bilinear\"\n\n # 2. overwrite parts of an existing data cube view\n vnew = cube_view(v, dt=\"P1M\")"
  },
  {
    "objectID": "source/reference/ref/ncdf_cube.html",
    "href": "source/reference/ref/ncdf_cube.html",
    "title": "gdalcubes",
    "section": "",
    "text": "Read a data cube from an existing netCDF file\n\n\nCreate a proxy data cube from a netCDF file that has been created using write_ncdf. This function does not read cubes from arbitrary netCDF files and can be used e.g., to load intermediate results and/or plotting existing netCDF cubes on disk without doing the data cube creation from image collections.\n\n\n\nncdf_cube(path, chunking = NULL, auto_unpack = TRUE)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\npath\npath to an existing netCDF file\n\n\nchunking\ncustom chunk sizes to read form the netCDF file; defaults to using chunk sizes from the netCDF file\n\n\nauto_unpack\nlogical; automatically apply offset and scale when reading data values\n\n\n\n\n\n\na proxy data cube object\n\n\n\nThis function returns a proxy object, i.e., it will not start any computations besides deriving the shape of the result.\n\n\n\n\n# create image collection from example Landsat data only \n# if not already done in other examples\nif (!file.exists(file.path(tempdir(), \"L8.db\"))) {\n  L8_files <- list.files(system.file(\"L8NY18\", package = \"gdalcubes\"),\n                         \".TIF\", recursive = TRUE, full.names = TRUE)\n  create_image_collection(L8_files, \"L8_L1TP\", file.path(tempdir(), \"L8.db\"), quiet = TRUE) \n}\n\nL8.col = image_collection(file.path(tempdir(), \"L8.db\"))\nv = cube_view(extent=list(left=388941.2, right=766552.4, \n              bottom=4345299, top=4744931, t0=\"2018-04\", t1=\"2018-06\"),\n              srs=\"EPSG:32618\", nx = 497, ny=526, dt=\"P1M\")\n\n\nncfile = write_ncdf(select_bands(raster_cube(L8.col, v), c(\"B02\", \"B03\", \"B04\")))\nncdf_cube(ncfile)\n\nA GDAL data cube proxy object\n\nDimensions:\n         low       high count       pixel_size chunk_size\nt 2018-04-01 2018-06-30     3              P1M          1\ny    4345299    4744931   526 759.756653992395        384\nx   388941.2   766552.4   497 759.781086519115        384\n\nBands:\n  name offset scale nodata unit\n1  B02      0     1    NaN     \n2  B03      0     1    NaN     \n3  B04      0     1    NaN"
  },
  {
    "objectID": "source/reference/ref/dim.cube.html",
    "href": "source/reference/ref/dim.cube.html",
    "title": "gdalcubes",
    "section": "",
    "text": "Query data cube properties\n\n\nQuery data cube properties\n\n\n\ndim.cube(x)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\na data cube proxy object (class cube)\n\n\n\n\n\n\nsize of a data cube (number of cells) as integer vector in the order t, y, x\n\n\n\n\n# create image collection from example Landsat data only \n# if not already done in other examples\nif (!file.exists(file.path(tempdir(), \"L8.db\"))) {\n  L8_files <- list.files(system.file(\"L8NY18\", package = \"gdalcubes\"),\n                         \".TIF\", recursive = TRUE, full.names = TRUE)\n  create_image_collection(L8_files, \"L8_L1TP\", file.path(tempdir(), \"L8.db\"), quiet = TRUE) \n}\n\nL8.col = image_collection(file.path(tempdir(), \"L8.db\"))\nv = cube_view(extent=list(left=388941.2, right=766552.4, \n              bottom=4345299, top=4744931, t0=\"2018-04\", t1=\"2018-06\"),\n              srs=\"EPSG:32618\", nx = 497, ny=526, dt=\"P1M\")\ndim(raster_cube(L8.col, v))\n\n[1]   3 526 497\n\n\n\n\n\nsize"
  },
  {
    "objectID": "source/reference/ref/select_time.html",
    "href": "source/reference/ref/select_time.html",
    "title": "gdalcubes",
    "section": "",
    "text": "Select time slices of a data cube\n\n\nCreate a proxy data cube, which selects specific time slices of a data cube. The time dimension of the resulting cube will be irregular / labeled.\n\n\n\nselect_time(cube, t)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ncube\nsource data cube\n\n\nt\ncharacter vector with date/time\n\n\n\n\n\n\nproxy data cube object\n\n\n\nThis function returns a proxy object, i.e., it will not start any computations besides deriving the shape of the result.\n\n\n\n\n# create image collection from example Landsat data only \n# if not already done in other examples\nif (!file.exists(file.path(tempdir(), \"L8.db\"))) {\n  L8_files <- list.files(system.file(\"L8NY18\", package = \"gdalcubes\"),\n                         \".TIF\", recursive = TRUE, full.names = TRUE)\n  create_image_collection(L8_files, \"L8_L1TP\", file.path(tempdir(), \"L8.db\"), quiet = TRUE) \n}\n\nL8.col = image_collection(file.path(tempdir(), \"L8.db\"))\nv = cube_view(extent=list(left=388941.2, right=766552.4, \n              bottom=4345299, top=4744931, t0=\"2018-04\", t1=\"2018-07\"),\n              srs=\"EPSG:32618\", nx = 497, ny=526, dt=\"P1M\")\nL8.cube = raster_cube(L8.col, v) \nL8.rgb = select_bands(L8.cube, c(\"B02\", \"B03\", \"B04\"))\nL8.rgb = select_time(L8.rgb, c(\"2018-04\", \"2018-07\"))\nL8.rgb\n\nA GDAL data cube proxy object\n\nDimensions:\n         low       high count       pixel_size chunk_size                values\nt 2018-04-01 2018-07-01     2              P0D          1 2018-04-01,2018-07-01\ny    4345299    4744931   526 759.756653992395        384                      \nx   388941.2   766552.4   497 759.781086519115        384                      \n\nBands:\n  name offset scale nodata unit\n1  B02      0     1    NaN     \n2  B03      0     1    NaN     \n3  B04      0     1    NaN     \n\nplot(L8.rgb, rgb=3:1)"
  },
  {
    "objectID": "source/reference/ref/filter_pixel.html",
    "href": "source/reference/ref/filter_pixel.html",
    "title": "gdalcubes",
    "section": "",
    "text": "Filter data cube pixels by a user-defined predicate on band values\n\n\nCreate a proxy data cube, which evaluates a predicate over all pixels of a data cube. For all pixels that fulfill the predicate, the original band values are returned. Other pixels are simply filled with NANs. The predicate may access band values by name.\n\n\n\nfilter_pixel(cube, pred)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ncube\nsource data cube\n\n\npred\npredicate to be evaluated over all pixels\n\n\n\n\n\n\ngdalcubes uses and extends the tinyexpr library to evaluate expressions in C / C++, you can look at the library documentation to see what kind of expressions you can execute. Pixel band values can be accessed by name.\n\n\n\na proxy data cube object\n\n\n\nThis function returns a proxy object, i.e., it will not start any computations besides deriving the shape of the result.\n\n\n\n\n# create image collection from example Landsat data only \n# if not already done in other examples\nif (!file.exists(file.path(tempdir(), \"L8.db\"))) {\n  L8_files <- list.files(system.file(\"L8NY18\", package = \"gdalcubes\"),\n                         \".TIF\", recursive = TRUE, full.names = TRUE)\n  create_image_collection(L8_files, \"L8_L1TP\", file.path(tempdir(), \"L8.db\"), quiet = TRUE) \n}\n\nL8.col = image_collection(file.path(tempdir(), \"L8.db\"))\nv = cube_view(extent=list(left=388941.2, right=766552.4, \n              bottom=4345299, top=4744931, t0=\"2018-01\", t1=\"2018-06\"),\n              srs=\"EPSG:32618\", nx = 497, ny=526, dt=\"P1M\")\nL8.cube = raster_cube(L8.col, v) \nL8.cube = select_bands(L8.cube, c(\"B04\", \"B05\")) \nL8.ndvi = apply_pixel(L8.cube, \"(B05-B04)/(B05+B04)\", \"NDVI\") \nL8.ndvi.filtered = filter_pixel(L8.ndvi, \"NDVI > 0.5\") \nL8.ndvi.filtered\n\nA GDAL data cube proxy object\n\nDimensions:\n         low       high count       pixel_size chunk_size\nt 2018-01-01 2018-06-30     6              P1M          1\ny    4345299    4744931   526 759.756653992395        384\nx   388941.2   766552.4   497 759.781086519115        384\n\nBands:\n  name offset scale nodata unit\n1 NDVI      0     1    NaN     \n\nplot(L8.ndvi.filtered)"
  },
  {
    "objectID": "source/reference/ref/plot.cube.html",
    "href": "source/reference/ref/plot.cube.html",
    "title": "gdalcubes",
    "section": "",
    "text": "Plot a gdalcubes data cube\n\n\nPlot a gdalcubes data cube\n\n\n\nplot.cube(\n  x,\n  y,\n  ...,\n  nbreaks = 11,\n  breaks = NULL,\n  col = grey(1:(nbreaks - 1)/nbreaks),\n  key.pos = NULL,\n  bands = NULL,\n  t = NULL,\n  rgb = NULL,\n  zlim = NULL,\n  gamma = 1,\n  periods.in.title = TRUE,\n  join.timeseries = FALSE,\n  axes = TRUE,\n  ncol = NULL,\n  nrow = NULL,\n  downsample = TRUE,\n  na.color = \"#AAAAAA\"\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\na data cube proxy object (class cube)\n\n\ny\nnot used\n\n\n…\nfurther arguments passed to image.default\n\n\nnbreaks\nnumber of breaks, should be one more than the number of colors given\n\n\nbreaks\nactual breaks used to assign colors to values; if missing, the function subsamples values and uses equally sized intervals between min and max or zlim[0] and zlim[1] if defined\n\n\ncol\ncolor definition, can be a character vector with nbreaks - 1 elements or a function such as heat.colors\n\n\nkey.pos\nposition for the legend, 1 (bottom), 2 (left), 3 (top), or 4 (right). If NULL (the default), do not plot a legend.\n\n\nbands\ninteger vector with band numbers to plot (this must be band numbers, not band names)\n\n\nt\ninteger vector with time indexes to plot (this must be time indexes, not date / time)\n\n\nrgb\nbands used to assign RGB color channels, vector of length 3 (this must be band numbers, not band names)\n\n\nzlim\nvector of length 2, defining the minimum and maximum values to either derive breaks, or define black and white values in RGB plots\n\n\ngamma\ngamma correction value, used for RGB plots only\n\n\nperiods.in.title\nlogical value, if TRUE, the title of plots includes the datetime period length as ISO 8601 string\n\n\njoin.timeseries\nlogical, for pure time-series plots, shall time series of multiple bands be plotted in a single plot (with different colors)?\n\n\naxes\nlogical, if TRUE, plots include axes\n\n\nncol\nnumber of columns for arranging plots with layout(), see Details\n\n\nnrow\nnumber of rows for arranging plots with layout(), see Details\n\n\ndownsample\nlength-one integer or logical value used to select only every i-th pixel (in space only) for faster plots; by default (TRUE), downsampling will be determined automatically based on the resolution of the graphics device; set to FALSE to avoid downsampling.\n\n\nna.color\ncolor used to plot NA pixels\n\n\n\n\n\n\nThe style of the plot depends on provided parameters and on the shape of the cube, i.e., whether it is a pure time series and whether it contains multiple bands or not. Multi-band, multi-temporal images will be arranged with layout() such that bands are represented by columns and time is represented by rows. Time series plots can be combined to a single plot by setting join.timeseries = TRUE. The layout can be controlled with ncol and nrow, which define the number of rows and columns in the plot layout. Typically, only one of ncol and nrow is provided. For multi-band, multi-temporal plots, the actual number of rows or columns can be less if the input cube has less bands or time slices.\nThe downsample argument is used to speed-up plotting if the cube has much more pixels than the graphics device. If set to a scalar integer value > 1, the value is used to skip pixels in the spatial dimensions. For example, setting downsample = 4 means that every fourth pixel is used in the spatial dimensions. If TRUE (the default) downsample is derived automatically based on the sizes of the cube and the graphics device. If 1 or FALSE, no additional downsampling is performed. Notice that downsampling is only used for plotting. The size of the data cube (and hence the computation time to process the data cube) is not modified.\n\n\n\nIf caching is enabled for the package (see gdalcubes_options), repeated calls of plot for the same data cube will not reevaluate the cube. Instead, the temporary result file will be reused, if possible.\nSome parts of the function have been copied from the stars package (c) Edzer Pebesma\n\n\n\n\n# create image collection from example Landsat data only \n# if not already done in other examples\nif (!file.exists(file.path(tempdir(), \"L8.db\"))) {\n  L8_files <- list.files(system.file(\"L8NY18\", package = \"gdalcubes\"),\n                         \".TIF\", recursive = TRUE, full.names = TRUE)\n  create_image_collection(L8_files, \"L8_L1TP\", file.path(tempdir(), \"L8.db\"), quiet = TRUE) \n}\n\nL8.col = image_collection(file.path(tempdir(), \"L8.db\"))\nv = cube_view(extent=list(left=388941.2, right=766552.4, \n              bottom=4345299, top=4744931, t0=\"2018-04\", t1=\"2018-06\"),\n              srs=\"EPSG:32618\", nx = 497, ny=526, dt=\"P1M\")\n              \nplot(select_bands(raster_cube(L8.col, v), c(\"B02\", \"B03\", \"B04\")), rgb=3:1)\n\n\n\nL8.cube = select_bands(raster_cube(L8.col, v), c(\"B04\", \"B05\")) \nL8.ndvi = apply_pixel(L8.cube, \"(B05-B04)/(B05+B04)\", \"NDVI\") \nplot(reduce_time(L8.ndvi, \"median(NDVI)\"), key.pos=1, zlim=c(0,1))"
  },
  {
    "objectID": "source/reference/ref/write_chunk_from_array.html",
    "href": "source/reference/ref/write_chunk_from_array.html",
    "title": "gdalcubes",
    "section": "",
    "text": "Write chunk data of a cube to stdout or a file\n\n\nThis function can be used within function passed to chunk_apply in order to pass four-dimensional R arrays as a data cube chunk to the gdalcubes C++ library. It works only for R processes, which have been started from the gdalcubes C++ library. The input array must have dimensions band, time, y, x (in this order).\n\n\n\nwrite_chunk_from_array(v)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nv\nfour-dimensional array with dimensions band, time, y, and x\n\n\n\n\n\n\nCall this function ONLY from a function passed to chunk_apply.\nThis function only works in R sessions started from gdalcubes streaming.\n\n\n\n\n# create image collection from example Landsat data only \n# if not already done in other examples\nif (!file.exists(file.path(tempdir(), \"L8.db\"))) {\n  L8_files <- list.files(system.file(\"L8NY18\", package = \"gdalcubes\"),\n                         \".TIF\", recursive = TRUE, full.names = TRUE)\n  create_image_collection(L8_files, \"L8_L1TP\", file.path(tempdir(), \"L8.db\"), quiet = TRUE) \n}\n\nL8.col = image_collection(file.path(tempdir(), \"L8.db\"))\nv = cube_view(extent=list(left=388941.2, right=766552.4,\n                          bottom=4345299, top=4744931, t0=\"2018-01\", t1=\"2018-12\"),\n                          srs=\"EPSG:32618\", nx = 497, ny=526, dt=\"P1M\")\nL8.cube = raster_cube(L8.col, v)\nL8.cube = select_bands(L8.cube, c(\"B04\", \"B05\"))\nf <- function() {\n  x <- read_chunk_as_array()\n  out <- reduce_time(x, function(x) {\n    cor(x[1,], x[2,], use=\"na.or.complete\", method = \"kendall\")\n  }) \n  write_chunk_from_array(out)\n}\nL8.cor = chunk_apply(L8.cube, f)\nplot(L8.cor, zlim=c(0,1), key.pos=1)"
  },
  {
    "objectID": "source/reference/ref/apply_time.cube.html",
    "href": "source/reference/ref/apply_time.cube.html",
    "title": "gdalcubes",
    "section": "",
    "text": "Apply a user-defined R function over (multi-band) pixel time series\n\n\nCreate a proxy data cube, which applies a user-defined R function over all pixel time series of a data cube. In contrast to reduce_time, the time dimension is not reduced, i.e., resulting time series must have identical length as the input data cube but may contain a different number of bands / variables. Example uses of this function may include time series decompositions, cumulative sums / products, smoothing, sophisticated NA filling, or similar.\n\n\n\napply_time.cube(x, names = NULL, keep_bands = FALSE, FUN, ...)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nsource data cube\n\n\nnames\noptional character vector to specify band names for the output cube\n\n\nkeep_bands\nlogical; keep bands of input data cube, defaults to FALSE, i.e., original bands will be dropped\n\n\nFUN\nuser-defined R function that is applied on all pixel time series (see Details)\n\n\n…\nnot used\n\n\n\n\n\n\nFUN receives a single (multi-band) pixel time series as a matrix with rows corresponding to bands and columns corresponding to time. In general, the function must return a matrix with the same number of columns. If re result contains only a single band, it may alternatively return a vector with length identical to the length of the input time series (number of columns of the input).\n\n\n\na proxy data cube object\n\n\n\nThis function returns a proxy object, i.e., it will not start any computations besides deriving the shape of the result.\n\n\n\n\n# create image collection from example Landsat data only \n# if not already done in other examples\nif (!file.exists(file.path(tempdir(), \"L8.db\"))) {\n  L8_files <- list.files(system.file(\"L8NY18\", package = \"gdalcubes\"),\n                         \".TIF\", recursive = TRUE, full.names = TRUE)\n  create_image_collection(L8_files, \"L8_L1TP\", file.path(tempdir(), \"L8.db\"), quiet = TRUE) \n}\n\nL8.col = image_collection(file.path(tempdir(), \"L8.db\"))\nv = cube_view(extent=list(left=388941.2, right=766552.4, \n              bottom=4345299, top=4744931, t0=\"2018-01\", t1=\"2018-06\"),\n              srs=\"EPSG:32618\", nx = 497, ny=526, dt=\"P1M\")\nL8.cube = raster_cube(L8.col, v) \nL8.cube = select_bands(L8.cube, c(\"B04\", \"B05\")) \nL8.ndvi = apply_pixel(L8.cube, \"(B05-B04)/(B05+B04)\", \"NDVI\")\n\n# Apply a user defined R function\nL8.ndvi.resid = apply_time(L8.ndvi, names=\"NDVI_residuals\", \n   FUN=function(x) {\n      y = x[\"NDVI\",]\n      if (sum(is.finite(y)) < 3) {\n         return(rep(NA,ncol(x)))\n      }\n      t = 1:ncol(x)\n      return(predict(lm(y ~ t)) -  x[\"NDVI\",])\n   })\nL8.ndvi.resid\n\nA GDAL data cube proxy object\n\nDimensions:\n         low       high count       pixel_size chunk_size\nt 2018-01-01 2018-06-30     6              P1M          6\ny    4345299    4744931   526 759.756653992395        384\nx   388941.2   766552.4   497 759.781086519115        384\n\nBands:\n            name offset scale nodata unit\n1 NDVI_residuals      0     1    NaN     \n\nplot(L8.ndvi.resid)"
  },
  {
    "objectID": "source/reference/ref/nx.html",
    "href": "source/reference/ref/nx.html",
    "title": "gdalcubes",
    "section": "",
    "text": "Query data cube properties\n\n\nQuery data cube properties\n\n\n\nnx(obj)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobj\na data cube proxy object (class cube)\n\n\n\n\n\n\nNumber of pixels in the x dimension\n\n\n\n\n# create image collection from example Landsat data only \n# if not already done in other examples\nif (!file.exists(file.path(tempdir(), \"L8.db\"))) {\n  L8_files <- list.files(system.file(\"L8NY18\", package = \"gdalcubes\"),\n                         \".TIF\", recursive = TRUE, full.names = TRUE)\n  create_image_collection(L8_files, \"L8_L1TP\", file.path(tempdir(), \"L8.db\"), quiet = TRUE) \n}\n\nL8.col = image_collection(file.path(tempdir(), \"L8.db\"))\nv = cube_view(extent=list(left=388941.2, right=766552.4, \n              bottom=4345299, top=4744931, t0=\"2018-04\", t1=\"2018-06\"),\n              srs=\"EPSG:32618\", nx = 497, ny=526, dt=\"P1M\")\nnx(raster_cube(L8.col, v))\n\n[1] 497"
  },
  {
    "objectID": "source/reference/ref/image_collection.html",
    "href": "source/reference/ref/image_collection.html",
    "title": "gdalcubes",
    "section": "",
    "text": "Load an existing image collection from a file\n\n\nThis function will load an image collection from an SQLite file. Image collection files index and reference existing imagery. To create a collection from files on disk, use create_image_collection.\n\n\n\nimage_collection(path)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\npath\npath to an existing image collection file\n\n\n\n\n\n\nan image collection proxy object, which can be used to create a data cube using raster_cube\n\n\n\n\n# create image collection from example Landsat data only \n# if not already done in other examples\nif (!file.exists(file.path(tempdir(), \"L8.db\"))) {\n  L8_files <- list.files(system.file(\"L8NY18\", package = \"gdalcubes\"),\n                         \".TIF\", recursive = TRUE, full.names = TRUE)\n  create_image_collection(L8_files, \"L8_L1TP\", file.path(tempdir(), \"L8.db\"), quiet = TRUE) \n}\n\nL8.col = image_collection(file.path(tempdir(), \"L8.db\"))\nL8.col\n\nImage collection object, referencing 19 images with 12 bands\nImages:\n                                      name      left      top   bottom\n1 LC08_L1TP_013032_20180131_20180207_01_T1 -74.67898 41.39099 39.25027\n2 LC08_L1TP_013032_20180405_20180417_01_T1 -74.70333 41.39106 39.25080\n3 LC08_L1TP_013032_20180421_20180502_01_T1 -74.70681 41.39107 39.25098\n4 LC08_L1TP_013032_20180710_20180717_01_T1 -74.66854 41.39096 39.24991\n5 LC08_L1TP_013032_20180827_20180911_01_T1 -74.67202 41.39097 39.25000\n6 LC08_L1TP_013032_20181030_20181115_01_T1 -74.69637 41.39104 39.25062\n      right            datetime        srs\n1 -71.92546 2018-01-31T00:00:00 EPSG:32618\n2 -71.94695 2018-04-05T00:00:00 EPSG:32618\n3 -71.95411 2018-04-21T00:00:00 EPSG:32618\n4 -71.91114 2018-07-10T00:00:00 EPSG:32618\n5 -71.91472 2018-08-27T00:00:00 EPSG:32618\n6 -71.93979 2018-10-30T00:00:00 EPSG:32618\n[ omitted 13 images ] \n\nBands:\n   name offset scale unit   nodata image_count\n1   B01      0     1      0.000000          19\n2   B02      0     1      0.000000          19\n3   B03      0     1      0.000000          19\n4   B04      0     1      0.000000          19\n5   B05      0     1      0.000000          19\n6   B06      0     1      0.000000          19\n7   B07      0     1      0.000000          19\n8   B08      0     1      0.000000          19\n9   B09      0     1      0.000000          19\n10  B10      0     1      0.000000          19\n11  B11      0     1      0.000000          19\n12  BQA      0     1                        19"
  },
  {
    "objectID": "source/reference/ref/chunk_apply.html",
    "href": "source/reference/ref/chunk_apply.html",
    "title": "gdalcubes",
    "section": "",
    "text": "Apply an R function on chunks of a data cube\n\n\nApply an R function on chunks of a data cube\n\n\n\nchunk_apply(cube, f)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ncube\nsource data cube\n\n\nf\nR function to apply over all chunks\n\n\n\n\n\n\nThis function internally creates a gdalcubes stream data cube, which streams data of a chunk to a new R process. For reading data, the function typically calls x <- read_chunk_as_array() which then results in a 4 dimensional (band, time, y, x) array. Similarly write_chunk_from_array(x) will write a result array as a chunk in the resulting data cube. The chunk size of the input cube is important to control how the function will be exposed to the data cube. For example, if you want to apply an R function over complete pixel time series, you must define the chunk size argument in raster_cube to make sure that chunk contain the correct parts of the data.\n\n\n\na proxy data cube object\n\n\n\nThis function returns a proxy object, i.e., it will not start any computations besides deriving the shape of the result.\n\n\n\n\n# create image collection from example Landsat data only \n# if not already done in other examples\nif (!file.exists(file.path(tempdir(), \"L8.db\"))) {\n  L8_files <- list.files(system.file(\"L8NY18\", package = \"gdalcubes\"),\n                         \".TIF\", recursive = TRUE, full.names = TRUE)\n  create_image_collection(L8_files, \"L8_L1TP\", file.path(tempdir(), \"L8.db\"), quiet = TRUE) \n}\n\nL8.col = image_collection(file.path(tempdir(), \"L8.db\"))\nv = cube_view(extent=list(left=388941.2, right=766552.4,\n                          bottom=4345299, top=4744931, t0=\"2018-01\", t1=\"2018-12\"),\n                          srs=\"EPSG:32618\", nx = 497, ny=526, dt=\"P1M\")\nL8.cube = raster_cube(L8.col, v)\nL8.cube = select_bands(L8.cube, c(\"B04\", \"B05\"))\nf <- function() {\n  x <- read_chunk_as_array()\n  out <- reduce_time(x, function(x) {\n    cor(x[1,], x[2,], use=\"na.or.complete\", method = \"kendall\")\n  }) \n  write_chunk_from_array(out)\n}\nL8.cor = chunk_apply(L8.cube, f)"
  },
  {
    "objectID": "source/reference/ref/reduce_time.array.html",
    "href": "source/reference/ref/reduce_time.array.html",
    "title": "gdalcubes",
    "section": "",
    "text": "Apply a function over time and bands in a four-dimensional (band, time, y, x) array and reduce time dimension\n\n\nApply a function over time and bands in a four-dimensional (band, time, y, x) array and reduce time dimension\n\n\n\nreduce_time.array(x, FUN, ...)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nfour-dimensional input array with dimensions band, time, y, x (in this order)\n\n\nFUN\nfunction which receives one time series in a two-dimensional array with dimensions bands, time as input\n\n\n…\nfurther arguments passed to FUN\n\n\n\n\n\n\nFUN is expected to produce a numeric vector (or scalar) where elements are interpreted as new bands in the result.\n\n\n\nThis is a helper function that uses the same dimension ordering as gdalcubes streaming. It can be used to simplify the application of R functions e.g. over time series in a data cube.\n\n\n\n\nd <- c(4,16,32,32)\nx <- array(rnorm(prod(d)), d)\n# reduce individual bands over pixel time series\ny <- reduce_time(x, function(v) {\n  apply(v, 1, mean)\n})\ndim(y)\n\n[1]  4  1 32 32"
  },
  {
    "objectID": "source/reference/ref/window_time.cube.html",
    "href": "source/reference/ref/window_time.cube.html",
    "title": "gdalcubes",
    "section": "",
    "text": "Apply a moving window function over the time dimension of a data cube\n\n\nCreate a proxy data cube, which applies one ore more moving window functions to selected bands over pixel time series of a data cube. The fuction can either use a predefined agggregation function or apply a custom convolution kernel.\n\n\n\nwindow_time.cube(x, expr, ..., kernel, window)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nsource data cube\n\n\nexpr\neither a single string, or a vector of strings defining which reducers wlil be applied over which bands of the input cube\n\n\n…\noptional additional expressions (if expr is not a vector)\n\n\nkernel\nnumeric vector with elements of the kernel\n\n\nwindow\ninteger vector with two elements defining the size of the window before and after a cell, the total size of the window is window[1] + 1 + window[2]\n\n\n\n\n\n\nThe function either applies a kernel convolution (if the kernel argument is provided) or a general reducer function over moving temporal windows. In the former case, the kernel convolution will be applied over all bands of the input cube, i.e., the output cube will have the same number of bands as the input cubes. If a kernel is given and the window argument is missing, the window will be symmetric to the center pixel with the size of the provided kernel. For general reducer functions, the window argument must be provided and several expressions can be used to create multiple bands in the output cube.\nNotice that expressions have a very simple format: the reducer is followed by the name of a band in parantheses. You cannot add more complex functions or arguments.\nPossible reducers currently are “min”, “max”, “sum”, “prod”, “count”, “mean”, “median”.\n\n\n\nproxy data cube object\n\n\n\nImplemented reducers will ignore any NAN values (as na.rm=TRUE does).\nThis function returns a proxy object, i.e., it will not start any computations besides deriving the shape of the result.\n\n\n\n\n# create image collection from example Landsat data only \n# if not already done in other examples\nif (!file.exists(file.path(tempdir(), \"L8.db\"))) {\n  L8_files <- list.files(system.file(\"L8NY18\", package = \"gdalcubes\"),\n                         \".TIF\", recursive = TRUE, full.names = TRUE)\n  create_image_collection(L8_files, \"L8_L1TP\", file.path(tempdir(), \"L8.db\"), quiet = TRUE) \n}\n\nL8.col = image_collection(file.path(tempdir(), \"L8.db\"))\nv = cube_view(extent=list(left=388941.2, right=766552.4, \n                          bottom=4345299, top=4744931, t0=\"2018-01\", t1=\"2018-07\"),\n                          srs=\"EPSG:32618\", nx = 400, dt=\"P1M\")\nL8.cube = raster_cube(L8.col, v) \nL8.nir = select_bands(L8.cube, c(\"B05\"))\nL8.nir.min = window_time(L8.nir, window = c(2,2), \"min(B05)\")  \nL8.nir.min\n\nA GDAL data cube proxy object\n\nDimensions:\n         low       high count       pixel_size chunk_size\nt 2018-01-01 2018-07-31     7              P1M          1\ny    4345299    4744931   423 944.756501182033        320\nx   388941.2   766552.4   400          944.028        320\n\nBands:\n     name offset scale nodata unit\n1 B05_min      0     1    NaN     \n\nL8.nir.kernel = window_time(L8.nir, kernel=c(-1,1), window=c(1,0))  \nL8.nir.kernel\n\nA GDAL data cube proxy object\n\nDimensions:\n         low       high count       pixel_size chunk_size\nt 2018-01-01 2018-07-31     7              P1M          1\ny    4345299    4744931   423 944.756501182033        320\nx   388941.2   766552.4   400          944.028        320\n\nBands:\n  name offset scale nodata unit\n1  B05      0     1    NaN"
  },
  {
    "objectID": "source/reference/ref/add_images.html",
    "href": "source/reference/ref/add_images.html",
    "title": "gdalcubes",
    "section": "",
    "text": "Add images to an existing image collection\n\n\nThis function adds provided files or GDAL dataset identifiers and to an existing image collection by extracting datetime, image identifiers, and band information according to the collection’s format.\n\n\n\nadd_images(\n  image_collection,\n  files,\n  unroll_archives = TRUE,\n  out_file = \"\",\n  quiet = FALSE\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nimage_collection\nimage_collection object or path to an existing collection file\n\n\nfiles\ncharacter vector with paths to image files on disk or any GDAL dataset identifiers (including virtual file systems and higher level drivers or GDAL subdatasets)\n\n\nunroll_archives\nautomatically convert .zip, .tar archives and .gz compressed files to GDAL virtual file system dataset identifiers (e.g. by prepending /vsizip/) and add contained files to the list of considered files\n\n\nout_file\npath to output file, an empty string (the default) will update the collection in-place, whereas images will be added to a new copy of the image collection at the given location otherwise.\n\n\nquiet\nlogical; if TRUE, do not print resulting image collection if return value is not assigned to a variable\n\n\n\n\n\n\nimage collection proxy object, which can be used to create a data cube using raster_cube\n\n\n\n\nL8_files <- list.files(system.file(\"L8NY18\", package = \"gdalcubes\"),\n                         \".TIF\", recursive = TRUE, full.names = TRUE)\nL8_col = create_image_collection(L8_files[1:12], \"L8_L1TP\") \nadd_images(L8_col, L8_files[13:24])\n\nImage collection object, referencing 2 images with 12 bands\nImages:\n                                      name      left      top   bottom\n1 LC08_L1TP_013032_20180131_20180207_01_T1 -74.67898 41.39099 39.25027\n2 LC08_L1TP_013032_20180405_20180417_01_T1 -74.70333 41.39106 39.25080\n      right            datetime        srs\n1 -71.92546 2018-01-31T00:00:00 EPSG:32618\n2 -71.94695 2018-04-05T00:00:00 EPSG:32618\n\nBands:\n   name offset scale unit   nodata image_count\n1   B01      0     1      0.000000           2\n2   B02      0     1      0.000000           2\n3   B03      0     1      0.000000           2\n4   B04      0     1      0.000000           2\n5   B05      0     1      0.000000           2\n6   B06      0     1      0.000000           2\n7   B07      0     1      0.000000           2\n8   B08      0     1      0.000000           2\n9   B09      0     1      0.000000           2\n10  B10      0     1      0.000000           2\n11  B11      0     1      0.000000           2\n12  BQA      0     1                         2"
  },
  {
    "objectID": "source/reference/ref/st_as_stars.cube.html",
    "href": "source/reference/ref/st_as_stars.cube.html",
    "title": "gdalcubes",
    "section": "",
    "text": "Coerce gdalcubes object into a stars object\n\n\nThe function materializes a data cube as a temporary netCDF file and loads the file with the stars package.\n\n\n\nst_as_stars.cube(.x, ...)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\n.x\ndata cube object to coerce\n\n\n…\nnot used\n\n\n\n\n\n\nstars object\n\n\n\n\n# create image collection from example Landsat data only \n# if not already done in other examples\nif (!file.exists(file.path(tempdir(), \"L8.db\"))) {\n  L8_files <- list.files(system.file(\"L8NY18\", package = \"gdalcubes\"),\n                         \".TIF\", recursive = TRUE, full.names = TRUE)\n  create_image_collection(L8_files, \"L8_L1TP\", file.path(tempdir(), \"L8.db\"), quiet = TRUE) \n}\n\nL8.col = image_collection(file.path(tempdir(), \"L8.db\"))\nv = cube_view(extent=list(left=388941.2, right=766552.4, \n              bottom=4345299, top=4744931, t0=\"2018-04\", t1=\"2018-04\"),\n              srs=\"EPSG:32618\", nx = 497, ny=526, dt=\"P1M\")\nif(require(\"stars\"))\n  st_as_stars(select_bands(raster_cube(L8.col, v), c(\"B04\", \"B05\")))\n\nLoading required package: stars\n\n\nLoading required package: abind\n\n\nLoading required package: sf\n\n\nLinking to GEOS 3.10.1, GDAL 3.4.0, PROJ 8.2.0; sf_use_s2() is TRUE\n\n\nstars object with 3 dimensions and 2 attributes\nattribute(s):\n                           Min. 1st Qu. Median     Mean 3rd Qu.  Max.  NA's\nfilebfd1839939b47.nc\":B04  6119    6928   8717 11063.82   10620 53002 99070\nfilebfd1839939b47.nc\":B05  5564    6411  13519 14300.35   17073 57497 99070\ndimension(s):\n     from  to  offset    delta                refsys point\nx       1 497  388941  759.781 WGS 84 / UTM zone 18N    NA\ny       1 526 4744931 -759.757 WGS 84 / UTM zone 18N    NA\ntime    1   1      NA       NA               POSIXct FALSE\n                      values x/y\nx                       NULL [x]\ny                       NULL [y]\ntime [2018-04-01,2018-05-01)"
  },
  {
    "objectID": "source/reference/ref/window_time.html",
    "href": "source/reference/ref/window_time.html",
    "title": "gdalcubes",
    "section": "",
    "text": "Apply a moving window operation over time\n\n\nThis generic function applies a reducer function over a moving window over the time dimension of a data cube, an R array, or other classes if implemented.\n\n\n\nwindow_time(x, ...)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nobject to be reduced\n\n\n…\nfurther arguments passed to specific implementations\n\n\n\n\n\n\nvalue and type depend on the class of x\n\n\n\n\n# create image collection from example Landsat data only \n# if not already done in other examples\nif (!file.exists(file.path(tempdir(), \"L8.db\"))) {\n  L8_files <- list.files(system.file(\"L8NY18\", package = \"gdalcubes\"),\n                         \".TIF\", recursive = TRUE, full.names = TRUE)\n  create_image_collection(L8_files, \"L8_L1TP\", file.path(tempdir(), \"L8.db\"), quiet = TRUE) \n}\n\nL8.col = image_collection(file.path(tempdir(), \"L8.db\"))\nv = cube_view(extent=list(left=388941.2, right=766552.4, \n                          bottom=4345299, top=4744931, t0=\"2018-01\", t1=\"2018-07\"),\n                          srs=\"EPSG:32618\", nx = 400, dt=\"P1M\")\nL8.cube = raster_cube(L8.col, v) \nL8.nir = select_bands(L8.cube, c(\"B05\"))\nwindow_time(L8.nir, window = c(2,2), \"min(B05)\")  \n\nA GDAL data cube proxy object\n\nDimensions:\n         low       high count       pixel_size chunk_size\nt 2018-01-01 2018-07-31     7              P1M          1\ny    4345299    4744931   423 944.756501182033        320\nx   388941.2   766552.4   400          944.028        320\n\nBands:\n     name offset scale nodata unit\n1 B05_min      0     1    NaN     \n\nwindow_time(L8.nir, kernel=c(-1,1), window=c(1,0))\n\nA GDAL data cube proxy object\n\nDimensions:\n         low       high count       pixel_size chunk_size\nt 2018-01-01 2018-07-31     7              P1M          1\ny    4345299    4744931   423 944.756501182033        320\nx   388941.2   766552.4   400          944.028        320\n\nBands:\n  name offset scale nodata unit\n1  B05      0     1    NaN     \n\nplot(window_time(L8.nir, kernel=c(-1,1), window=c(1,0)), key.pos=1)\n\n\n\n\n\n\n\nwindow_time.cube"
  },
  {
    "objectID": "source/reference/ref/raster_cube.html",
    "href": "source/reference/ref/raster_cube.html",
    "title": "gdalcubes",
    "section": "",
    "text": "Create a data cube from an image collection\n\n\nCreate a proxy data cube, which loads data from a given image collection according to a data cube view\n\n\n\nraster_cube(\n  image_collection,\n  view,\n  mask = NULL,\n  chunking = .pkgenv$default_chunksize\n)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nimage_collection\nSource image collection as from image_collection or create_image_collection\n\n\nview\nA data cube view defining the shape (spatiotemporal extent, resolution, and spatial reference), if missing, a default overview is used\n\n\nmask\nmask pixels of images based on band values, see image_mask\n\n\nchunking\nlength-3 vector or a function returning a vector of length 3, defining the size of data cube chunks in the order time, y, x.\n\n\n\n\n\n\nThe following steps will be performed when the data cube is requested to read data of a chunk:\n\nFind images from the input collection that intersect with the spatiotemporal extent of the chunk\nFor all resulting images, apply gdalwarp to reproject, resize, and resample to an in-memory GDAL dataset\nRead the resulting data to the chunk buffer and optionally apply a mask on the result\nUpdate pixel-wise aggregator (as defined in the data cube view) to combine values of multiple images within the same data cube pixels\n\nIf chunking is provided as a function, it must accept exactly three arguments for the total size of the cube in t, y, and x axes (in this order).\n\n\n\nA proxy data cube object\n\n\n\nThis function returns a proxy object, i.e., it will not start any computations besides deriving the shape of the result.\n\n\n\n\n# create image collection from example Landsat data only \n# if not already done in other examples\nif (!file.exists(file.path(tempdir(), \"L8.db\"))) {\n  L8_files <- list.files(system.file(\"L8NY18\", package = \"gdalcubes\"),\n                         \".TIF\", recursive = TRUE, full.names = TRUE)\n  create_image_collection(L8_files, \"L8_L1TP\", file.path(tempdir(), \"L8.db\"), quiet = TRUE) \n}\n\nL8.col = image_collection(file.path(tempdir(), \"L8.db\"))\nv = cube_view(extent=list(left=388941.2, right=766552.4, \n              bottom=4345299, top=4744931, t0=\"2018-01\", t1=\"2018-12\"),\n              srs=\"EPSG:32618\", nx = 497, ny=526, dt=\"P1M\")\nraster_cube(L8.col, v)\n\nA GDAL data cube proxy object\n\nDimensions:\n         low       high count       pixel_size chunk_size\nt 2018-01-01 2018-12-31    12              P1M          1\ny    4345299    4744931   526 759.756653992395        384\nx   388941.2   766552.4   497 759.781086519115        384\n\nBands:\n   name offset scale nodata unit\n1   B01      0     1    NaN     \n2   B02      0     1    NaN     \n3   B03      0     1    NaN     \n4   B04      0     1    NaN     \n5   B05      0     1    NaN     \n6   B06      0     1    NaN     \n7   B07      0     1    NaN     \n8   B08      0     1    NaN     \n9   B09      0     1    NaN     \n10  B10      0     1    NaN     \n11  B11      0     1    NaN     \n12  BQA      0     1    NaN     \n\n # using a mask on the Landsat quality bit band to filter out clouds\n raster_cube(L8.col, v, mask=image_mask(\"BQA\", bits=4, values=16))\n\nA GDAL data cube proxy object\n\nDimensions:\n         low       high count       pixel_size chunk_size\nt 2018-01-01 2018-12-31    12              P1M          1\ny    4345299    4744931   526 759.756653992395        384\nx   388941.2   766552.4   497 759.781086519115        384\n\nBands:\n   name offset scale nodata unit\n1   B01      0     1    NaN     \n2   B02      0     1    NaN     \n3   B03      0     1    NaN     \n4   B04      0     1    NaN     \n5   B05      0     1    NaN     \n6   B06      0     1    NaN     \n7   B07      0     1    NaN     \n8   B08      0     1    NaN     \n9   B09      0     1    NaN     \n10  B10      0     1    NaN     \n11  B11      0     1    NaN     \n12  BQA      0     1    NaN"
  },
  {
    "objectID": "source/reference/ref/gdalcubes_selection.html",
    "href": "source/reference/ref/gdalcubes_selection.html",
    "title": "gdalcubes",
    "section": "",
    "text": "Subsetting data cubes\n\n\nSubset data cube dimensions and bands / variables.\n\n\n\n$.cube(x, name)\n\n[.cube(x, ib = TRUE, it = TRUE, iy = TRUE, ix = TRUE, ...)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nsource data cube\n\n\nname\ncharacter; name of selected band\n\n\nib\nfirst selector (optional), object of type character, list, Date, POSIXt, numeric, [sf::st_bbox](sf::st_bbox), or [sf::st_sfc](sf::st_sfc), see Details and examples\n\n\nit\nsecond selector (optional), see ib\n\n\niy\nthird selector (optional), see ib\n\n\nix\nfourth selector (optional), see ib\n\n\n…\nfurther arguments, not used\n\n\n\n\n\n\nThe [] operator allows for flexible subsetting of data cubes by date, datetime,\nbounding box, spatial points, and band names. Depending on the arguments, it supports slicing (selecting one element of a dimension), cropping (selecting a subinterval of a dimension) and combinations thereof (e.g., selecting a spatial window and a temporal slice). Dimension subsets can be specified by integer indexes or coordinates / datetime values. Arguments are matched by type and order. For example, if the first argument is a length-two vector of type Date, the function will understand to subset the time dimension. Otherwise, arguments are treated in the order band, time, y, x.\n\n\n\nThis function returns a proxy object, i.e., it will not start any computations besides deriving the shape of the result.\n\n\n\n\n# create image collection from example Landsat data only \n# if not already done in other examples\nif (!file.exists(file.path(tempdir(), \"L8.db\"))) {\n  L8_files <- list.files(system.file(\"L8NY18\", package = \"gdalcubes\"),\n                         \".TIF\", recursive = TRUE, full.names = TRUE)\n  create_image_collection(L8_files, \"L8_L1TP\", file.path(tempdir(), \"L8.db\"), quiet = TRUE) \n}\nL8.col = image_collection(file.path(tempdir(), \"L8.db\"))\nv = cube_view(extent=list(left=388941.2, right=766552.4, \n              bottom=4345299, top=4744931, t0=\"2018-01\", t1=\"2018-12\"),\n              srs=\"EPSG:32618\", nx = 497, ny=526, dt=\"P3M\", aggregation = \"median\")\nL8.cube = raster_cube(L8.col, v, mask=image_mask(\"BQA\", bits=4, values=16))\nL8.red = L8.cube$B04\n\n\nplot(L8.red)\n\n\nv = cube_view(extent=list(left=388941.2, right=766552.4,\n                          bottom=4345299, top=4744931, t0=\"2018-01-01\", t1=\"2018-12-31\"),\n              srs=\"EPSG:32618\", nx = 497, ny=526, dt=\"P1D\", aggregation = \"median\")\nL8.cube = raster_cube(L8.col, v, mask=image_mask(\"BQA\", bits=4, values=16))\n\nL8.cube[c(\"B05\",\"B04\")] # select bands\n\nA GDAL data cube proxy object\n\nDimensions:\n         low       high count       pixel_size chunk_size\nt 2018-01-01 2018-12-31   365              P1D          1\ny    4345299    4744931   526 759.756653992395        384\nx   388941.2   766552.4   497 759.781086519115        384\n\nBands:\n  name offset scale nodata unit\n1  B05      0     1    NaN     \n2  B04      0     1    NaN     \n\nL8.cube[as.Date(c(\"2018-01-10\", \"2018-01-20\"))] # crop by time\n\nA GDAL data cube proxy object\n\nDimensions:\n         low       high count       pixel_size chunk_size\nt 2018-01-10 2018-01-20    11              P1D          1\ny    4345299    4744931   526 759.756653992395        384\nx   388941.2   766552.4   497 759.781086519115        384\n\nBands:\n   name offset scale nodata unit\n1   B01      0     1    NaN     \n2   B02      0     1    NaN     \n3   B03      0     1    NaN     \n4   B04      0     1    NaN     \n5   B05      0     1    NaN     \n6   B06      0     1    NaN     \n7   B07      0     1    NaN     \n8   B08      0     1    NaN     \n9   B09      0     1    NaN     \n10  B10      0     1    NaN     \n11  B11      0     1    NaN     \n12  BQA      0     1    NaN     \n\nL8.cube[as.Date(\"2018-01-10\")] # slice by time\n\nA GDAL data cube proxy object\n\nDimensions:\n         low       high count       pixel_size chunk_size\nt 2018-01-10 2018-01-10     1              P1D          1\ny    4345299    4744931   526 759.756653992395        384\nx   388941.2   766552.4   497 759.781086519115        384\n\nBands:\n   name offset scale nodata unit\n1   B01      0     1    NaN     \n2   B02      0     1    NaN     \n3   B03      0     1    NaN     \n4   B04      0     1    NaN     \n5   B05      0     1    NaN     \n6   B06      0     1    NaN     \n7   B07      0     1    NaN     \n8   B08      0     1    NaN     \n9   B09      0     1    NaN     \n10  B10      0     1    NaN     \n11  B11      0     1    NaN     \n12  BQA      0     1    NaN     \n\nL8.cube[\"B05\", \"2018-01-10\"] # select bands and slice by time\n\nA GDAL data cube proxy object\n\nDimensions:\n         low       high count       pixel_size chunk_size\nt 2018-01-10 2018-01-10     1              P1D          1\ny    4345299    4744931   526 759.756653992395        384\nx   388941.2   766552.4   497 759.781086519115        384\n\nBands:\n  name offset scale nodata unit\n1  B05      0     1    NaN     \n\nL8.cube[\"B05\", c(\"2018-01-10\",\"2018-01-17\")] # select bands and crop by time\n\nA GDAL data cube proxy object\n\nDimensions:\n         low       high count       pixel_size chunk_size\nt 2018-01-10 2018-01-17     8              P1D          1\ny    4345299    4744931   526 759.756653992395        384\nx   388941.2   766552.4   497 759.781086519115        384\n\nBands:\n  name offset scale nodata unit\n1  B05      0     1    NaN     \n\nL8.cube[, c(\"2018-01-10\",\"2018-01-17\")] # crop by time\n\nA GDAL data cube proxy object\n\nDimensions:\n         low       high count       pixel_size chunk_size\nt 2018-01-10 2018-01-17     8              P1D          1\ny    4345299    4744931   526 759.756653992395        384\nx   388941.2   766552.4   497 759.781086519115        384\n\nBands:\n   name offset scale nodata unit\n1   B01      0     1    NaN     \n2   B02      0     1    NaN     \n3   B03      0     1    NaN     \n4   B04      0     1    NaN     \n5   B05      0     1    NaN     \n6   B06      0     1    NaN     \n7   B07      0     1    NaN     \n8   B08      0     1    NaN     \n9   B09      0     1    NaN     \n10  B10      0     1    NaN     \n11  B11      0     1    NaN     \n12  BQA      0     1    NaN     \n\n# crop by space (coordinates and integer indexes respectively)\nL8.cube[list(left=388941.2 + 1e5, right=766552.4 - 1e5, bottom=4345299 + 1e5, top=4744931 - 1e5)]\n\nA GDAL data cube proxy object\n\nDimensions:\n               low             high count       pixel_size chunk_size\nt       2018-01-01       2018-12-31   365              P1D          1\ny   4445586.878327   4644643.121673   262 759.756653992395        384\nx 489232.303420523 666261.296579477   233 759.781086519115        384\n\nBands:\n   name offset scale nodata unit\n1   B01      0     1    NaN     \n2   B02      0     1    NaN     \n3   B03      0     1    NaN     \n4   B04      0     1    NaN     \n5   B05      0     1    NaN     \n6   B06      0     1    NaN     \n7   B07      0     1    NaN     \n8   B08      0     1    NaN     \n9   B09      0     1    NaN     \n10  B10      0     1    NaN     \n11  B11      0     1    NaN     \n12  BQA      0     1    NaN     \n\nL8.cube[,,c(1,100), c(1,100)] \n\nA GDAL data cube proxy object\n\nDimensions:\n               low             high count       pixel_size chunk_size\nt       2018-01-01       2018-12-31   365              P1D          1\ny 4668195.57794677 4744171.24334601   100 759.756653992394        384\nx 389700.981086519 465679.089738431   100 759.781086519114        384\n\nBands:\n   name offset scale nodata unit\n1   B01      0     1    NaN     \n2   B02      0     1    NaN     \n3   B03      0     1    NaN     \n4   B04      0     1    NaN     \n5   B05      0     1    NaN     \n6   B06      0     1    NaN     \n7   B07      0     1    NaN     \n8   B08      0     1    NaN     \n9   B09      0     1    NaN     \n10  B10      0     1    NaN     \n11  B11      0     1    NaN     \n12  BQA      0     1    NaN     \n\nL8.cube[,c(1,2),,] # crop by time (integer indexes)\n\nA GDAL data cube proxy object\n\nDimensions:\n         low       high count       pixel_size chunk_size\nt 2018-01-02 2018-01-03     2              P1D          1\ny    4345299    4744931   526 759.756653992395        384\nx   388941.2   766552.4   497 759.781086519115        384\n\nBands:\n   name offset scale nodata unit\n1   B01      0     1    NaN     \n2   B02      0     1    NaN     \n3   B03      0     1    NaN     \n4   B04      0     1    NaN     \n5   B05      0     1    NaN     \n6   B06      0     1    NaN     \n7   B07      0     1    NaN     \n8   B08      0     1    NaN     \n9   B09      0     1    NaN     \n10  B10      0     1    NaN     \n11  B11      0     1    NaN     \n12  BQA      0     1    NaN     \n\n# subset by spatial point or bounding box\nif (requireNamespace(\"sf\", quietly = TRUE)) {\n  s = sf::st_sfc(sf::st_point(c(500000, 4500000)), crs = \"EPSG:32618\")\n  L8.cube[s]\n\n  bbox =  sf::st_bbox(c(xmin = 388941.2 + 1e5, xmax = 766552.4 - 1e5,\n                   ymax = 4744931 - 1e5, ymin = 4345299 + 1e5), crs = sf::st_crs(32618))\n  L8.cube[bbox]\n}\n\n\n\n\nA GDAL data cube proxy object\n\nDimensions:\n               low             high count       pixel_size chunk_size\nt       2018-01-01       2018-12-31   365              P1D          1\ny   4445586.878327   4644643.121673   262 759.756653992395        384\nx 489232.303420523 666261.296579477   233 759.781086519115        384\n\nBands:\n   name offset scale nodata unit\n1   B01      0     1    NaN     \n2   B02      0     1    NaN     \n3   B03      0     1    NaN     \n4   B04      0     1    NaN     \n5   B05      0     1    NaN     \n6   B06      0     1    NaN     \n7   B07      0     1    NaN     \n8   B08      0     1    NaN     \n9   B09      0     1    NaN     \n10  B10      0     1    NaN     \n11  B11      0     1    NaN     \n12  BQA      0     1    NaN"
  },
  {
    "objectID": "source/reference/ref/animate.html",
    "href": "source/reference/ref/animate.html",
    "title": "gdalcubes",
    "section": "",
    "text": "Animate a data cube as an image time series\n\n\nThis function can animate data cube time series as mp4 videos or animated GIFs. Depending on the desired output format, either the av or the gifski package is needed to create mp4 and GIF animations respectively.\n\n\n\nanimate(\n  x,\n  ...,\n  fps = 1,\n  loop = TRUE,\n  width = 800,\n  height = 800,\n  save_as = tempfile(fileext = \".gif\"),\n  preview = interactive()\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\na data cube proxy object (class cube)\n\n\n…\nparameters passed to plot.cube\n\n\nfps\nframes per second of the animation\n\n\nloop\nhow many iterations, TRUE = infinite\n\n\nwidth\nwidth (in pixels) of the animation\n\n\nheight\nheight (in pixels) of the animation\n\n\nsave_as\ncharacter path where the animation shall be stored, must end with “.mp4” or “.gif”\n\n\npreview\nlogical; preview the animation\n\n\n\n\n\n\nAnimations can be created for single band data cubes or RGB plots of multi-band data cubes (by providing the argument rgb) only.\n\n\n\ncharacter; path pointing to the the created file\n\n\n\n\nif (!file.exists(file.path(tempdir(), \"L8.db\"))) {\n  L8_files <- list.files(system.file(\"L8NY18\", package = \"gdalcubes\"),\n                         \".TIF\", recursive = TRUE, full.names = TRUE)\n  create_image_collection(L8_files, \"L8_L1TP\", file.path(tempdir(), \"L8.db\"), quiet = TRUE)\n}\n\nL8.col = image_collection(file.path(tempdir(), \"L8.db\"))\nv = cube_view(extent=list(left=388941.2, right=766552.4,\n                          bottom=4345299, top=4744931, t0=\"2018-04\", t1=\"2018-06\"),\n              srs=\"EPSG:32618\", nx = 497, ny=526, dt=\"P16D\")\n\nanimate(select_bands(raster_cube(L8.col, v), c(\"B02\", \"B03\", \"B04\")), rgb=3:1,\n        zlim=c(0,20000), fps=1, loop=1)\n\n[1] \"/tmp/Rtmptlw663/filebfee527efc7d9.gif\"\n\nanimate(select_bands(raster_cube(L8.col, v), c(\"B05\")), col=terrain.colors, key.pos=1)\n\n[1] \"/tmp/Rtmptlw663/filebfee536c702e1.gif\"\n\n\n\n\n\nplot.cube"
  },
  {
    "objectID": "source/reference/ref/json_cube.html",
    "href": "source/reference/ref/json_cube.html",
    "title": "gdalcubes",
    "section": "",
    "text": "Read a data cube from a json description file\n\n\nRead a data cube from a json description file\n\n\n\njson_cube(json, path = NULL)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\njson\nlength-one character vector with a valid json data cube description\n\n\npath\nsource data cube proxy object\n\n\n\n\n\n\nData cubes can be stored as JSON description files. These files do not store any data but the recipe how a data cube is consructed, i.e., the chain (or graph) of processes involved.\nSince data cube objects (as returned from raster_cube) cannot be saved with normal R methods, the combination of as_json and json_cube provides a cheap way to save data cube objects across several R sessions, as in the examples.\n\n\n\ndata cube proxy object\n\n\n\n\n{\n# create image collection from example Landsat data only \n# if not already done in other examples\nif (!file.exists(file.path(tempdir(), \"L8.db\"))) {\n  L8_files <- list.files(system.file(\"L8NY18\", package = \"gdalcubes\"),\n                         \".TIF\", recursive = TRUE, full.names = TRUE)\n  create_image_collection(L8_files, \"L8_L1TP\", file.path(tempdir(), \"L8.db\"), quiet = TRUE) \n}\n\nL8.col = image_collection(file.path(tempdir(), \"L8.db\"))\nv = cube_view(extent=list(left=388941.2, right=766552.4, \n              bottom=4345299, top=4744931, t0=\"2018-01\", t1=\"2018-12\"),\n              srs=\"EPSG:32618\", nx = 497, ny=526, dt=\"P1M\")\ncube = raster_cube(L8.col, v) \n\n# save\nfname = tempfile()\nwriteLines(as_json(cube), fname)\n\n# load\njson_cube(path = fname)  \n}\n\nA GDAL data cube proxy object\n\nDimensions:\n         low       high count       pixel_size chunk_size\nt 2018-01-01 2018-12-01    12              P1M          1\ny    4345299    4744931   526 759.756653992395        384\nx   388941.2   766552.4   497 759.781086519115        384\n\nBands:\n   name offset scale nodata unit\n1   B01      0     1    NaN     \n2   B02      0     1    NaN     \n3   B03      0     1    NaN     \n4   B04      0     1    NaN     \n5   B05      0     1    NaN     \n6   B06      0     1    NaN     \n7   B07      0     1    NaN     \n8   B08      0     1    NaN     \n9   B09      0     1    NaN     \n10  B10      0     1    NaN     \n11  B11      0     1    NaN     \n12  BQA      0     1    NaN"
  },
  {
    "objectID": "source/reference/ref/gdalcubes_version.html",
    "href": "source/reference/ref/gdalcubes_version.html",
    "title": "gdalcubes",
    "section": "",
    "text": "Query gdalcubes version information\n\n\nQuery gdalcubes version information\n\n\n\ngdalcubes_version()\n\n\n\nList with gdalcubes library version information\n\n\n\n\ngdalcubes_version()\n\n$VERSION_MAJOR\n[1] 0\n\n$VERSION_MINOR\n[1] 3\n\n$VERSION_PATCH\n[1] 2\n\n$BUILD_DATE\n[1] \"May  6 2022\"\n\n$BUILD_TIME\n[1] \"12:24:45\"\n\n$GIT_DESC\n[1] \"v0.3.0-45-gdf51e935\"\n\n$GIT_COMMIT\n[1] \"df51e9352d60d399f7186d870421fa9f523f24d2\""
  },
  {
    "objectID": "source/reference/ref/write_tif.html",
    "href": "source/reference/ref/write_tif.html",
    "title": "gdalcubes",
    "section": "",
    "text": "Export a data cube as a collection of GeoTIFF files\n\n\nThis function will time slices of a data cube as GeoTIFF files in a given directory.\n\n\n\nwrite_tif(\n  x,\n  dir = tempfile(pattern = \"\"),\n  prefix = basename(tempfile(pattern = \"cube_\")),\n  overviews = FALSE,\n  COG = FALSE,\n  rsmpl_overview = \"nearest\",\n  creation_options = NULL,\n  write_json_descr = FALSE,\n  pack = NULL\n)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\na data cube proxy object (class cube)\n\n\ndir\ndestination directory\n\n\nprefix\noutput file name\n\n\noverviews\nlogical; generate overview images\n\n\nCOG\nlogical; create cloud-optimized GeoTIFF files (forces overviews=TRUE)\n\n\nrsmpl_overview\nresampling method for overviews (image pyramid) generation (see https://gdal.org/programs/gdaladdo.html for available methods)\n\n\ncreation_options\nadditional creation options for resulting GeoTIFF files, e.g. to define compression (see https://gdal.org/drivers/raster/gtiff.html#creation-options)\n\n\nwrite_json_descr\nlogical; write a JSON description of x as additional file\n\n\npack\nreduce output file size by packing values (see Details), defaults to no packing\n\n\n\n\n\n\nIf write_json_descr is TRUE, the function will write an additional file with name according to prefix (if not missing) or simply cube.json This file includes a serialized description of the input data cube, including all chained data cube operations.\nAdditional GDAL creation options for resulting GeoTIFF files must be passed as a named list of simple strings, where element names refer to the key. For example, creation_options = list(\"COMPRESS\" = \"DEFLATE\", \"ZLEVEL\" = \"5\") would enable deflate compression at level 5.\nTo reduce the size of created files, values can be packed by applying a scale factor and an offset value and using a smaller integer data type for storage. The pack argument can be either NULL (the default), or a list with elements type, scale, offset, and nodata. type can be any of “uint8”, “uint16” , “uint32”, “int16”, or “int32”. scale, offset, and nodata must be numeric vectors with length one or length equal to the number of data cube bands (to use different values for different bands). The helper function pack_minmax can be used to derive offset and scale values with maximum precision from minimum and maximum data values on original scale.\nIf overviews=TRUE, the numbers of pixels are halved until the longer spatial dimensions counts less than 256 pixels. Setting COG=TRUE automatically sets overviews=TRUE.\n\n\n\nreturns (invisibly) a vector of paths pointing to the created GeoTIFF files\n\n\n\n\n# create image collection from example Landsat data only \n# if not already done in other examples\nif (!file.exists(file.path(tempdir(), \"L8.db\"))) {\n  L8_files <- list.files(system.file(\"L8NY18\", package = \"gdalcubes\"),\n                         \".TIF\", recursive = TRUE, full.names = TRUE)\n  create_image_collection(L8_files, \"L8_L1TP\", file.path(tempdir(), \"L8.db\"), quiet = TRUE) \n}\n\nL8.col = image_collection(file.path(tempdir(), \"L8.db\"))\nv = cube_view(extent=list(left=388941.2, right=766552.4, \n              bottom=4345299, top=4744931, t0=\"2018-04\", t1=\"2018-04\"),\n              srs=\"EPSG:32618\", nx = 497, ny=526, dt=\"P1M\")\nwrite_tif(select_bands(raster_cube(L8.col, v), c(\"B04\", \"B05\")), dir=tempdir())\n\n\n\n\npack_minmax"
  },
  {
    "objectID": "source/reference/ref/stack_cube.html",
    "href": "source/reference/ref/stack_cube.html",
    "title": "gdalcubes",
    "section": "",
    "text": "Create a data cube from a set of images with the same spatial extent and spatial reference system\n\n\nCreate a spatiotemporal data cube directly from images with identical spatial extent and spatial reference system, similar to a raster stack with an additional dimension supporting both, time and multiple bands / variables.\n\n\n\nstack_cube(\n  x,\n  datetime_values,\n  bands = NULL,\n  band_names = NULL,\n  chunking = c(1, 256, 256),\n  dx = NULL,\n  dy = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\ncharacter vector where items point to image files\n\n\ndatetime_values\nvector of type character, Date, or POSIXct with recording date of images\n\n\nbands\noptional character vector defining the band or spectral band of each item in x, if files relate to different spectral bands or variables\n\n\nband_names\nname of bands, only used if bands is NULL, i.e., if all files contain the same spectral band(s) / variable(s)\n\n\nchunking\nvector of length 3 defining the size of data cube chunks in the order time, y, x.\n\n\ndx\noptional target pixel size in x direction, by default (NULL) the original or highest resolution of images is used\n\n\ndy\noptional target pixel size in y direction, by default (NULL) the original or highest resolution of images is used\n\n\n\n\n\n\nThis function creates a four-dimensional (space, time, bands / variables) raster data cube from a set of provided files without the need to create an image collection before. This is possible if all images have the same spatial extent and spatial reference system and can be used for two different file organizations:\n\nIf all image files share the same bands / variables, the bands argument can be ignored (default NULL) can names of the bands can be specified using the band_names argument.\nIf image files represent different band / variable (e.g. individual files for red, green, and blue channels), the bands argument must be used to define the corresponding band / variable. Notice that in this case all files are expected to represent exactly one variable / band at one point in datetime. It is not possible to combine files with different numbers of variables / bands. If image files for different bands have different pixel sizes, the smallest size is used by default.\n\nNotice that to avoid opening all image files in advance,no automatic check whether all images share the spatial extent and spatial reference system is performed.\n\n\n\nA proxy data cube object\n\n\n\nThis function returns a proxy object, i.e., it will not start any computations besides deriving the shape of the result.\n\n\n\n\n# toy example, repeating the same image as a daily time series\nL8_file_nir <- \nsystem.file(\"L8NY18/LC08_L1TP_014032_20181122_20181129_01_T1/LC08_L1TP_014032_20181122_B5.TIF\",\n            package = \"gdalcubes\")\nfiles = rep(L8_file_nir, 10)\ndatetime = as.Date(\"2018-11-22\") + 1:10\nstack_cube(files, datetime, band_names = \"B05\") \n\nA GDAL data cube proxy object\n\nDimensions:\n         low       high count       pixel_size chunk_size\nt 2018-11-23 2018-12-02    10              P1D          1\ny    4346085    4582215    78 3027.30769230769        256\nx     394185     626415    77 3015.97402597403        256\n                                                      values\nt 2018-11-23,2018-11-24,2018-11-25,2018-11-26,2018-11-27,...\ny                                                           \nx                                                           \n\nBands:\n  name offset scale nodata unit\n1  B05      0     1 -1e+10     \n\n# using a second band from different files\nL8_file_red <- \nsystem.file(\"L8NY18/LC08_L1TP_014032_20181122_20181129_01_T1/LC08_L1TP_014032_20181122_B4.TIF\",\n            package = \"gdalcubes\")\nfiles = rep(c(L8_file_nir, L8_file_red), each = 10)\ndatetime = rep(as.Date(\"2018-11-22\") + 1:10, 2)\nbands = rep(c(\"B5\",\"B4\"), each = 10)\nstack_cube(files, datetime, bands = bands)         \n\nA GDAL data cube proxy object\n\nDimensions:\n         low       high count       pixel_size chunk_size\nt 2018-11-23 2018-12-02    10              P1D          1\ny    4346085    4582215    78 3027.30769230769        256\nx     394185     626415    77 3015.97402597403        256\n                                                      values\nt 2018-11-23,2018-11-24,2018-11-25,2018-11-26,2018-11-27,...\ny                                                           \nx                                                           \n\nBands:\n  name offset scale nodata unit\n1   B5      0     1 -1e+10     \n2   B4      0     1 -1e+10"
  },
  {
    "objectID": "source/reference/ref/gdalcubes_gdal_has_geos.html",
    "href": "source/reference/ref/gdalcubes_gdal_has_geos.html",
    "title": "gdalcubes",
    "section": "",
    "text": "Check if GDAL was built with GEOS\n\n\nCheck if GDAL was built with GEOS\n\n\n\ngdalcubes_gdal_has_geos()\n\n\n\n\ngdalcubes_gdal_has_geos()\n\n[1] TRUE"
  },
  {
    "objectID": "source/reference/ref/slice_space.html",
    "href": "source/reference/ref/slice_space.html",
    "title": "gdalcubes",
    "section": "",
    "text": "Extract a single time series (spatial slice) from a data cube\n\n\nCreate a proxy data cube, which extracts a time series from a data cube defined by spatial coordinates or integer x and y indexes.\n\n\n\nslice_space(cube, loc = NULL, i = NULL)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ncube\nsource data cube\n\n\nloc\nnumeric length-two vector; spatial coordinates (x, y) of the time series, expressed in the coordinate reference system of the source data cube\n\n\ni\ninteger length-2 vector; indexes (x,y) of the time slice (zero-based)\n\n\n\n\n\n\nEither loc or i must be non-NULL. If both arguments are provided, integer indexes i are ignored.\n\n\n\nThis function returns a proxy object, i.e., it will not start any computations besides deriving the shape of the result.\n\n\n\n\n# create image collection from example Landsat data only \n# if not already done in other examples\nif (!file.exists(file.path(tempdir(), \"L8.db\"))) {\n  L8_files <- list.files(system.file(\"L8NY18\", package = \"gdalcubes\"),\n                         \".TIF\", recursive = TRUE, full.names = TRUE)\n  create_image_collection(L8_files, \"L8_L1TP\", file.path(tempdir(), \"L8.db\"), quiet = TRUE) \n}\nL8.col = image_collection(file.path(tempdir(), \"L8.db\"))\nv = cube_view(extent=list(left=388941.2, right=766552.4, \n              bottom=4345299, top=4744931, t0=\"2018-01\", t1=\"2018-12\"),\n              srs=\"EPSG:32618\", nx = 497, ny=526, dt=\"P3M\", aggregation = \"median\")\nL8.cube = raster_cube(L8.col, v, mask=image_mask(\"BQA\", bits=4, values=16))\nL8.rgb = select_bands(L8.cube, c(\"B02\", \"B03\", \"B04\"))\nL8.ts = slice_space(L8.rgb, loc = c(5e05, 4400000))\nL8.ts\n\nA GDAL data cube proxy object\n\nDimensions:\n               low             high count       pixel_size chunk_size\nt       2018-01-01       2018-12-31     4              P3M          1\ny 4690228.52091255 4690988.27756654     1 759.756653992459          1\nx 499869.238631791  500629.01971831     1 759.781086519128          1\n\nBands:\n  name offset scale nodata unit\n1  B02      0     1    NaN     \n2  B03      0     1    NaN     \n3  B04      0     1    NaN     \n\nplot(L8.ts, join.timeseries = TRUE)"
  },
  {
    "objectID": "source/reference/ref/gdalcubes_gdalformats.html",
    "href": "source/reference/ref/gdalcubes_gdalformats.html",
    "title": "gdalcubes",
    "section": "",
    "text": "Get available GDAL drivers\n\n\nGet available GDAL drivers\n\n\n\ngdalcubes_gdalformats()\n\n\n\n\ngdalcubes_gdalformats()\n\n  [1] \"VRT\"             \"DERIVED\"         \"GTiff\"           \"COG\"            \n  [5] \"NITF\"            \"RPFTOC\"          \"ECRGTOC\"         \"HFA\"            \n  [9] \"SAR_CEOS\"        \"CEOS\"            \"JAXAPALSAR\"      \"GFF\"            \n [13] \"ELAS\"            \"ESRIC\"           \"AIG\"             \"AAIGrid\"        \n [17] \"GRASSASCIIGrid\"  \"ISG\"             \"SDTS\"            \"DTED\"           \n [21] \"PNG\"             \"JPEG\"            \"MEM\"             \"JDEM\"           \n [25] \"GIF\"             \"BIGGIF\"          \"ESAT\"            \"FITS\"           \n [29] \"BSB\"             \"XPM\"             \"BMP\"             \"DIMAP\"          \n [33] \"AirSAR\"          \"RS2\"             \"SAFE\"            \"PCIDSK\"         \n [37] \"PCRaster\"        \"ILWIS\"           \"SGI\"             \"SRTMHGT\"        \n [41] \"Leveller\"        \"Terragen\"        \"GMT\"             \"netCDF\"         \n [45] \"HDF4\"            \"HDF4Image\"       \"ISIS3\"           \"ISIS2\"          \n [49] \"PDS\"             \"PDS4\"            \"VICAR\"           \"TIL\"            \n [53] \"ERS\"             \"JP2OpenJPEG\"     \"L1B\"             \"FIT\"            \n [57] \"GRIB\"            \"RMF\"             \"WCS\"             \"WMS\"            \n [61] \"MSGN\"            \"RST\"             \"INGR\"            \"GSAG\"           \n [65] \"GSBG\"            \"GS7BG\"           \"COSAR\"           \"TSX\"            \n [69] \"COASP\"           \"R\"               \"MAP\"             \"KMLSUPEROVERLAY\"\n [73] \"WEBP\"            \"PDF\"             \"Rasterlite\"      \"MBTiles\"        \n [77] \"PLMOSAIC\"        \"CALS\"            \"WMTS\"            \"SENTINEL2\"      \n [81] \"MRF\"             \"PNM\"             \"DOQ1\"            \"DOQ2\"           \n [85] \"PAux\"            \"MFF\"             \"MFF2\"            \"FujiBAS\"        \n [89] \"GSC\"             \"FAST\"            \"BT\"              \"LAN\"            \n [93] \"CPG\"             \"IDA\"             \"NDF\"             \"EIR\"            \n [97] \"DIPEx\"           \"LCP\"             \"GTX\"             \"LOSLAS\"         \n[101] \"NTv2\"            \"CTable2\"         \"ACE2\"            \"SNODAS\"         \n[105] \"KRO\"             \"ROI_PAC\"         \"RRASTER\"         \"BYN\"            \n[109] \"ARG\"             \"RIK\"             \"USGSDEM\"         \"GXF\"            \n[113] \"BAG\"             \"HDF5\"            \"HDF5Image\"       \"NWT_GRD\"        \n[117] \"NWT_GRC\"         \"ADRG\"            \"SRP\"             \"BLX\"            \n[121] \"PostGISRaster\"   \"SAGA\"            \"XYZ\"             \"HF2\"            \n[125] \"JPEGLS\"          \"OZI\"             \"CTG\"             \"ZMap\"           \n[129] \"NGSGEOID\"        \"IRIS\"            \"PRF\"             \"RDA\"            \n[133] \"EEDAI\"           \"EEDA\"            \"DAAS\"            \"SIGDEM\"         \n[137] \"HEIF\"            \"TGA\"             \"OGCAPI\"          \"STACTA\"         \n[141] \"STACIT\"          \"GNMFile\"         \"GNMDatabase\"     \"ESRI Shapefile\" \n[145] \"MapInfo File\"    \"UK .NTF\"         \"LVBAG\"           \"OGR_SDTS\"       \n[149] \"S57\"             \"DGN\"             \"OGR_VRT\"         \"REC\"            \n[153] \"Memory\"          \"CSV\"             \"NAS\"             \"GML\"            \n[157] \"GPX\"             \"LIBKML\"          \"KML\"             \"GeoJSON\"        \n[161] \"GeoJSONSeq\"      \"ESRIJSON\"        \"TopoJSON\"        \"Interlis 1\"     \n[165] \"Interlis 2\"      \"OGR_GMT\"         \"GPKG\"            \"SQLite\"         \n[169] \"ODBC\"            \"WAsP\"            \"PGeo\"            \"MSSQLSpatial\"   \n[173] \"OGR_OGDI\"        \"PostgreSQL\"      \"MySQL\"           \"OpenFileGDB\"    \n[177] \"DXF\"             \"CAD\"             \"FlatGeobuf\"      \"Geoconcept\"     \n[181] \"GeoRSS\"          \"GPSTrackMaker\"   \"VFK\"             \"PGDUMP\"         \n[185] \"OSM\"             \"GPSBabel\"        \"OGR_PDS\"         \"WFS\"            \n[189] \"OAPIF\"           \"SOSI\"            \"Geomedia\"        \"EDIGEO\"         \n[193] \"SVG\"             \"CouchDB\"         \"Cloudant\"        \"Idrisi\"         \n[197] \"ARCGEN\"          \"XLS\"             \"ODS\"             \"XLSX\"           \n[201] \"Elasticsearch\"   \"Walk\"            \"Carto\"           \"AmigoCloud\"     \n[205] \"SXF\"             \"Selafin\"         \"JML\"             \"PLSCENES\"       \n[209] \"CSW\"             \"VDV\"             \"GMLAS\"           \"MVT\"            \n[213] \"NGW\"             \"MapML\"           \"TIGER\"           \"AVCBin\"         \n[217] \"AVCE00\"          \"GenBin\"          \"ENVI\"            \"EHdr\"           \n[221] \"ISCE\"            \"Zarr\"            \"HTTP\""
  },
  {
    "objectID": "source/reference/ref/print.cube_view.html",
    "href": "source/reference/ref/print.cube_view.html",
    "title": "gdalcubes",
    "section": "",
    "text": "Print data cube view information\n\n\nPrints information about a data cube view, including its dimensions, spatial reference, aggregation method, and resampling method.\n\n\n\nprint.cube_view(x, ...)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nObject of class “cube_view”\n\n\n…\nFurther arguments passed to the generic print function\n\n\n\n\n\n\n\nv = cube_view(extent=list(left=388941.2, right=766552.4, \n              bottom=4345299, top=4744931, t0=\"2018-01\", t1=\"2018-12\"),\n              srs=\"EPSG:32618\", nx = 497, ny=526, dt=\"P1M\")\nprint(v)\n\nA data cube view object\n\nDimensions:\n         low       high count       pixel_size\nt 2018-01-01 2018-12-31    12              P1M\ny    4345299    4744931   526 759.756653992395\nx   388941.2   766552.4   497 759.781086519115\n\nSRS: \"EPSG:32618\"\nTemporal aggregation method: \"first\"\nSpatial resampling method: \"near\""
  },
  {
    "objectID": "source/reference/ref/stac_image_collection.html",
    "href": "source/reference/ref/stac_image_collection.html",
    "title": "gdalcubes",
    "section": "",
    "text": "Create an image collection from a STAC feature collection\n\n\nThis function creates an image collection from a STAC API collection response. It does not need to read any image data. Additionally, bands can be filtered and asset links can be transformed to make them readable for GDAL.\n\n\n\nstac_image_collection(\n  s,\n  out_file = tempfile(fileext = \".sqlite\"),\n  asset_names = NULL,\n  asset_regex = NULL,\n  url_fun = function(x) {     paste0(\"/vsicurl/\", x) },\n  property_filter = NULL,\n  skip_image_metadata = FALSE\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ns\nSTAC feature collection\n\n\nout_file\noptional name of the output SQLite database file, defaults to a temporary file\n\n\nasset_names\ncharacter vector with names of assets (e.g., bands) to be used, other assets will be ignored. By default (NULL), all asset names with “eo:bands” attributes will be used\n\n\nasset_regex\nlength 1 character defining a regular expression asset names must match to be considered\n\n\nurl_fun\noptional function to modify URLs of assets, e.g, to add /vsicurl/ to URLS (the default)\n\n\nproperty_filter\noptional function to filter STAC items (images) by their properties; see Details\n\n\nskip_image_metadata\nlogical, if TRUE per-image metadata (STAC item properties) will not be added to the image collection\n\n\n\n\n\n\nThe property_filter argument can be used to filter images by metadata such as cloud coverage. The functions receives all properties of a STAC item (image) as input list and is expected to produce a single logical value, where an image will be ignored if the function returns FALSE.\n\n\n\nCurrently, bbox results are expected to be WGS84 coordinates, even if bbox-crs is given in the STAC response.\nThis function is experimental."
  },
  {
    "objectID": "source/reference/ref/pack_minmax.html",
    "href": "source/reference/ref/pack_minmax.html",
    "title": "gdalcubes",
    "section": "",
    "text": "Helper function to define packed data exports by min / max values\n\n\nThis function can be used to define packed exports in write_ncdf and write_tif. It will generate scale and offset values with maximum precision (unless simplify=TRUE).\n\n\n\npack_minmax(type = \"int16\", min, max, simplify = FALSE)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ntype\ntarget data type of packed values (one of “uint8”, “uint16”, “uint32”, “int16”, or “int32”)\n\n\nmin\nnumeric; minimum value(s) of original values, will be packed to the 2nd lowest value of the target data type\n\n\nmax\nnumeric; maximum value(s) in original scale, will be packed to the highest value of the target data type\n\n\nsimplify\nlogical; round resulting scale and offset to power of 10 values\n\n\n\n\n\n\nNodata values will be mapped to the lowest value of the target data type.\nArguments min and max must have length 1 or length equal to the number of bands of the data cube to be exported. In the former case, the same values are used for all bands of the exported target cube, whereas the latter case allows to use different ranges for different bands.\n\n\n\nUsing simplify=TRUE will round scale values to the next smaller power of 10.\n\n\n\n\nndvi_packing = pack_minmax(type=\"int16\", min=-1, max=1)\nndvi_packing\n\n$type\n[1] \"int16\"\n\n$offset\n[1] 0\n\n$scale\n[1] 3.051851e-05\n\n$nodata\n[1] -32768"
  },
  {
    "objectID": "source/reference/index.html",
    "href": "source/reference/index.html",
    "title": "gdalcubes",
    "section": "",
    "text": "This page presents an auto-generated reference of most important package functions. Functions are categorized into a few topics in the left menu.\n\n\n\n\n\nadd_collection_format\naggregate_space\nanimate\napply_pixel.cube\napply_time.array\napply_time\nas_json\nchunk_apply\ncreate_image_collection\ncube_view\ndimension_bounds\ndimensions\nextent\nfill_time\nfilter_pixel\ngdalcubes_gdalformats\ngdalcubes_options\ngdalcubes_set_gdal_config\ngdalcubes\nimage_mask\njson_cube\nnames.cube\nncdf_cube\nnx\npack_minmax\nprint.cube_view\nprint.image_collection\nraster_cube\nreduce_space.array\nreduce_space\nreduce_time.cube\nrename_bands\nselect_time\nslice_space\nsrs\nstac_image_collection\nwindow_time.cube\nwrite_chunk_from_array\nwrite_tif\n\n\nadd_images\naggregate_time\napply_pixel.array\napply_pixel\napply_time.cube\nas_array\nbands\ncollection_formats\ncrop\ndim.cube\ndimension_values\ndot-copy_cube\nextract_geom\nfilter_geom\ngdalcubes_gdal_has_geos\ngdalcubes_gdalversion\ngdalcubes_selection\ngdalcubes_version\nimage_collection\njoin_bands\nmemsize\nnbands\nnt\nny\nplot.cube\nprint.cube\nproj4\nread_chunk_as_array\nreduce_space.cube\nreduce_time.array\nreduce_time\nselect_bands\nsize\nslice_time\nst_as_stars.cube\nstack_cube\nwindow_time\nwrite_ncdf"
  }
]